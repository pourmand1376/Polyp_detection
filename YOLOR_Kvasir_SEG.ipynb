{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "YOLOR-Kvasir-SEG.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EtClYG2z74SY"
      },
      "source": [
        "# How to Train YOLOR on Custom Objects\n",
        "\n",
        "This tutorial is based on the [YOLOR repository](https://github.com/WongKinYiu/yolor) by [Wong Kin-Yiu](https://github.com/WongKinYiu). This notebook shows training on **your own custom objects**. Many thanks to Wong for putting this repository together - we hope that in combination with clean data management tools at Roboflow, this technologoy will become easily accessible to any developer wishing to use computer vision in their projects.\n",
        "\n",
        "### Accompanying Blog Post\n",
        "\n",
        "We recommend that you follow along in this notebook while reading the blog post on [How to Train YOLOR](blog.roboflow.com/how-to-train-yolor-on-a-custom-dataset/), concurrently.\n",
        "\n",
        "### Steps Covered in this Tutorial\n",
        "\n",
        "In this tutorial, we will walk through the steps required to train YOLOR on your custom objects. We use a [public blood cell detection dataset](https://public.roboflow.ai/object-detection/bccd), which is open source and free to use. You can also use this notebook on your own data.\n",
        "\n",
        "To train our detector we take the following steps:\n",
        "\n",
        "* Install YOLOR dependencies\n",
        "* Download custom YOLOR object detection data\n",
        "* Prepare Pre-Trained Weights for YOLOR\n",
        "* Run YOLOR training\n",
        "* Evaluate YOLOR performance\n",
        "* Visualize YOLOR training data\n",
        "* Run YOLOR inference on test images\n",
        "* Export saved YOLOR weights for future inference\n",
        "\n",
        "### **About**\n",
        "\n",
        "[Roboflow](https://roboflow.com) enables teams to deploy custom computer vision models quickly and accurately. Convert data from to annotation format, assess dataset health, preprocess, augment, and more. It's free for your first 1000 source images.\n",
        "\n",
        "**Looking for a vision model available via API without hassle? Try Roboflow Train.**\n",
        "\n",
        "![Roboflow Wordmark](https://i.imgur.com/dcLNMhV.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "icONSOTY9AmP"
      },
      "source": [
        "#Install Dependencies\n",
        "\n",
        "_(Remember to choose GPU in Runtime if not already selected. Runtime --> Change Runtime Type --> Hardware accelerator --> GPU)_"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6bs156q-9Fpe",
        "outputId": "3ae0d545-b233-44e7-c9a6-7b576e186bb3"
      },
      "source": [
        "# clone YOLOR repository\n",
        "!git clone https://github.com/roboflow-ai/yolor\n",
        "%cd yolor \n",
        "!git reset --hard eb3ef0b7472413d6740f5cde39beb1a2f5b8b5d1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'yolor'...\n",
            "remote: Enumerating objects: 387, done.\u001b[K\n",
            "remote: Total 387 (delta 0), reused 0 (delta 0), pack-reused 387\u001b[K\n",
            "Receiving objects: 100% (387/387), 2.97 MiB | 12.99 MiB/s, done.\n",
            "Resolving deltas: 100% (173/173), done.\n",
            "/content/yolor/yolor\n",
            "HEAD is now at eb3ef0b indentation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fy4tuOqP9efo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e7996d3-8ce4-46e7-d49d-22bbd9ae4f56"
      },
      "source": [
        "# Install necessary dependencies\n",
        "!pip install -qr requirements.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 596 kB 5.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 776.7 MB 4.7 kB/s \n",
            "\u001b[K     |████████████████████████████████| 12.7 MB 16.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.5 MB 40.6 MB/s \n",
            "\u001b[?25h  Building wheel for pycocotools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.11.0 requires torch==1.10.0, but you have torch 1.7.0 which is incompatible.\n",
            "torchaudio 0.10.0+cu111 requires torch==1.10.0, but you have torch 1.7.0 which is incompatible.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w23WgLFB-TZ-",
        "outputId": "971123a1-9c41-4e7e-af18-258de5e2d96d"
      },
      "source": [
        "# Install Mish CUDA\n",
        "!git clone https://github.com/JunnYu/mish-cuda\n",
        "%cd mish-cuda\n",
        "!git reset --hard 6f38976064cbcc4782f4212d7c0c5f6dd5e315a8\n",
        "!python setup.py build install\n",
        "%cd .."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'mish-cuda'...\n",
            "remote: Enumerating objects: 195, done.\u001b[K\n",
            "remote: Counting objects: 100% (88/88), done.\u001b[K\n",
            "remote: Compressing objects: 100% (75/75), done.\u001b[K\n",
            "remote: Total 195 (delta 7), reused 79 (delta 3), pack-reused 107\u001b[K\n",
            "Receiving objects: 100% (195/195), 208.77 KiB | 3.94 MiB/s, done.\n",
            "Resolving deltas: 100% (56/56), done.\n",
            "/content/yolor/mish-cuda\n",
            "HEAD is now at 6f38976 Update README.md\n",
            "/usr/lib/python3.7/distutils/extension.py:131: UserWarning: Unknown Extension options: 'headers'\n",
            "  warnings.warn(msg)\n",
            "running build\n",
            "running build_py\n",
            "creating build\n",
            "creating build/lib.linux-x86_64-3.7\n",
            "creating build/lib.linux-x86_64-3.7/mish_cuda\n",
            "copying src/mish_cuda/__init__.py -> build/lib.linux-x86_64-3.7/mish_cuda\n",
            "running egg_info\n",
            "creating src/mish_cuda.egg-info\n",
            "writing src/mish_cuda.egg-info/PKG-INFO\n",
            "writing dependency_links to src/mish_cuda.egg-info/dependency_links.txt\n",
            "writing requirements to src/mish_cuda.egg-info/requires.txt\n",
            "writing top-level names to src/mish_cuda.egg-info/top_level.txt\n",
            "writing manifest file 'src/mish_cuda.egg-info/SOURCES.txt'\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/cpp_extension.py:339: UserWarning: Attempted to use ninja as the BuildExtension backend but we could not find ninja.. Falling back to using the slow distutils backend.\n",
            "  warnings.warn(msg.format('we could not find ninja.'))\n",
            "adding license file 'LICENSE'\n",
            "writing manifest file 'src/mish_cuda.egg-info/SOURCES.txt'\n",
            "running build_ext\n",
            "building 'mish_cuda._C' extension\n",
            "creating build/temp.linux-x86_64-3.7\n",
            "creating build/temp.linux-x86_64-3.7/csrc\n",
            "creating build/temp.linux-x86_64-3.7/csrc/cpu\n",
            "creating build/temp.linux-x86_64-3.7/csrc/cuda\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-Y7dWVB/python3.7-3.7.12=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-Y7dWVB/python3.7-3.7.12=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c csrc/cpu/mish_cpu.cpp -o build/temp.linux-x86_64-3.7/csrc/cpu/mish_cpu.o -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Parallel.h:149:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/CPUApplyUtils.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kcsrc/cpu/mish_cpu.cpp:3\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ParallelOpenMP.h:84:0:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kignoring #pragma omp parallel [\u001b[01;35m\u001b[K-Wunknown-pragmas\u001b[m\u001b[K]\n",
            " #pragma omp parallel for if ((end - begin) >= grain_size)\n",
            " \n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-Y7dWVB/python3.7-3.7.12=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-Y7dWVB/python3.7-3.7.12=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c csrc/cuda/mish_cuda.cpp -o build/temp.linux-x86_64-3.7/csrc/cuda/mish_cuda.o -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Parallel.h:149:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/utils.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:5\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/nn.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:12\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kcsrc/cuda/mish_cuda.cpp:2\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ParallelOpenMP.h:84:0:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kignoring #pragma omp parallel [\u001b[01;35m\u001b[K-Wunknown-pragmas\u001b[m\u001b[K]\n",
            " #pragma omp parallel for if ((end - begin) >= grain_size)\n",
            " \n",
            "/usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c csrc/cuda/mish_kernel.cu -o build/temp.linux-x86_64-3.7/csrc/cuda/mish_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' --expt-extended-lambda -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=sm_37 -std=c++14\n",
            "nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/boxing/impl/boxing.h(100): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/op_registration/op_whitelist.h(39): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/boxing/impl/boxing.h(100): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/op_registration/op_whitelist.h(39): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fdebug-prefix-map=/build/python3.7-Y7dWVB/python3.7-3.7.12=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.7/csrc/cpu/mish_cpu.o build/temp.linux-x86_64-3.7/csrc/cuda/mish_cuda.o build/temp.linux-x86_64-3.7/csrc/cuda/mish_kernel.o -L/usr/local/lib/python3.7/dist-packages/torch/lib -L/usr/local/cuda/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-3.7/mish_cuda/_C.cpython-37m-x86_64-linux-gnu.so\n",
            "running install\n",
            "running bdist_egg\n",
            "installing library code to build/bdist.linux-x86_64/egg\n",
            "running install_lib\n",
            "creating build/bdist.linux-x86_64\n",
            "creating build/bdist.linux-x86_64/egg\n",
            "creating build/bdist.linux-x86_64/egg/mish_cuda\n",
            "copying build/lib.linux-x86_64-3.7/mish_cuda/__init__.py -> build/bdist.linux-x86_64/egg/mish_cuda\n",
            "copying build/lib.linux-x86_64-3.7/mish_cuda/_C.cpython-37m-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/egg/mish_cuda\n",
            "byte-compiling build/bdist.linux-x86_64/egg/mish_cuda/__init__.py to __init__.cpython-37.pyc\n",
            "creating stub loader for mish_cuda/_C.cpython-37m-x86_64-linux-gnu.so\n",
            "byte-compiling build/bdist.linux-x86_64/egg/mish_cuda/_C.py to _C.cpython-37.pyc\n",
            "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying src/mish_cuda.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying src/mish_cuda.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying src/mish_cuda.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying src/mish_cuda.egg-info/not-zip-safe -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying src/mish_cuda.egg-info/requires.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying src/mish_cuda.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "writing build/bdist.linux-x86_64/egg/EGG-INFO/native_libs.txt\n",
            "creating dist\n",
            "creating 'dist/mish_cuda-0.0.3-py3.7-linux-x86_64.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
            "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
            "Processing mish_cuda-0.0.3-py3.7-linux-x86_64.egg\n",
            "creating /usr/local/lib/python3.7/dist-packages/mish_cuda-0.0.3-py3.7-linux-x86_64.egg\n",
            "Extracting mish_cuda-0.0.3-py3.7-linux-x86_64.egg to /usr/local/lib/python3.7/dist-packages\n",
            "Adding mish-cuda 0.0.3 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.7/dist-packages/mish_cuda-0.0.3-py3.7-linux-x86_64.egg\n",
            "Processing dependencies for mish-cuda==0.0.3\n",
            "Searching for torch==1.7.0\n",
            "Best match: torch 1.7.0\n",
            "Adding torch 1.7.0 to easy-install.pth file\n",
            "Installing convert-caffe2-to-onnx script to /usr/local/bin\n",
            "Installing convert-onnx-to-caffe2 script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for typing-extensions==3.10.0.2\n",
            "Best match: typing-extensions 3.10.0.2\n",
            "Adding typing-extensions 3.10.0.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for numpy==1.19.5\n",
            "Best match: numpy 1.19.5\n",
            "Adding numpy 1.19.5 to easy-install.pth file\n",
            "Installing f2py script to /usr/local/bin\n",
            "Installing f2py3 script to /usr/local/bin\n",
            "Installing f2py3.7 script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for future==0.16.0\n",
            "Best match: future 0.16.0\n",
            "Adding future 0.16.0 to easy-install.pth file\n",
            "Installing futurize script to /usr/local/bin\n",
            "Installing pasteurize script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for dataclasses==0.6\n",
            "Best match: dataclasses 0.6\n",
            "Adding dataclasses 0.6 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Finished processing dependencies for mish-cuda==0.0.3\n",
            "/content/yolor\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MWJkbCp8Yoj_",
        "outputId": "0f473b48-b684-4326-dec5-4c2eec5696f2"
      },
      "source": [
        "# Install PyTorch Wavelets\n",
        "!git clone https://github.com/fbcotter/pytorch_wavelets\n",
        "%cd pytorch_wavelets\n",
        "!pip install .\n",
        "%cd .."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'pytorch_wavelets'...\n",
            "remote: Enumerating objects: 972, done.\u001b[K\n",
            "remote: Counting objects: 100% (136/136), done.\u001b[K\n",
            "remote: Compressing objects: 100% (91/91), done.\u001b[K\n",
            "remote: Total 972 (delta 75), reused 89 (delta 45), pack-reused 836\u001b[K\n",
            "Receiving objects: 100% (972/972), 6.80 MiB | 23.92 MiB/s, done.\n",
            "Resolving deltas: 100% (659/659), done.\n",
            "/content/yolor/pytorch_wavelets\n",
            "Processing /content/yolor/pytorch_wavelets\n",
            "\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
            "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pytorch-wavelets==1.3.0) (1.19.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from pytorch-wavelets==1.3.0) (1.15.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from pytorch-wavelets==1.3.0) (1.7.0)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.7/dist-packages (from torch->pytorch-wavelets==1.3.0) (0.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->pytorch-wavelets==1.3.0) (3.10.0.2)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch->pytorch-wavelets==1.3.0) (0.16.0)\n",
            "Building wheels for collected packages: pytorch-wavelets\n",
            "  Building wheel for pytorch-wavelets (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytorch-wavelets: filename=pytorch_wavelets-1.3.0-py3-none-any.whl size=54869 sha256=da18a68c04b5d901609af1ba639255ee0bd9329998068d52a05535b7c71ac2fa\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-8t9xp6bv/wheels/68/d6/0a/629cb6c68e1577155ab73a47758996d9ab26f15ba622561e28\n",
            "Successfully built pytorch-wavelets\n",
            "Installing collected packages: pytorch-wavelets\n",
            "Successfully installed pytorch-wavelets-1.3.0\n",
            "/content/yolor\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TYI5O1mW98Ji"
      },
      "source": [
        "# Download Correctly Formatted Custom Dataset \n",
        "\n",
        "We'll download our dataset from Roboflow. Use the \"**YOLOv5 PyTorch**\" export format. Note that the Ultralytics implementation calls for a YAML file defining where your training and test data is. The Roboflow export also writes this format for us.\n",
        "\n",
        "To get your data into Roboflow, follow the [Getting Started Guide](https://blog.roboflow.ai/getting-started-with-roboflow/).\n",
        "\n",
        "![YOLOv5 PyTorch export](https://i.imgur.com/5vr9G2u.png)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8GecVEGw4mMz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3d0f3d9-a7e6-4307-d071-f7b8c9147609"
      },
      "source": [
        "#follow the link below to get your download code from from Roboflow\n",
        "!pip install -q roboflow\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(model_format=\"yolov5\", notebook=\"roboflow-yolor\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 138 kB 7.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 40.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 145 kB 45.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 178 kB 48.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 67 kB 5.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.7 MB/s \n",
            "\u001b[?25h  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.11.0 requires torch==1.10.0, but you have torch 1.7.0 which is incompatible.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.27.1 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "upload and label your dataset, and get an API KEY here: https://app.roboflow.com/?model=yolov5&ref=roboflow-yolor\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HOqdKhc4-vOK",
        "outputId": "3f5ba80f-7fb4-45a6-8b2f-23a84d56a55f"
      },
      "source": [
        "%cd /content/yolov5\n",
        "#after following the link above, recieve python code with these fields filled in\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"Quj44CovudhOOv2fXcs0\")\n",
        "project = rf.workspace().project(\"kvasir-seg-hrk5k\")\n",
        "dataset = project.version(\"1\").download(\"yolov5\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: '/content/yolov5'\n",
            "/content/yolor\n",
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n",
            "Downloading Dataset Version Zip in Kvasir-SEG-1 to yolov5pytorch: 100% [48322306 / 48322306] bytes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting Dataset Version Zip to Kvasir-SEG-1 in yolov5pytorch:: 100%|██████████| 4812/4812 [00:05<00:00, 957.97it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eltS69vHDldw",
        "outputId": "9fd13f2b-5e4a-417d-9af6-43925c1eb983"
      },
      "source": [
        "# this is the YAML file Roboflow wrote for us that we're loading into this notebook with our data\n",
        "%cat {dataset.location}/data.yaml"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "names:\n",
            "- json\n",
            "nc: 1\n",
            "train: Kvasir-SEG-1/train/images\n",
            "val: Kvasir-SEG-1/valid/images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GCs0G_xoD0aq"
      },
      "source": [
        "# Prepare Pre-Trained Weights for YOLOR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8JepT8h7EA_j",
        "outputId": "d70908ae-633a-474a-fc8d-8ccda05dcbcc"
      },
      "source": [
        "%cd /content/yolor\n",
        "!bash scripts/get_pretrain.sh"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/yolor\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   408    0   408    0     0   2060      0 --:--:-- --:--:-- --:--:--  2060\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100  142M  100  142M    0     0  59.7M      0  0:00:02  0:00:02 --:--:-- 91.4M\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   408    0   408    0     0   3090      0 --:--:-- --:--:-- --:--:--  3090\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100  305M  100  305M    0     0   128M      0  0:00:02  0:00:02 --:--:--  145M\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PBjYNGD4ER_4"
      },
      "source": [
        "# Write YOLOR Configuration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cy8NlkoKg9lC"
      },
      "source": [
        "import yaml\n",
        "with open(dataset.location + \"/data.yaml\") as f:\n",
        "    dataMap = yaml.safe_load(f)\n",
        "\n",
        "num_classes = len(dataMap['names'])\n",
        "num_filters = (num_classes + 5) * 3\n",
        "from IPython.core.magic import register_line_cell_magic\n",
        "\n",
        "@register_line_cell_magic\n",
        "def writetemplate(line, cell):\n",
        "    with open(line, 'w') as f:\n",
        "        f.write(cell.format(**globals()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2XOWgwAg5kV"
      },
      "source": [
        "%%writetemplate /content/yolor/cfg/yolor_p6.cfg\n",
        "\n",
        "[net]\n",
        "batch=64\n",
        "subdivisions=8\n",
        "width=1280\n",
        "height=1280\n",
        "channels=3\n",
        "momentum=0.949\n",
        "decay=0.0005\n",
        "angle=0\n",
        "saturation = 1.5\n",
        "exposure = 1.5\n",
        "hue=.1\n",
        "\n",
        "learning_rate=0.00261\n",
        "burn_in=1000\n",
        "max_batches = 500500\n",
        "policy=steps\n",
        "steps=400000,450000\n",
        "scales=.1,.1\n",
        "\n",
        "mosaic=1\n",
        "\n",
        "\n",
        "# ============ Backbone ============ #\n",
        "\n",
        "# Stem \n",
        "\n",
        "# P1\n",
        "\n",
        "# Downsample\n",
        "\n",
        "# 0\n",
        "[reorg]\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=64\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "\n",
        "# P2\n",
        "\n",
        "# Downsample\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=3\n",
        "stride=2\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "# Split\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=64\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[route]\n",
        "layers = -2\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=64\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "# Residual Block\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=64\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=64\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[shortcut]\n",
        "from=-3\n",
        "activation=linear\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=64\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=64\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[shortcut]\n",
        "from=-3\n",
        "activation=linear\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=64\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=64\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[shortcut]\n",
        "from=-3\n",
        "activation=linear\n",
        "\n",
        "# Transition first\n",
        "#\n",
        "#[convolutional]\n",
        "#batch_normalize=1\n",
        "#filters=64\n",
        "#size=1\n",
        "#stride=1\n",
        "#pad=1\n",
        "#activation=silu\n",
        "\n",
        "# Merge [-1, -(3k+3)]\n",
        "\n",
        "[route]\n",
        "layers = -1,-12\n",
        "\n",
        "# Transition last\n",
        "\n",
        "# 16 (previous+6+3k)\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "\n",
        "# P3\n",
        "\n",
        "# Downsample\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=256\n",
        "size=3\n",
        "stride=2\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "# Split\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[route]\n",
        "layers = -2\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "# Residual Block\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[shortcut]\n",
        "from=-3\n",
        "activation=linear\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[shortcut]\n",
        "from=-3\n",
        "activation=linear\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[shortcut]\n",
        "from=-3\n",
        "activation=linear\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[shortcut]\n",
        "from=-3\n",
        "activation=linear\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[shortcut]\n",
        "from=-3\n",
        "activation=linear\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[shortcut]\n",
        "from=-3\n",
        "activation=linear\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[shortcut]\n",
        "from=-3\n",
        "activation=linear\n",
        "\n",
        "# Transition first\n",
        "#\n",
        "#[convolutional]\n",
        "#batch_normalize=1\n",
        "#filters=128\n",
        "#size=1\n",
        "#stride=1\n",
        "#pad=1\n",
        "#activation=silu\n",
        "\n",
        "# Merge [-1, -(3k+3)]\n",
        "\n",
        "[route]\n",
        "layers = -1,-24\n",
        "\n",
        "# Transition last\n",
        "\n",
        "# 43 (previous+6+3k)\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=256\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "\n",
        "# P4\n",
        "\n",
        "# Downsample\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=384\n",
        "size=3\n",
        "stride=2\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "# Split\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=192\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[route]\n",
        "layers = -2\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=192\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "# Residual Block\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=192\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=192\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[shortcut]\n",
        "from=-3\n",
        "activation=linear\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=192\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=192\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[shortcut]\n",
        "from=-3\n",
        "activation=linear\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=192\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=192\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[shortcut]\n",
        "from=-3\n",
        "activation=linear\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=192\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=192\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[shortcut]\n",
        "from=-3\n",
        "activation=linear\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=192\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=192\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[shortcut]\n",
        "from=-3\n",
        "activation=linear\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=192\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=192\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[shortcut]\n",
        "from=-3\n",
        "activation=linear\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=192\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=192\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[shortcut]\n",
        "from=-3\n",
        "activation=linear\n",
        "\n",
        "# Transition first\n",
        "#\n",
        "#[convolutional]\n",
        "#batch_normalize=1\n",
        "#filters=192\n",
        "#size=1\n",
        "#stride=1\n",
        "#pad=1\n",
        "#activation=silu\n",
        "\n",
        "# Merge [-1, -(3k+3)]\n",
        "\n",
        "[route]\n",
        "layers = -1,-24\n",
        "\n",
        "# Transition last\n",
        "\n",
        "# 70 (previous+6+3k)\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=384\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "\n",
        "# P5\n",
        "\n",
        "# Downsample\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=512\n",
        "size=3\n",
        "stride=2\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "# Split\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=256\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[route]\n",
        "layers = -2\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=256\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "# Residual Block\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=256\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=256\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[shortcut]\n",
        "from=-3\n",
        "activation=linear\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=256\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=256\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[shortcut]\n",
        "from=-3\n",
        "activation=linear\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=256\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=256\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[shortcut]\n",
        "from=-3\n",
        "activation=linear\n",
        "\n",
        "# Transition first\n",
        "#\n",
        "#[convolutional]\n",
        "#batch_normalize=1\n",
        "#filters=256\n",
        "#size=1\n",
        "#stride=1\n",
        "#pad=1\n",
        "#activation=silu\n",
        "\n",
        "# Merge [-1, -(3k+3)]\n",
        "\n",
        "[route]\n",
        "layers = -1,-12\n",
        "\n",
        "# Transition last\n",
        "\n",
        "# 85 (previous+6+3k)\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=512\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "\n",
        "# P6\n",
        "\n",
        "# Downsample\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=640\n",
        "size=3\n",
        "stride=2\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "# Split\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=320\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[route]\n",
        "layers = -2\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=320\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "# Residual Block\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=320\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=320\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[shortcut]\n",
        "from=-3\n",
        "activation=linear\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=320\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=320\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[shortcut]\n",
        "from=-3\n",
        "activation=linear\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=320\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=320\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[shortcut]\n",
        "from=-3\n",
        "activation=linear\n",
        "\n",
        "# Transition first\n",
        "#\n",
        "#[convolutional]\n",
        "#batch_normalize=1\n",
        "#filters=320\n",
        "#size=1\n",
        "#stride=1\n",
        "#pad=1\n",
        "#activation=silu\n",
        "\n",
        "# Merge [-1, -(3k+3)]\n",
        "\n",
        "[route]\n",
        "layers = -1,-12\n",
        "\n",
        "# Transition last\n",
        "\n",
        "# 100 (previous+6+3k)\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=640\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "# ============ End of Backbone ============ #\n",
        "\n",
        "# ============ Neck ============ #\n",
        "\n",
        "# CSPSPP\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=320\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[route]\n",
        "layers = -2\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=320\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "filters=320\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=320\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "### SPP ###\n",
        "[maxpool]\n",
        "stride=1\n",
        "size=5\n",
        "\n",
        "[route]\n",
        "layers=-2\n",
        "\n",
        "[maxpool]\n",
        "stride=1\n",
        "size=9\n",
        "\n",
        "[route]\n",
        "layers=-4\n",
        "\n",
        "[maxpool]\n",
        "stride=1\n",
        "size=13\n",
        "\n",
        "[route]\n",
        "layers=-1,-3,-5,-6\n",
        "### End SPP ###\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=320\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "filters=320\n",
        "activation=silu\n",
        "\n",
        "[route]\n",
        "layers = -1, -13\n",
        "\n",
        "# 115 (previous+6+5+2k)\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=320\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "# End of CSPSPP\n",
        "\n",
        "\n",
        "# FPN-5\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=256\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[upsample]\n",
        "stride=2\n",
        "\n",
        "[route]\n",
        "layers = 85\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=256\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[route]\n",
        "layers = -1, -3\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=256\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "# Split\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=256\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[route]\n",
        "layers = -2\n",
        "\n",
        "# Plain Block\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=256\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "filters=256\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=256\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "filters=256\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=256\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "filters=256\n",
        "activation=silu\n",
        "\n",
        "# Merge [-1, -(2k+2)]\n",
        "\n",
        "[route]\n",
        "layers = -1, -8\n",
        "\n",
        "# Transition last\n",
        "\n",
        "# 131 (previous+6+4+2k)\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=256\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "\n",
        "# FPN-4\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=192\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[upsample]\n",
        "stride=2\n",
        "\n",
        "[route]\n",
        "layers = 70\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=192\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[route]\n",
        "layers = -1, -3\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=192\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "# Split\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=192\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[route]\n",
        "layers = -2\n",
        "\n",
        "# Plain Block\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=192\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "filters=192\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=192\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "filters=192\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=192\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "filters=192\n",
        "activation=silu\n",
        "\n",
        "# Merge [-1, -(2k+2)]\n",
        "\n",
        "[route]\n",
        "layers = -1, -8\n",
        "\n",
        "# Transition last\n",
        "\n",
        "# 147 (previous+6+4+2k)\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=192\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "\n",
        "# FPN-3\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[upsample]\n",
        "stride=2\n",
        "\n",
        "[route]\n",
        "layers = 43\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[route]\n",
        "layers = -1, -3\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "# Split\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[route]\n",
        "layers = -2\n",
        "\n",
        "# Plain Block\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "filters=128\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "filters=128\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "filters=128\n",
        "activation=silu\n",
        "\n",
        "# Merge [-1, -(2k+2)]\n",
        "\n",
        "[route]\n",
        "layers = -1, -8\n",
        "\n",
        "# Transition last\n",
        "\n",
        "# 163 (previous+6+4+2k)\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "\n",
        "# PAN-4\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "size=3\n",
        "stride=2\n",
        "pad=1\n",
        "filters=192\n",
        "activation=silu\n",
        "\n",
        "[route]\n",
        "layers = -1, 147\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=192\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "# Split\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=192\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[route]\n",
        "layers = -2\n",
        "\n",
        "# Plain Block\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=192\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "filters=192\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=192\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "filters=192\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=192\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "filters=192\n",
        "activation=silu\n",
        "\n",
        "[route]\n",
        "layers = -1,-8\n",
        "\n",
        "# Transition last\n",
        "\n",
        "# 176 (previous+3+4+2k)\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=192\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "\n",
        "# PAN-5\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "size=3\n",
        "stride=2\n",
        "pad=1\n",
        "filters=256\n",
        "activation=silu\n",
        "\n",
        "[route]\n",
        "layers = -1, 131\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=256\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "# Split\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=256\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[route]\n",
        "layers = -2\n",
        "\n",
        "# Plain Block\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=256\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "filters=256\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=256\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "filters=256\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=256\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "filters=256\n",
        "activation=silu\n",
        "\n",
        "[route]\n",
        "layers = -1,-8\n",
        "\n",
        "# Transition last\n",
        "\n",
        "# 189 (previous+3+4+2k)\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=256\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "\n",
        "# PAN-6\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "size=3\n",
        "stride=2\n",
        "pad=1\n",
        "filters=320\n",
        "activation=silu\n",
        "\n",
        "[route]\n",
        "layers = -1, 115\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=320\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "# Split\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=320\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[route]\n",
        "layers = -2\n",
        "\n",
        "# Plain Block\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=320\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "filters=320\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=320\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "filters=320\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=320\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "filters=320\n",
        "activation=silu\n",
        "\n",
        "[route]\n",
        "layers = -1,-8\n",
        "\n",
        "# Transition last\n",
        "\n",
        "# 202 (previous+3+4+2k)\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=320\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "# ============ End of Neck ============ #\n",
        "\n",
        "# 203\n",
        "[implicit_add]\n",
        "filters=256\n",
        "\n",
        "# 204\n",
        "[implicit_add]\n",
        "filters=384\n",
        "\n",
        "# 205\n",
        "[implicit_add]\n",
        "filters=512\n",
        "\n",
        "# 206\n",
        "[implicit_add]\n",
        "filters=640\n",
        "\n",
        "# 207\n",
        "[implicit_mul]\n",
        "filters={num_filters}\n",
        "\n",
        "# 208\n",
        "[implicit_mul]\n",
        "filters={num_filters}\n",
        "\n",
        "# 209\n",
        "[implicit_mul]\n",
        "filters={num_filters}\n",
        "\n",
        "# 210\n",
        "[implicit_mul]\n",
        "filters={num_filters}\n",
        "\n",
        "# ============ Head ============ #\n",
        "\n",
        "# YOLO-3\n",
        "\n",
        "[route]\n",
        "layers = 163\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "filters=256\n",
        "activation=silu\n",
        "\n",
        "[shift_channels]\n",
        "from=203\n",
        "\n",
        "[convolutional]\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "filters={num_filters}\n",
        "activation=linear\n",
        "\n",
        "[control_channels]\n",
        "from=207\n",
        "\n",
        "[yolo]\n",
        "mask = 0,1,2\n",
        "anchors = 19,27,  44,40,  38,94,  96,68,  86,152,  180,137,  140,301,  303,264,  238,542,  436,615,  739,380,  925,792\n",
        "classes={num_classes}\n",
        "num=12\n",
        "jitter=.3\n",
        "ignore_thresh = .7\n",
        "truth_thresh = 1\n",
        "random=1\n",
        "scale_x_y = 1.05\n",
        "iou_thresh=0.213\n",
        "cls_normalizer=1.0\n",
        "iou_normalizer=0.07\n",
        "iou_loss=ciou\n",
        "nms_kind=greedynms\n",
        "beta_nms=0.6\n",
        "\n",
        "\n",
        "# YOLO-4\n",
        "\n",
        "[route]\n",
        "layers = 176\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "filters=384\n",
        "activation=silu\n",
        "\n",
        "[shift_channels]\n",
        "from=204\n",
        "\n",
        "[convolutional]\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "filters={num_filters}\n",
        "activation=linear\n",
        "\n",
        "[control_channels]\n",
        "from=208\n",
        "\n",
        "[yolo]\n",
        "mask = 3,4,5\n",
        "anchors = 19,27,  44,40,  38,94,  96,68,  86,152,  180,137,  140,301,  303,264,  238,542,  436,615,  739,380,  925,792\n",
        "classes={num_classes}\n",
        "num=12\n",
        "jitter=.3\n",
        "ignore_thresh = .7\n",
        "truth_thresh = 1\n",
        "random=1\n",
        "scale_x_y = 1.05\n",
        "iou_thresh=0.213\n",
        "cls_normalizer=1.0\n",
        "iou_normalizer=0.07\n",
        "iou_loss=ciou\n",
        "nms_kind=greedynms\n",
        "beta_nms=0.6\n",
        "\n",
        "\n",
        "# YOLO-5\n",
        "\n",
        "[route]\n",
        "layers = 189\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "filters=512\n",
        "activation=silu\n",
        "\n",
        "[shift_channels]\n",
        "from=205\n",
        "\n",
        "[convolutional]\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "filters={num_filters}\n",
        "activation=linear\n",
        "\n",
        "[control_channels]\n",
        "from=209\n",
        "\n",
        "[yolo]\n",
        "mask = 6,7,8\n",
        "anchors = 19,27,  44,40,  38,94,  96,68,  86,152,  180,137,  140,301,  303,264,  238,542,  436,615,  739,380,  925,792\n",
        "classes={num_classes}\n",
        "num=12\n",
        "jitter=.3\n",
        "ignore_thresh = .7\n",
        "truth_thresh = 1\n",
        "random=1\n",
        "scale_x_y = 1.05\n",
        "iou_thresh=0.213\n",
        "cls_normalizer=1.0\n",
        "iou_normalizer=0.07\n",
        "iou_loss=ciou\n",
        "nms_kind=greedynms\n",
        "beta_nms=0.6\n",
        "\n",
        "\n",
        "# YOLO-6\n",
        "\n",
        "[route]\n",
        "layers = 202\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "filters=640\n",
        "activation=silu\n",
        "\n",
        "[shift_channels]\n",
        "from=206\n",
        "\n",
        "[convolutional]\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "filters={num_filters}\n",
        "activation=linear\n",
        "\n",
        "[control_channels]\n",
        "from=210\n",
        "\n",
        "[yolo]\n",
        "mask = 9,10,11\n",
        "anchors = 19,27,  44,40,  38,94,  96,68,  86,152,  180,137,  140,301,  303,264,  238,542,  436,615,  739,380,  925,792\n",
        "classes={num_classes}\n",
        "num=12\n",
        "jitter=.3\n",
        "ignore_thresh = .7\n",
        "truth_thresh = 1\n",
        "random=1\n",
        "scale_x_y = 1.05\n",
        "iou_thresh=0.213\n",
        "cls_normalizer=1.0\n",
        "iou_normalizer=0.07\n",
        "iou_loss=ciou\n",
        "nms_kind=greedynms\n",
        "beta_nms=0.6\n",
        "\n",
        "# ============ End of Head ============ #"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZLldIGy2ERgB",
        "outputId": "f0b6afb9-28a8-4c23-86d7-54605ecf7b20"
      },
      "source": [
        "%cat /content/yolor/cfg/yolor_p6.cfg"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[net]\n",
            "batch=64\n",
            "subdivisions=8\n",
            "width=1280\n",
            "height=1280\n",
            "channels=3\n",
            "momentum=0.949\n",
            "decay=0.0005\n",
            "angle=0\n",
            "saturation = 1.5\n",
            "exposure = 1.5\n",
            "hue=.1\n",
            "\n",
            "learning_rate=0.00261\n",
            "burn_in=1000\n",
            "max_batches = 500500\n",
            "policy=steps\n",
            "steps=400000,450000\n",
            "scales=.1,.1\n",
            "\n",
            "mosaic=1\n",
            "\n",
            "\n",
            "# ============ Backbone ============ #\n",
            "\n",
            "# Stem \n",
            "\n",
            "# P1\n",
            "\n",
            "# Downsample\n",
            "\n",
            "# 0\n",
            "[reorg]\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=64\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "\n",
            "# P2\n",
            "\n",
            "# Downsample\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=128\n",
            "size=3\n",
            "stride=2\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "# Split\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=64\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[route]\n",
            "layers = -2\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=64\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "# Residual Block\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=64\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=64\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[shortcut]\n",
            "from=-3\n",
            "activation=linear\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=64\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=64\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[shortcut]\n",
            "from=-3\n",
            "activation=linear\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=64\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=64\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[shortcut]\n",
            "from=-3\n",
            "activation=linear\n",
            "\n",
            "# Transition first\n",
            "#\n",
            "#[convolutional]\n",
            "#batch_normalize=1\n",
            "#filters=64\n",
            "#size=1\n",
            "#stride=1\n",
            "#pad=1\n",
            "#activation=silu\n",
            "\n",
            "# Merge [-1, -(3k+3)]\n",
            "\n",
            "[route]\n",
            "layers = -1,-12\n",
            "\n",
            "# Transition last\n",
            "\n",
            "# 16 (previous+6+3k)\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=128\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "\n",
            "# P3\n",
            "\n",
            "# Downsample\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=256\n",
            "size=3\n",
            "stride=2\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "# Split\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=128\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[route]\n",
            "layers = -2\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=128\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "# Residual Block\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=128\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=128\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[shortcut]\n",
            "from=-3\n",
            "activation=linear\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=128\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=128\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[shortcut]\n",
            "from=-3\n",
            "activation=linear\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=128\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=128\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[shortcut]\n",
            "from=-3\n",
            "activation=linear\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=128\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=128\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[shortcut]\n",
            "from=-3\n",
            "activation=linear\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=128\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=128\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[shortcut]\n",
            "from=-3\n",
            "activation=linear\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=128\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=128\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[shortcut]\n",
            "from=-3\n",
            "activation=linear\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=128\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=128\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[shortcut]\n",
            "from=-3\n",
            "activation=linear\n",
            "\n",
            "# Transition first\n",
            "#\n",
            "#[convolutional]\n",
            "#batch_normalize=1\n",
            "#filters=128\n",
            "#size=1\n",
            "#stride=1\n",
            "#pad=1\n",
            "#activation=silu\n",
            "\n",
            "# Merge [-1, -(3k+3)]\n",
            "\n",
            "[route]\n",
            "layers = -1,-24\n",
            "\n",
            "# Transition last\n",
            "\n",
            "# 43 (previous+6+3k)\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=256\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "\n",
            "# P4\n",
            "\n",
            "# Downsample\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=384\n",
            "size=3\n",
            "stride=2\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "# Split\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=192\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[route]\n",
            "layers = -2\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=192\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "# Residual Block\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=192\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=192\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[shortcut]\n",
            "from=-3\n",
            "activation=linear\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=192\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=192\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[shortcut]\n",
            "from=-3\n",
            "activation=linear\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=192\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=192\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[shortcut]\n",
            "from=-3\n",
            "activation=linear\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=192\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=192\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[shortcut]\n",
            "from=-3\n",
            "activation=linear\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=192\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=192\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[shortcut]\n",
            "from=-3\n",
            "activation=linear\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=192\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=192\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[shortcut]\n",
            "from=-3\n",
            "activation=linear\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=192\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=192\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[shortcut]\n",
            "from=-3\n",
            "activation=linear\n",
            "\n",
            "# Transition first\n",
            "#\n",
            "#[convolutional]\n",
            "#batch_normalize=1\n",
            "#filters=192\n",
            "#size=1\n",
            "#stride=1\n",
            "#pad=1\n",
            "#activation=silu\n",
            "\n",
            "# Merge [-1, -(3k+3)]\n",
            "\n",
            "[route]\n",
            "layers = -1,-24\n",
            "\n",
            "# Transition last\n",
            "\n",
            "# 70 (previous+6+3k)\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=384\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "\n",
            "# P5\n",
            "\n",
            "# Downsample\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=512\n",
            "size=3\n",
            "stride=2\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "# Split\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=256\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[route]\n",
            "layers = -2\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=256\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "# Residual Block\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=256\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=256\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[shortcut]\n",
            "from=-3\n",
            "activation=linear\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=256\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=256\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[shortcut]\n",
            "from=-3\n",
            "activation=linear\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=256\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=256\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[shortcut]\n",
            "from=-3\n",
            "activation=linear\n",
            "\n",
            "# Transition first\n",
            "#\n",
            "#[convolutional]\n",
            "#batch_normalize=1\n",
            "#filters=256\n",
            "#size=1\n",
            "#stride=1\n",
            "#pad=1\n",
            "#activation=silu\n",
            "\n",
            "# Merge [-1, -(3k+3)]\n",
            "\n",
            "[route]\n",
            "layers = -1,-12\n",
            "\n",
            "# Transition last\n",
            "\n",
            "# 85 (previous+6+3k)\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=512\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "\n",
            "# P6\n",
            "\n",
            "# Downsample\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=640\n",
            "size=3\n",
            "stride=2\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "# Split\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=320\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[route]\n",
            "layers = -2\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=320\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "# Residual Block\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=320\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=320\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[shortcut]\n",
            "from=-3\n",
            "activation=linear\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=320\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=320\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[shortcut]\n",
            "from=-3\n",
            "activation=linear\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=320\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=320\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[shortcut]\n",
            "from=-3\n",
            "activation=linear\n",
            "\n",
            "# Transition first\n",
            "#\n",
            "#[convolutional]\n",
            "#batch_normalize=1\n",
            "#filters=320\n",
            "#size=1\n",
            "#stride=1\n",
            "#pad=1\n",
            "#activation=silu\n",
            "\n",
            "# Merge [-1, -(3k+3)]\n",
            "\n",
            "[route]\n",
            "layers = -1,-12\n",
            "\n",
            "# Transition last\n",
            "\n",
            "# 100 (previous+6+3k)\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=640\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "# ============ End of Backbone ============ #\n",
            "\n",
            "# ============ Neck ============ #\n",
            "\n",
            "# CSPSPP\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=320\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[route]\n",
            "layers = -2\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=320\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "filters=320\n",
            "activation=silu\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=320\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "### SPP ###\n",
            "[maxpool]\n",
            "stride=1\n",
            "size=5\n",
            "\n",
            "[route]\n",
            "layers=-2\n",
            "\n",
            "[maxpool]\n",
            "stride=1\n",
            "size=9\n",
            "\n",
            "[route]\n",
            "layers=-4\n",
            "\n",
            "[maxpool]\n",
            "stride=1\n",
            "size=13\n",
            "\n",
            "[route]\n",
            "layers=-1,-3,-5,-6\n",
            "### End SPP ###\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=320\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "filters=320\n",
            "activation=silu\n",
            "\n",
            "[route]\n",
            "layers = -1, -13\n",
            "\n",
            "# 115 (previous+6+5+2k)\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=320\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "# End of CSPSPP\n",
            "\n",
            "\n",
            "# FPN-5\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=256\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[upsample]\n",
            "stride=2\n",
            "\n",
            "[route]\n",
            "layers = 85\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=256\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[route]\n",
            "layers = -1, -3\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=256\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "# Split\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=256\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[route]\n",
            "layers = -2\n",
            "\n",
            "# Plain Block\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=256\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "filters=256\n",
            "activation=silu\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=256\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "filters=256\n",
            "activation=silu\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=256\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "filters=256\n",
            "activation=silu\n",
            "\n",
            "# Merge [-1, -(2k+2)]\n",
            "\n",
            "[route]\n",
            "layers = -1, -8\n",
            "\n",
            "# Transition last\n",
            "\n",
            "# 131 (previous+6+4+2k)\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=256\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "\n",
            "# FPN-4\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=192\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[upsample]\n",
            "stride=2\n",
            "\n",
            "[route]\n",
            "layers = 70\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=192\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[route]\n",
            "layers = -1, -3\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=192\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "# Split\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=192\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[route]\n",
            "layers = -2\n",
            "\n",
            "# Plain Block\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=192\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "filters=192\n",
            "activation=silu\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=192\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "filters=192\n",
            "activation=silu\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=192\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "filters=192\n",
            "activation=silu\n",
            "\n",
            "# Merge [-1, -(2k+2)]\n",
            "\n",
            "[route]\n",
            "layers = -1, -8\n",
            "\n",
            "# Transition last\n",
            "\n",
            "# 147 (previous+6+4+2k)\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=192\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "\n",
            "# FPN-3\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=128\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[upsample]\n",
            "stride=2\n",
            "\n",
            "[route]\n",
            "layers = 43\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=128\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[route]\n",
            "layers = -1, -3\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=128\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "# Split\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=128\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[route]\n",
            "layers = -2\n",
            "\n",
            "# Plain Block\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=128\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "filters=128\n",
            "activation=silu\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=128\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "filters=128\n",
            "activation=silu\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=128\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "filters=128\n",
            "activation=silu\n",
            "\n",
            "# Merge [-1, -(2k+2)]\n",
            "\n",
            "[route]\n",
            "layers = -1, -8\n",
            "\n",
            "# Transition last\n",
            "\n",
            "# 163 (previous+6+4+2k)\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=128\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "\n",
            "# PAN-4\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "size=3\n",
            "stride=2\n",
            "pad=1\n",
            "filters=192\n",
            "activation=silu\n",
            "\n",
            "[route]\n",
            "layers = -1, 147\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=192\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "# Split\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=192\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[route]\n",
            "layers = -2\n",
            "\n",
            "# Plain Block\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=192\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "filters=192\n",
            "activation=silu\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=192\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "filters=192\n",
            "activation=silu\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=192\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "filters=192\n",
            "activation=silu\n",
            "\n",
            "[route]\n",
            "layers = -1,-8\n",
            "\n",
            "# Transition last\n",
            "\n",
            "# 176 (previous+3+4+2k)\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=192\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "\n",
            "# PAN-5\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "size=3\n",
            "stride=2\n",
            "pad=1\n",
            "filters=256\n",
            "activation=silu\n",
            "\n",
            "[route]\n",
            "layers = -1, 131\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=256\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "# Split\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=256\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[route]\n",
            "layers = -2\n",
            "\n",
            "# Plain Block\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=256\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "filters=256\n",
            "activation=silu\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=256\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "filters=256\n",
            "activation=silu\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=256\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "filters=256\n",
            "activation=silu\n",
            "\n",
            "[route]\n",
            "layers = -1,-8\n",
            "\n",
            "# Transition last\n",
            "\n",
            "# 189 (previous+3+4+2k)\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=256\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "\n",
            "# PAN-6\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "size=3\n",
            "stride=2\n",
            "pad=1\n",
            "filters=320\n",
            "activation=silu\n",
            "\n",
            "[route]\n",
            "layers = -1, 115\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=320\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "# Split\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=320\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[route]\n",
            "layers = -2\n",
            "\n",
            "# Plain Block\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=320\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "filters=320\n",
            "activation=silu\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=320\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "filters=320\n",
            "activation=silu\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=320\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "filters=320\n",
            "activation=silu\n",
            "\n",
            "[route]\n",
            "layers = -1,-8\n",
            "\n",
            "# Transition last\n",
            "\n",
            "# 202 (previous+3+4+2k)\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=320\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "# ============ End of Neck ============ #\n",
            "\n",
            "# 203\n",
            "[implicit_add]\n",
            "filters=256\n",
            "\n",
            "# 204\n",
            "[implicit_add]\n",
            "filters=384\n",
            "\n",
            "# 205\n",
            "[implicit_add]\n",
            "filters=512\n",
            "\n",
            "# 206\n",
            "[implicit_add]\n",
            "filters=640\n",
            "\n",
            "# 207\n",
            "[implicit_mul]\n",
            "filters=18\n",
            "\n",
            "# 208\n",
            "[implicit_mul]\n",
            "filters=18\n",
            "\n",
            "# 209\n",
            "[implicit_mul]\n",
            "filters=18\n",
            "\n",
            "# 210\n",
            "[implicit_mul]\n",
            "filters=18\n",
            "\n",
            "# ============ Head ============ #\n",
            "\n",
            "# YOLO-3\n",
            "\n",
            "[route]\n",
            "layers = 163\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "filters=256\n",
            "activation=silu\n",
            "\n",
            "[shift_channels]\n",
            "from=203\n",
            "\n",
            "[convolutional]\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "filters=18\n",
            "activation=linear\n",
            "\n",
            "[control_channels]\n",
            "from=207\n",
            "\n",
            "[yolo]\n",
            "mask = 0,1,2\n",
            "anchors = 19,27,  44,40,  38,94,  96,68,  86,152,  180,137,  140,301,  303,264,  238,542,  436,615,  739,380,  925,792\n",
            "classes=1\n",
            "num=12\n",
            "jitter=.3\n",
            "ignore_thresh = .7\n",
            "truth_thresh = 1\n",
            "random=1\n",
            "scale_x_y = 1.05\n",
            "iou_thresh=0.213\n",
            "cls_normalizer=1.0\n",
            "iou_normalizer=0.07\n",
            "iou_loss=ciou\n",
            "nms_kind=greedynms\n",
            "beta_nms=0.6\n",
            "\n",
            "\n",
            "# YOLO-4\n",
            "\n",
            "[route]\n",
            "layers = 176\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "filters=384\n",
            "activation=silu\n",
            "\n",
            "[shift_channels]\n",
            "from=204\n",
            "\n",
            "[convolutional]\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "filters=18\n",
            "activation=linear\n",
            "\n",
            "[control_channels]\n",
            "from=208\n",
            "\n",
            "[yolo]\n",
            "mask = 3,4,5\n",
            "anchors = 19,27,  44,40,  38,94,  96,68,  86,152,  180,137,  140,301,  303,264,  238,542,  436,615,  739,380,  925,792\n",
            "classes=1\n",
            "num=12\n",
            "jitter=.3\n",
            "ignore_thresh = .7\n",
            "truth_thresh = 1\n",
            "random=1\n",
            "scale_x_y = 1.05\n",
            "iou_thresh=0.213\n",
            "cls_normalizer=1.0\n",
            "iou_normalizer=0.07\n",
            "iou_loss=ciou\n",
            "nms_kind=greedynms\n",
            "beta_nms=0.6\n",
            "\n",
            "\n",
            "# YOLO-5\n",
            "\n",
            "[route]\n",
            "layers = 189\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "filters=512\n",
            "activation=silu\n",
            "\n",
            "[shift_channels]\n",
            "from=205\n",
            "\n",
            "[convolutional]\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "filters=18\n",
            "activation=linear\n",
            "\n",
            "[control_channels]\n",
            "from=209\n",
            "\n",
            "[yolo]\n",
            "mask = 6,7,8\n",
            "anchors = 19,27,  44,40,  38,94,  96,68,  86,152,  180,137,  140,301,  303,264,  238,542,  436,615,  739,380,  925,792\n",
            "classes=1\n",
            "num=12\n",
            "jitter=.3\n",
            "ignore_thresh = .7\n",
            "truth_thresh = 1\n",
            "random=1\n",
            "scale_x_y = 1.05\n",
            "iou_thresh=0.213\n",
            "cls_normalizer=1.0\n",
            "iou_normalizer=0.07\n",
            "iou_loss=ciou\n",
            "nms_kind=greedynms\n",
            "beta_nms=0.6\n",
            "\n",
            "\n",
            "# YOLO-6\n",
            "\n",
            "[route]\n",
            "layers = 202\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "filters=640\n",
            "activation=silu\n",
            "\n",
            "[shift_channels]\n",
            "from=206\n",
            "\n",
            "[convolutional]\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "filters=18\n",
            "activation=linear\n",
            "\n",
            "[control_channels]\n",
            "from=210\n",
            "\n",
            "[yolo]\n",
            "mask = 9,10,11\n",
            "anchors = 19,27,  44,40,  38,94,  96,68,  86,152,  180,137,  140,301,  303,264,  238,542,  436,615,  739,380,  925,792\n",
            "classes=1\n",
            "num=12\n",
            "jitter=.3\n",
            "ignore_thresh = .7\n",
            "truth_thresh = 1\n",
            "random=1\n",
            "scale_x_y = 1.05\n",
            "iou_thresh=0.213\n",
            "cls_normalizer=1.0\n",
            "iou_normalizer=0.07\n",
            "iou_loss=ciou\n",
            "nms_kind=greedynms\n",
            "beta_nms=0.6\n",
            "\n",
            "# ============ End of Head ============ #"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o6t4nA4wWr8v"
      },
      "source": [
        "# Train Custom YOLOR Detector\n",
        "\n",
        "### Next, we'll fire off training!\n",
        "\n",
        "\n",
        "Here, we are able to pass a number of arguments:\n",
        "- **img:** define input image size\n",
        "- **batch:** determine batch size\n",
        "- **epochs:** define the number of training epochs. (Note: often, 3000+ are common here!)\n",
        "- **data:** set the path to our yaml file\n",
        "- **cfg:** specify our model configuration\n",
        "- **weights:** specify a custom path to weights. (Note: We can specify the pretrained weights we downloaded up above with the shell script)\n",
        "- **name:** result names\n",
        "-**hyp:** Define the hyperparamters for training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OqG-CDJZEiw2",
        "outputId": "29c11518-03d1-4214-b523-ddb46b322925"
      },
      "source": [
        "%cd /content/yolor\n",
        "!python train.py --batch-size 32 --img 416 416 --data {dataset.location}/data.yaml --cfg cfg/yolor_p6.cfg --weights '/content/yolor/yolor_p6.pt' --device 0 --name yolor_p6 --hyp '/content/yolor/data/hyp.scratch.1280.yaml' --epochs 100"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/yolor\n",
            "Using torch 1.7.0 CUDA:0 (Tesla K80, 11441MB)\n",
            "\n",
            "Namespace(adam=False, batch_size=32, bucket='', cache_images=False, cfg='cfg/yolor_p6.cfg', data='/content/yolor/Kvasir-SEG-1/data.yaml', device='0', epochs=100, evolve=False, exist_ok=False, global_rank=-1, hyp='/content/yolor/data/hyp.scratch.1280.yaml', image_weights=False, img_size=[416, 416], local_rank=-1, log_imgs=16, multi_scale=False, name='yolor_p6', noautoanchor=False, nosave=False, notest=False, project='runs/train', rect=False, resume=False, save_dir='runs/train/yolor_p6', single_cls=False, sync_bn=False, total_batch_size=32, weights='/content/yolor/yolor_p6.pt', workers=8, world_size=1)\n",
            "Start Tensorboard with \"tensorboard --logdir runs/train\", view at http://localhost:6006/\n",
            "Hyperparameters {'lr0': 0.01, 'lrf': 0.2, 'momentum': 0.937, 'weight_decay': 0.0005, 'warmup_epochs': 3.0, 'warmup_momentum': 0.8, 'warmup_bias_lr': 0.1, 'box': 0.05, 'cls': 0.5, 'cls_pw': 1.0, 'obj': 1.0, 'obj_pw': 1.0, 'iou_t': 0.2, 'anchor_t': 4.0, 'fl_gamma': 0.0, 'hsv_h': 0.015, 'hsv_s': 0.7, 'hsv_v': 0.4, 'degrees': 0.0, 'translate': 0.5, 'scale': 0.5, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.5, 'mosaic': 1.0, 'mixup': 0.0}\n",
            "Model Summary: 665 layers, 36838416 parameters, 36838416 gradients, 80.364773200 GFLOPS\n",
            "Transferred 850/862 items from /content/yolor/yolor_p6.pt\n",
            "Optimizer groups: 145 .bias, 145 conv.weight, 149 other\n",
            "WARNING: --img-size 416 must be multiple of max stride 64, updating to 448\n",
            "WARNING: --img-size 416 must be multiple of max stride 64, updating to 448\n",
            "Scanning images: 100% 2100/2100 [00:00<00:00, 5260.71it/s]\n",
            "Scanning labels Kvasir-SEG-1/train/labels.cache3 (2100 found, 0 missing, 0 empty, 0 duplicate, for 2100 images): 2100it [00:00, 9084.97it/s]\n",
            "Scanning images: 100% 200/200 [00:00<00:00, 2615.02it/s]\n",
            "Scanning labels Kvasir-SEG-1/valid/labels.cache3 (200 found, 0 missing, 0 empty, 0 duplicate, for 200 images): 200it [00:00, 2986.55it/s]\n",
            "NumExpr defaulting to 2 threads.\n",
            "Image sizes 448 train, 448 test\n",
            "Using 2 dataloader workers\n",
            "Logging results to runs/train/yolor_p6\n",
            "Starting training for 100 epochs...\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
            "      0/99     5.98G   0.09207   0.05215         0    0.1442        35       448: 100% 66/66 [03:46<00:00,  3.43s/it]\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
            "      1/99     8.45G   0.05933   0.04764         0     0.107        43       448: 100% 66/66 [03:23<00:00,  3.09s/it]\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
            "      2/99     8.45G   0.04925    0.0407         0   0.08994        30       448: 100% 66/66 [03:22<00:00,  3.07s/it]\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
            "      3/99     8.45G   0.04512   0.03749         0   0.08261        43       448: 100% 66/66 [03:22<00:00,  3.07s/it]\n",
            "               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100% 4/4 [00:15<00:00,  3.84s/it]\n",
            "                 all         200         212       0.288       0.933       0.805       0.429\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
            "      4/99     8.43G    0.0416   0.03751         0   0.07911        38       448: 100% 66/66 [03:23<00:00,  3.08s/it]\n",
            "               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100% 4/4 [00:06<00:00,  1.54s/it]\n",
            "                 all         200         212       0.472        0.92       0.868       0.539\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
            "      5/99     8.43G   0.03755   0.03434         0   0.07188        35       448: 100% 66/66 [03:22<00:00,  3.06s/it]\n",
            "               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100% 4/4 [00:06<00:00,  1.55s/it]\n",
            "                 all         200         212       0.585       0.934       0.908       0.595\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
            "      6/99     8.43G   0.03467   0.03513         0   0.06981        33       448: 100% 66/66 [03:22<00:00,  3.06s/it]\n",
            "               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100% 4/4 [00:06<00:00,  1.54s/it]\n",
            "                 all         200         212       0.656       0.915       0.884       0.556\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
            "      7/99     8.43G   0.03555    0.0339         0   0.06945        42       448: 100% 66/66 [03:21<00:00,  3.05s/it]\n",
            "               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100% 4/4 [00:06<00:00,  1.57s/it]\n",
            "                 all         200         212       0.518        0.92       0.864       0.579\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
            "      8/99     8.43G   0.03648   0.03375         0   0.07024        47       448: 100% 66/66 [03:19<00:00,  3.03s/it]\n",
            "               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95:   0% 0/4 [00:00<?, ?it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FAbe94smXcg0"
      },
      "source": [
        "# Evaluate Custom YOLOR Detector Performance\n",
        "\n",
        "Training losses and performance metrics are saved to Tensorboard and also to a logfile defined above with the **--name** flag when we train. In our case, we named this `yolor_p6`. (If given no name, it defaults to `results.txt`.) The results file is plotted as a png after training completes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Kha-ehkX1qP"
      },
      "source": [
        "# Start tensorboard\n",
        "# Launch after you have started training\n",
        "# logs save in the folder \"runs\"\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir runs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MGnkowATX4ZS"
      },
      "source": [
        "from IPython.display import Image\n",
        "# we can also output some older school graphs if the tensor board isn't working for whatever reason... \n",
        "from utils.plots import plot_results  # plot results.txt as results.png\n",
        "Image(filename='/content/yolor/runs/train/yolor_p64/results.png', width=1000)  # view results.png"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jyp7zrtBX6wc"
      },
      "source": [
        "# first, display our ground truth data\n",
        "print(\"GROUND TRUTH TRAINING DATA:\")\n",
        "Image(filename='/content/yolor/runs/train/yolor_p6/train_batch0.jpg', width=900)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kDDz3cWgq4gQ"
      },
      "source": [
        "print(\"AUGMENTED DATA:\")\n",
        "Image(filename='/content/yolor/runs/train/yolor_p6/train_batch1.jpg', width=900)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mqYf31oCYYRn"
      },
      "source": [
        "#Run Inference  With Trained Weights\n",
        "Run inference with a pretrained checkpoint on contents of `test/images` folder downloaded from Roboflow."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QwuHFc3nYf7J"
      },
      "source": [
        "# trained weights are saved by default in our weights folder\n",
        "%ls runs/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "liYDNniHYiKq"
      },
      "source": [
        "%ls runs/train/yolor_p6/weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%pwd"
      ],
      "metadata": {
        "id": "Q7mWvRGf1AwT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLG0HPpbtpK0"
      },
      "source": [
        "# Create names file for model\n",
        "%cd /content/yolor/Kvasir-SEG-1/\n",
        "import yaml\n",
        "import ast\n",
        "with open(\"data.yaml\", 'r') as stream:\n",
        "    names = str(yaml.safe_load(stream)['names'])\n",
        "\n",
        "namesFile = open(\"../data.names\", \"w+\")\n",
        "names = ast.literal_eval(names)\n",
        "for name in names:\n",
        "  namesFile.write(name +'\\n')\n",
        "namesFile.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SfObNHTCYqih"
      },
      "source": [
        "%cd /content/yolor\n",
        "%time\n",
        "!python detect.py --weights \"runs/train/yolor_p64/weights/best_overall.pt\" --conf 0.5 --source /content/yolor/Kvasir-SEG-1/test/images/ --names /content/yolor/data.names --cfg cfg/yolor_p6.cfg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBeuZJA4s2Zh"
      },
      "source": [
        "#display inference on ALL test images\n",
        "#this looks much better with longer training above\n",
        "\n",
        "import glob\n",
        "from IPython.display import Image, display\n",
        "\n",
        "for imageName in glob.glob('/content/yolor/inference/output/*.jpg'): #assuming JPG\n",
        "    display(Image(filename=imageName))\n",
        "    print(\"\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_XUnMCThYM3W"
      },
      "source": [
        "# Export Trained Weights for Future Inference\n",
        "\n",
        "Now that you have trained your custom detector, you can export the trained weights you have made here for inference on your device elsewhere"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mP8-UrwiYP8j"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZ-zspK3YQlr"
      },
      "source": [
        "%cp /content/yolor/runs/train/yolor_p6/weights/best.pt /content/gdrive/My\\ Drive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dQrUGu9nYI-T"
      },
      "source": [
        "## Congrats!\n",
        "\n",
        "Hope you enjoyed this!\n",
        "\n",
        "--Team [Roboflow](https://roboflow.ai)"
      ]
    }
  ]
}