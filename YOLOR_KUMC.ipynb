{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pourmand1376/Polyp_detection/blob/main/YOLOR_KUMC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EtClYG2z74SY"
      },
      "source": [
        "# How to Train YOLOR on Custom Objects\n",
        "\n",
        "This tutorial is based on the [YOLOR repository](https://github.com/WongKinYiu/yolor) by [Wong Kin-Yiu](https://github.com/WongKinYiu). This notebook shows training on **your own custom objects**. Many thanks to Wong for putting this repository together - we hope that in combination with clean data management tools at Roboflow, this technologoy will become easily accessible to any developer wishing to use computer vision in their projects.\n",
        "\n",
        "### Accompanying Blog Post\n",
        "\n",
        "We recommend that you follow along in this notebook while reading the blog post on [How to Train YOLOR](blog.roboflow.com/how-to-train-yolor-on-a-custom-dataset/), concurrently.\n",
        "\n",
        "### Steps Covered in this Tutorial\n",
        "\n",
        "In this tutorial, we will walk through the steps required to train YOLOR on your custom objects. We use a [public blood cell detection dataset](https://public.roboflow.ai/object-detection/bccd), which is open source and free to use. You can also use this notebook on your own data.\n",
        "\n",
        "To train our detector we take the following steps:\n",
        "\n",
        "* Install YOLOR dependencies\n",
        "* Download custom YOLOR object detection data\n",
        "* Prepare Pre-Trained Weights for YOLOR\n",
        "* Run YOLOR training\n",
        "* Evaluate YOLOR performance\n",
        "* Visualize YOLOR training data\n",
        "* Run YOLOR inference on test images\n",
        "* Export saved YOLOR weights for future inference\n",
        "\n",
        "### **About**\n",
        "\n",
        "[Roboflow](https://roboflow.com) enables teams to deploy custom computer vision models quickly and accurately. Convert data from to annotation format, assess dataset health, preprocess, augment, and more. It's free for your first 1000 source images.\n",
        "\n",
        "**Looking for a vision model available via API without hassle? Try Roboflow Train.**\n",
        "\n",
        "![Roboflow Wordmark](https://i.imgur.com/dcLNMhV.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "icONSOTY9AmP"
      },
      "source": [
        "#Install Dependencies\n",
        "\n",
        "_(Remember to choose GPU in Runtime if not already selected. Runtime --> Change Runtime Type --> Hardware accelerator --> GPU)_"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install git-lfs\n",
        "!git lfs install"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4bx-SI0b4Hmm",
        "outputId": "207ec286-6b7b-4fd4-df7e-ffe4e5968ea6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "git-lfs is already the newest version (2.9.2-1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 24 not upgraded.\n",
            "Error: Failed to call git rev-parse --git-dir: exit status 128 \n",
            "Git LFS initialized.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6bs156q-9Fpe",
        "outputId": "390dff30-cae9-41d0-d463-a857183007bb"
      },
      "source": [
        "# clone YOLOR repository\n",
        "!git clone https://github.com/roboflow-ai/yolor\n",
        "%cd yolor \n",
        "!git reset --hard eb3ef0b7472413d6740f5cde39beb1a2f5b8b5d1"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'yolor'...\n",
            "remote: Enumerating objects: 387, done.\u001b[K\n",
            "remote: Total 387 (delta 0), reused 0 (delta 0), pack-reused 387\u001b[K\n",
            "Receiving objects: 100% (387/387), 2.97 MiB | 16.79 MiB/s, done.\n",
            "Resolving deltas: 100% (172/172), done.\n",
            "/content/yolor\n",
            "HEAD is now at eb3ef0b indentation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fy4tuOqP9efo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90c08897-f8b3-494f-8afd-bc472e2a274b"
      },
      "source": [
        "# Install necessary dependencies\n",
        "!pip install -qr requirements.txt"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement torch==1.7.0 (from versions: 1.11.0, 1.12.0, 1.12.1, 1.13.0, 1.13.1, 2.0.0, 2.0.1)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for torch==1.7.0\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w23WgLFB-TZ-",
        "outputId": "c97a1baf-c178-470c-e290-1b6ac22bbe6a"
      },
      "source": [
        "# Install Mish CUDA\n",
        "!git clone https://github.com/JunnYu/mish-cuda\n",
        "%cd mish-cuda\n",
        "!git reset --hard 6f38976064cbcc4782f4212d7c0c5f6dd5e315a8\n",
        "!python setup.py build install\n",
        "%cd .."
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'mish-cuda'...\n",
            "remote: Enumerating objects: 195, done.\u001b[K\n",
            "remote: Counting objects: 100% (88/88), done.\u001b[K\n",
            "remote: Compressing objects: 100% (75/75), done.\u001b[K\n",
            "remote: Total 195 (delta 7), reused 79 (delta 3), pack-reused 107\u001b[K\n",
            "Receiving objects: 100% (195/195), 208.77 KiB | 8.35 MiB/s, done.\n",
            "Resolving deltas: 100% (56/56), done.\n",
            "/content/yolor/mish-cuda\n",
            "HEAD is now at 6f38976 Update README.md\n",
            "/usr/local/lib/python3.10/dist-packages/setuptools/_distutils/extension.py:134: UserWarning: Unknown Extension options: 'headers'\n",
            "  warnings.warn(msg)\n",
            "running build\n",
            "running build_py\n",
            "creating build\n",
            "creating build/lib.linux-x86_64-cpython-310\n",
            "creating build/lib.linux-x86_64-cpython-310/mish_cuda\n",
            "copying src/mish_cuda/__init__.py -> build/lib.linux-x86_64-cpython-310/mish_cuda\n",
            "running egg_info\n",
            "creating src/mish_cuda.egg-info\n",
            "writing src/mish_cuda.egg-info/PKG-INFO\n",
            "writing dependency_links to src/mish_cuda.egg-info/dependency_links.txt\n",
            "writing requirements to src/mish_cuda.egg-info/requires.txt\n",
            "writing top-level names to src/mish_cuda.egg-info/top_level.txt\n",
            "writing manifest file 'src/mish_cuda.egg-info/SOURCES.txt'\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/cpp_extension.py:476: UserWarning: Attempted to use ninja as the BuildExtension backend but we could not find ninja.. Falling back to using the slow distutils backend.\n",
            "  warnings.warn(msg.format('we could not find ninja.'))\n",
            "reading manifest file 'src/mish_cuda.egg-info/SOURCES.txt'\n",
            "adding license file 'LICENSE'\n",
            "writing manifest file 'src/mish_cuda.egg-info/SOURCES.txt'\n",
            "running build_ext\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/cpp_extension.py:398: UserWarning: There are no x86_64-linux-gnu-g++ version bounds defined for CUDA version 11.8\n",
            "  warnings.warn(f'There are no {compiler_name} version bounds defined for CUDA version {cuda_str_version}')\n",
            "building 'mish_cuda._C' extension\n",
            "creating build/temp.linux-x86_64-cpython-310\n",
            "creating build/temp.linux-x86_64-cpython-310/csrc\n",
            "creating build/temp.linux-x86_64-cpython-310/csrc/cpu\n",
            "creating build/temp.linux-x86_64-cpython-310/csrc/cuda\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/usr/local/lib/python3.10/dist-packages/torch/include -I/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.10/dist-packages/torch/include/TH -I/usr/local/lib/python3.10/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.10 -c csrc/cpu/mish_cpu.cpp -o build/temp.linux-x86_64-cpython-310/csrc/cpu/mish_cpu.o -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/usr/local/lib/python3.10/dist-packages/torch/include -I/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.10/dist-packages/torch/include/TH -I/usr/local/lib/python3.10/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.10 -c csrc/cuda/mish_cuda.cpp -o build/temp.linux-x86_64-cpython-310/csrc/cuda/mish_cuda.o -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n",
            "/usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.10/dist-packages/torch/include -I/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.10/dist-packages/torch/include/TH -I/usr/local/lib/python3.10/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.10 -c csrc/cuda/mish_kernel.cu -o build/temp.linux-x86_64-cpython-310/csrc/cuda/mish_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' --expt-extended-lambda -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++17\n",
            "\u001b[01m\u001b[0m\u001b[01m/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/irange.h(54)\u001b[0m: \u001b[01;35mwarning\u001b[0m #186-D: pointless comparison of unsigned integer with zero\n",
            "          detected during:\n",
            "            instantiation of \u001b[01m\"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator==(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=size_t, one_sided=false, <unnamed>=0]\"\u001b[0m \u001b[32m\n",
            "(61): here\u001b[0m\n",
            "            instantiation of \u001b[01m\"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator!=(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=size_t, one_sided=false, <unnamed>=0]\"\u001b[0m \u001b[32m\n",
            "/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/TensorImpl.h(77): here\u001b[0m\n",
            "\n",
            "\u001b[01m\u001b[0m\u001b[01m/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/irange.h(54)\u001b[0m: \u001b[01;35mwarning\u001b[0m #186-D: pointless comparison of unsigned integer with zero\n",
            "          detected during:\n",
            "            instantiation of \u001b[01m\"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator==(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=std::size_t, one_sided=true, <unnamed>=0]\"\u001b[0m \u001b[32m\n",
            "(61): here\u001b[0m\n",
            "            instantiation of \u001b[01m\"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator!=(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=std::size_t, one_sided=true, <unnamed>=0]\"\u001b[0m \u001b[32m\n",
            "/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/qualified_name.h(73): here\u001b[0m\n",
            "\n",
            "x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -g -fwrapv -O2 build/temp.linux-x86_64-cpython-310/csrc/cpu/mish_cpu.o build/temp.linux-x86_64-cpython-310/csrc/cuda/mish_cuda.o build/temp.linux-x86_64-cpython-310/csrc/cuda/mish_kernel.o -L/usr/local/lib/python3.10/dist-packages/torch/lib -L/usr/local/cuda/lib64 -L/usr/lib/x86_64-linux-gnu -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-cpython-310/mish_cuda/_C.cpython-310-x86_64-linux-gnu.so\n",
            "running install\n",
            "/usr/local/lib/python3.10/dist-packages/setuptools/_distutils/cmd.py:66: SetuptoolsDeprecationWarning: setup.py install is deprecated.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        Please avoid running ``setup.py`` directly.\n",
            "        Instead, use pypa/build, pypa/installer, pypa/build or\n",
            "        other standards-based tools.\n",
            "\n",
            "        See https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  self.initialize_options()\n",
            "/usr/local/lib/python3.10/dist-packages/setuptools/_distutils/cmd.py:66: EasyInstallDeprecationWarning: easy_install command is deprecated.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        Please avoid running ``setup.py`` and ``easy_install``.\n",
            "        Instead, use pypa/build, pypa/installer, pypa/build or\n",
            "        other standards-based tools.\n",
            "\n",
            "        See https://github.com/pypa/setuptools/issues/917 for details.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  self.initialize_options()\n",
            "running bdist_egg\n",
            "installing library code to build/bdist.linux-x86_64/egg\n",
            "running install_lib\n",
            "creating build/bdist.linux-x86_64\n",
            "creating build/bdist.linux-x86_64/egg\n",
            "creating build/bdist.linux-x86_64/egg/mish_cuda\n",
            "copying build/lib.linux-x86_64-cpython-310/mish_cuda/_C.cpython-310-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/egg/mish_cuda\n",
            "copying build/lib.linux-x86_64-cpython-310/mish_cuda/__init__.py -> build/bdist.linux-x86_64/egg/mish_cuda\n",
            "byte-compiling build/bdist.linux-x86_64/egg/mish_cuda/__init__.py to __init__.cpython-310.pyc\n",
            "creating stub loader for mish_cuda/_C.cpython-310-x86_64-linux-gnu.so\n",
            "byte-compiling build/bdist.linux-x86_64/egg/mish_cuda/_C.py to _C.cpython-310.pyc\n",
            "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying src/mish_cuda.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying src/mish_cuda.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying src/mish_cuda.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying src/mish_cuda.egg-info/not-zip-safe -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying src/mish_cuda.egg-info/requires.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying src/mish_cuda.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "writing build/bdist.linux-x86_64/egg/EGG-INFO/native_libs.txt\n",
            "creating dist\n",
            "creating 'dist/mish_cuda-0.0.3-py3.10-linux-x86_64.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
            "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
            "Processing mish_cuda-0.0.3-py3.10-linux-x86_64.egg\n",
            "creating /usr/local/lib/python3.10/dist-packages/mish_cuda-0.0.3-py3.10-linux-x86_64.egg\n",
            "Extracting mish_cuda-0.0.3-py3.10-linux-x86_64.egg to /usr/local/lib/python3.10/dist-packages\n",
            "Adding mish-cuda 0.0.3 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.10/dist-packages/mish_cuda-0.0.3-py3.10-linux-x86_64.egg\n",
            "Processing dependencies for mish-cuda==0.0.3\n",
            "Searching for torch==2.0.1+cu118\n",
            "Best match: torch 2.0.1+cu118\n",
            "Adding torch 2.0.1+cu118 to easy-install.pth file\n",
            "Installing convert-caffe2-to-onnx script to /usr/local/bin\n",
            "Installing convert-onnx-to-caffe2 script to /usr/local/bin\n",
            "Installing torchrun script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for triton==2.0.0\n",
            "Best match: triton 2.0.0\n",
            "Adding triton 2.0.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for Jinja2==3.1.2\n",
            "Best match: Jinja2 3.1.2\n",
            "Adding Jinja2 3.1.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for networkx==3.1\n",
            "Best match: networkx 3.1\n",
            "Adding networkx 3.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for sympy==1.11.1\n",
            "Best match: sympy 1.11.1\n",
            "Adding sympy 1.11.1 to easy-install.pth file\n",
            "Installing isympy script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for typing-extensions==4.5.0\n",
            "Best match: typing-extensions 4.5.0\n",
            "Adding typing-extensions 4.5.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for filelock==3.12.0\n",
            "Best match: filelock 3.12.0\n",
            "Adding filelock 3.12.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for lit==16.0.5\n",
            "Best match: lit 16.0.5\n",
            "Adding lit 16.0.5 to easy-install.pth file\n",
            "Installing lit script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for cmake==3.25.2\n",
            "Best match: cmake 3.25.2\n",
            "Adding cmake 3.25.2 to easy-install.pth file\n",
            "Installing cmake script to /usr/local/bin\n",
            "Installing cpack script to /usr/local/bin\n",
            "Installing ctest script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for MarkupSafe==2.1.2\n",
            "Best match: MarkupSafe 2.1.2\n",
            "Adding MarkupSafe 2.1.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for mpmath==1.3.0\n",
            "Best match: mpmath 1.3.0\n",
            "Adding mpmath 1.3.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Finished processing dependencies for mish-cuda==0.0.3\n",
            "/content/yolor\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MWJkbCp8Yoj_",
        "outputId": "cbb5b214-bf6e-4726-e837-e00eabea5935"
      },
      "source": [
        "# Install PyTorch Wavelets\n",
        "!git clone https://github.com/fbcotter/pytorch_wavelets\n",
        "%cd pytorch_wavelets\n",
        "!pip install .\n",
        "%cd .."
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'pytorch_wavelets'...\n",
            "remote: Enumerating objects: 978, done.\u001b[K\n",
            "remote: Counting objects: 100% (142/142), done.\u001b[K\n",
            "remote: Compressing objects: 100% (96/96), done.\u001b[K\n",
            "remote: Total 978 (delta 79), reused 91 (delta 46), pack-reused 836\u001b[K\n",
            "Receiving objects: 100% (978/978), 6.80 MiB | 19.72 MiB/s, done.\n",
            "Resolving deltas: 100% (663/663), done.\n",
            "/content/yolor/pytorch_wavelets\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Processing /content/yolor/pytorch_wavelets\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pytorch-wavelets==1.3.0) (1.22.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from pytorch-wavelets==1.3.0) (1.16.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from pytorch-wavelets==1.3.0) (2.0.1+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->pytorch-wavelets==1.3.0) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->pytorch-wavelets==1.3.0) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->pytorch-wavelets==1.3.0) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->pytorch-wavelets==1.3.0) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->pytorch-wavelets==1.3.0) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->pytorch-wavelets==1.3.0) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->pytorch-wavelets==1.3.0) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->pytorch-wavelets==1.3.0) (16.0.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->pytorch-wavelets==1.3.0) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->pytorch-wavelets==1.3.0) (1.3.0)\n",
            "Building wheels for collected packages: pytorch-wavelets\n",
            "  Building wheel for pytorch-wavelets (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytorch-wavelets: filename=pytorch_wavelets-1.3.0-py3-none-any.whl size=54854 sha256=a44befa9e9258bfa7770bfa855cdc0634987dd101919cd3ffc44d060e95771e7\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-92h_qf8p/wheels/67/2b/75/b238b39512b74de50324a5f8afb0180ba106a66bd01588bf0f\n",
            "Successfully built pytorch-wavelets\n",
            "Installing collected packages: pytorch-wavelets\n",
            "Successfully installed pytorch-wavelets-1.3.0\n",
            "/content/yolor\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TYI5O1mW98Ji"
      },
      "source": [
        "# Download Correctly Formatted Custom Dataset \n",
        "\n",
        "We'll download our dataset from Roboflow. Use the \"**YOLOv5 PyTorch**\" export format. Note that the Ultralytics implementation calls for a YAML file defining where your training and test data is. The Roboflow export also writes this format for us.\n",
        "\n",
        "To get your data into Roboflow, follow the [Getting Started Guide](https://blog.roboflow.ai/getting-started-with-roboflow/).\n",
        "\n",
        "![YOLOv5 PyTorch export](https://i.imgur.com/5vr9G2u.png)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8GecVEGw4mMz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a590b14c-45de-4b48-d50c-aa7efb7c5a7b"
      },
      "source": [
        "%%bash\n",
        "pip install gdown\n",
        "gdown 1qPQuaZNTCZD6h7M2DtVY_avb-T_ZmVFr\n",
        "mkdir KUMC\n",
        "unzip KUMC.zip"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1qPQuaZNTCZD6h7M2DtVY_avb-T_ZmVFr\n",
            "To: /content/yolor/KUMC.zip\n",
            "100%|██████████| 3.18G/3.18G [00:33<00:00, 94.6MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOqdKhc4-vOK"
      },
      "source": [
        "%%bash\n",
        "echo \"\n",
        "train: /content/yolor/KUMC/train2019/images\n",
        "val: /content/yolor/KUMC/val2019/images\n",
        "test: /content/yolor/KUMC/test2019/images\n",
        "nc: 2\n",
        "names: [hyperplastic, adenomatous]\" > KUMC/database.yaml"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eltS69vHDldw"
      },
      "source": [
        "location = '/content/yolor/KUMC/database.yaml'"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gMoDFgMZx9RQ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GCs0G_xoD0aq"
      },
      "source": [
        "# Prepare Pre-Trained Weights for YOLOR"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 1UflcHlN5ERPdhahMivQYCbWWw7d2wY7U"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2HI-kARX526D",
        "outputId": "e68dd706-8329-4216-f760-1204f38712b6"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Access denied with the following error:\n",
            "\n",
            " \tCannot retrieve the public link of the file. You may need to change\n",
            "\tthe permission to 'Anyone with the link', or have had many accesses. \n",
            "\n",
            "You may still be able to access the file from the browser:\n",
            "\n",
            "\t https://drive.google.com/uc?id=1UflcHlN5ERPdhahMivQYCbWWw7d2wY7U \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8JepT8h7EA_j",
        "outputId": "971debba-ac61-4584-8b7b-5812e19fbe78"
      },
      "source": [
        "%cd /content/yolor\n",
        "!bash scripts/get_pretrain.sh"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/yolor\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  1642    0  1642    0     0  16927      0 --:--:-- --:--:-- --:--:-- 16927\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  1642    0  1642    0     0  16098      0 --:--:-- --:--:-- --:--:-- 16098\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PBjYNGD4ER_4"
      },
      "source": [
        "# Write YOLOR Configuration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cy8NlkoKg9lC"
      },
      "source": [
        "import yaml\n",
        "with open(location) as f:\n",
        "    dataMap = yaml.safe_load(f)\n",
        "\n",
        "num_classes = len(dataMap['names'])\n",
        "num_filters = (num_classes + 5) * 3\n",
        "from IPython.core.magic import register_line_cell_magic\n",
        "\n",
        "@register_line_cell_magic\n",
        "def writetemplate(line, cell):\n",
        "    with open(line, 'w') as f:\n",
        "        f.write(cell.format(**globals()))"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2XOWgwAg5kV"
      },
      "source": [
        "%%writetemplate /content/yolor/cfg/yolor_p6.cfg\n",
        "\n",
        "[net]\n",
        "batch=64\n",
        "subdivisions=8\n",
        "width=1280\n",
        "height=1280\n",
        "channels=3\n",
        "momentum=0.949\n",
        "decay=0.0005\n",
        "angle=0\n",
        "saturation = 1.5\n",
        "exposure = 1.5\n",
        "hue=.1\n",
        "\n",
        "learning_rate=0.00261\n",
        "burn_in=1000\n",
        "max_batches = 500500\n",
        "policy=steps\n",
        "steps=400000,450000\n",
        "scales=.1,.1\n",
        "\n",
        "mosaic=1\n",
        "\n",
        "\n",
        "# ============ Backbone ============ #\n",
        "\n",
        "# Stem \n",
        "\n",
        "# P1\n",
        "\n",
        "# Downsample\n",
        "\n",
        "# 0\n",
        "[reorg]\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=64\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "\n",
        "# P2\n",
        "\n",
        "# Downsample\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=3\n",
        "stride=2\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "# Split\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=64\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[route]\n",
        "layers = -2\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=64\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "# Residual Block\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=64\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=64\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[shortcut]\n",
        "from=-3\n",
        "activation=linear\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=64\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=64\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[shortcut]\n",
        "from=-3\n",
        "activation=linear\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=64\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=64\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[shortcut]\n",
        "from=-3\n",
        "activation=linear\n",
        "\n",
        "# Transition first\n",
        "#\n",
        "#[convolutional]\n",
        "#batch_normalize=1\n",
        "#filters=64\n",
        "#size=1\n",
        "#stride=1\n",
        "#pad=1\n",
        "#activation=silu\n",
        "\n",
        "# Merge [-1, -(3k+3)]\n",
        "\n",
        "[route]\n",
        "layers = -1,-12\n",
        "\n",
        "# Transition last\n",
        "\n",
        "# 16 (previous+6+3k)\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "\n",
        "# P3\n",
        "\n",
        "# Downsample\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=256\n",
        "size=3\n",
        "stride=2\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "# Split\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[route]\n",
        "layers = -2\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "# Residual Block\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[shortcut]\n",
        "from=-3\n",
        "activation=linear\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[shortcut]\n",
        "from=-3\n",
        "activation=linear\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[shortcut]\n",
        "from=-3\n",
        "activation=linear\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[shortcut]\n",
        "from=-3\n",
        "activation=linear\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[shortcut]\n",
        "from=-3\n",
        "activation=linear\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[shortcut]\n",
        "from=-3\n",
        "activation=linear\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[shortcut]\n",
        "from=-3\n",
        "activation=linear\n",
        "\n",
        "# Transition first\n",
        "#\n",
        "#[convolutional]\n",
        "#batch_normalize=1\n",
        "#filters=128\n",
        "#size=1\n",
        "#stride=1\n",
        "#pad=1\n",
        "#activation=silu\n",
        "\n",
        "# Merge [-1, -(3k+3)]\n",
        "\n",
        "[route]\n",
        "layers = -1,-24\n",
        "\n",
        "# Transition last\n",
        "\n",
        "# 43 (previous+6+3k)\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=256\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "\n",
        "# P4\n",
        "\n",
        "# Downsample\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=384\n",
        "size=3\n",
        "stride=2\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "# Split\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=192\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[route]\n",
        "layers = -2\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=192\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "# Residual Block\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=192\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=192\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[shortcut]\n",
        "from=-3\n",
        "activation=linear\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=192\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=192\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[shortcut]\n",
        "from=-3\n",
        "activation=linear\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=192\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=192\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[shortcut]\n",
        "from=-3\n",
        "activation=linear\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=192\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=192\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[shortcut]\n",
        "from=-3\n",
        "activation=linear\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=192\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=192\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[shortcut]\n",
        "from=-3\n",
        "activation=linear\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=192\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=192\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[shortcut]\n",
        "from=-3\n",
        "activation=linear\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=192\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=192\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[shortcut]\n",
        "from=-3\n",
        "activation=linear\n",
        "\n",
        "# Transition first\n",
        "#\n",
        "#[convolutional]\n",
        "#batch_normalize=1\n",
        "#filters=192\n",
        "#size=1\n",
        "#stride=1\n",
        "#pad=1\n",
        "#activation=silu\n",
        "\n",
        "# Merge [-1, -(3k+3)]\n",
        "\n",
        "[route]\n",
        "layers = -1,-24\n",
        "\n",
        "# Transition last\n",
        "\n",
        "# 70 (previous+6+3k)\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=384\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "\n",
        "# P5\n",
        "\n",
        "# Downsample\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=512\n",
        "size=3\n",
        "stride=2\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "# Split\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=256\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[route]\n",
        "layers = -2\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=256\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "# Residual Block\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=256\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=256\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[shortcut]\n",
        "from=-3\n",
        "activation=linear\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=256\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=256\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[shortcut]\n",
        "from=-3\n",
        "activation=linear\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=256\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=256\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[shortcut]\n",
        "from=-3\n",
        "activation=linear\n",
        "\n",
        "# Transition first\n",
        "#\n",
        "#[convolutional]\n",
        "#batch_normalize=1\n",
        "#filters=256\n",
        "#size=1\n",
        "#stride=1\n",
        "#pad=1\n",
        "#activation=silu\n",
        "\n",
        "# Merge [-1, -(3k+3)]\n",
        "\n",
        "[route]\n",
        "layers = -1,-12\n",
        "\n",
        "# Transition last\n",
        "\n",
        "# 85 (previous+6+3k)\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=512\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "\n",
        "# P6\n",
        "\n",
        "# Downsample\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=640\n",
        "size=3\n",
        "stride=2\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "# Split\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=320\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[route]\n",
        "layers = -2\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=320\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "# Residual Block\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=320\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=320\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[shortcut]\n",
        "from=-3\n",
        "activation=linear\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=320\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=320\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[shortcut]\n",
        "from=-3\n",
        "activation=linear\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=320\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=320\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[shortcut]\n",
        "from=-3\n",
        "activation=linear\n",
        "\n",
        "# Transition first\n",
        "#\n",
        "#[convolutional]\n",
        "#batch_normalize=1\n",
        "#filters=320\n",
        "#size=1\n",
        "#stride=1\n",
        "#pad=1\n",
        "#activation=silu\n",
        "\n",
        "# Merge [-1, -(3k+3)]\n",
        "\n",
        "[route]\n",
        "layers = -1,-12\n",
        "\n",
        "# Transition last\n",
        "\n",
        "# 100 (previous+6+3k)\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=640\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "# ============ End of Backbone ============ #\n",
        "\n",
        "# ============ Neck ============ #\n",
        "\n",
        "# CSPSPP\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=320\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[route]\n",
        "layers = -2\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=320\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "filters=320\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=320\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "### SPP ###\n",
        "[maxpool]\n",
        "stride=1\n",
        "size=5\n",
        "\n",
        "[route]\n",
        "layers=-2\n",
        "\n",
        "[maxpool]\n",
        "stride=1\n",
        "size=9\n",
        "\n",
        "[route]\n",
        "layers=-4\n",
        "\n",
        "[maxpool]\n",
        "stride=1\n",
        "size=13\n",
        "\n",
        "[route]\n",
        "layers=-1,-3,-5,-6\n",
        "### End SPP ###\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=320\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "filters=320\n",
        "activation=silu\n",
        "\n",
        "[route]\n",
        "layers = -1, -13\n",
        "\n",
        "# 115 (previous+6+5+2k)\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=320\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "# End of CSPSPP\n",
        "\n",
        "\n",
        "# FPN-5\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=256\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[upsample]\n",
        "stride=2\n",
        "\n",
        "[route]\n",
        "layers = 85\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=256\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[route]\n",
        "layers = -1, -3\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=256\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "# Split\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=256\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[route]\n",
        "layers = -2\n",
        "\n",
        "# Plain Block\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=256\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "filters=256\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=256\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "filters=256\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=256\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "filters=256\n",
        "activation=silu\n",
        "\n",
        "# Merge [-1, -(2k+2)]\n",
        "\n",
        "[route]\n",
        "layers = -1, -8\n",
        "\n",
        "# Transition last\n",
        "\n",
        "# 131 (previous+6+4+2k)\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=256\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "\n",
        "# FPN-4\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=192\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[upsample]\n",
        "stride=2\n",
        "\n",
        "[route]\n",
        "layers = 70\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=192\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[route]\n",
        "layers = -1, -3\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=192\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "# Split\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=192\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[route]\n",
        "layers = -2\n",
        "\n",
        "# Plain Block\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=192\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "filters=192\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=192\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "filters=192\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=192\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "filters=192\n",
        "activation=silu\n",
        "\n",
        "# Merge [-1, -(2k+2)]\n",
        "\n",
        "[route]\n",
        "layers = -1, -8\n",
        "\n",
        "# Transition last\n",
        "\n",
        "# 147 (previous+6+4+2k)\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=192\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "\n",
        "# FPN-3\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[upsample]\n",
        "stride=2\n",
        "\n",
        "[route]\n",
        "layers = 43\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[route]\n",
        "layers = -1, -3\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "# Split\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[route]\n",
        "layers = -2\n",
        "\n",
        "# Plain Block\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "filters=128\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "filters=128\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "filters=128\n",
        "activation=silu\n",
        "\n",
        "# Merge [-1, -(2k+2)]\n",
        "\n",
        "[route]\n",
        "layers = -1, -8\n",
        "\n",
        "# Transition last\n",
        "\n",
        "# 163 (previous+6+4+2k)\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "\n",
        "# PAN-4\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "size=3\n",
        "stride=2\n",
        "pad=1\n",
        "filters=192\n",
        "activation=silu\n",
        "\n",
        "[route]\n",
        "layers = -1, 147\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=192\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "# Split\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=192\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[route]\n",
        "layers = -2\n",
        "\n",
        "# Plain Block\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=192\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "filters=192\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=192\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "filters=192\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=192\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "filters=192\n",
        "activation=silu\n",
        "\n",
        "[route]\n",
        "layers = -1,-8\n",
        "\n",
        "# Transition last\n",
        "\n",
        "# 176 (previous+3+4+2k)\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=192\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "\n",
        "# PAN-5\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "size=3\n",
        "stride=2\n",
        "pad=1\n",
        "filters=256\n",
        "activation=silu\n",
        "\n",
        "[route]\n",
        "layers = -1, 131\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=256\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "# Split\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=256\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[route]\n",
        "layers = -2\n",
        "\n",
        "# Plain Block\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=256\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "filters=256\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=256\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "filters=256\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=256\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "filters=256\n",
        "activation=silu\n",
        "\n",
        "[route]\n",
        "layers = -1,-8\n",
        "\n",
        "# Transition last\n",
        "\n",
        "# 189 (previous+3+4+2k)\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=256\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "\n",
        "# PAN-6\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "size=3\n",
        "stride=2\n",
        "pad=1\n",
        "filters=320\n",
        "activation=silu\n",
        "\n",
        "[route]\n",
        "layers = -1, 115\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=320\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "# Split\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=320\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[route]\n",
        "layers = -2\n",
        "\n",
        "# Plain Block\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=320\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "filters=320\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=320\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "filters=320\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=320\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "filters=320\n",
        "activation=silu\n",
        "\n",
        "[route]\n",
        "layers = -1,-8\n",
        "\n",
        "# Transition last\n",
        "\n",
        "# 202 (previous+3+4+2k)\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=320\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "# ============ End of Neck ============ #\n",
        "\n",
        "# 203\n",
        "[implicit_add]\n",
        "filters=256\n",
        "\n",
        "# 204\n",
        "[implicit_add]\n",
        "filters=384\n",
        "\n",
        "# 205\n",
        "[implicit_add]\n",
        "filters=512\n",
        "\n",
        "# 206\n",
        "[implicit_add]\n",
        "filters=640\n",
        "\n",
        "# 207\n",
        "[implicit_mul]\n",
        "filters={num_filters}\n",
        "\n",
        "# 208\n",
        "[implicit_mul]\n",
        "filters={num_filters}\n",
        "\n",
        "# 209\n",
        "[implicit_mul]\n",
        "filters={num_filters}\n",
        "\n",
        "# 210\n",
        "[implicit_mul]\n",
        "filters={num_filters}\n",
        "\n",
        "# ============ Head ============ #\n",
        "\n",
        "# YOLO-3\n",
        "\n",
        "[route]\n",
        "layers = 163\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "filters=256\n",
        "activation=silu\n",
        "\n",
        "[shift_channels]\n",
        "from=203\n",
        "\n",
        "[convolutional]\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "filters={num_filters}\n",
        "activation=linear\n",
        "\n",
        "[control_channels]\n",
        "from=207\n",
        "\n",
        "[yolo]\n",
        "mask = 0,1,2\n",
        "anchors = 19,27,  44,40,  38,94,  96,68,  86,152,  180,137,  140,301,  303,264,  238,542,  436,615,  739,380,  925,792\n",
        "classes={num_classes}\n",
        "num=12\n",
        "jitter=.3\n",
        "ignore_thresh = .7\n",
        "truth_thresh = 1\n",
        "random=1\n",
        "scale_x_y = 1.05\n",
        "iou_thresh=0.213\n",
        "cls_normalizer=1.0\n",
        "iou_normalizer=0.07\n",
        "iou_loss=ciou\n",
        "nms_kind=greedynms\n",
        "beta_nms=0.6\n",
        "\n",
        "\n",
        "# YOLO-4\n",
        "\n",
        "[route]\n",
        "layers = 176\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "filters=384\n",
        "activation=silu\n",
        "\n",
        "[shift_channels]\n",
        "from=204\n",
        "\n",
        "[convolutional]\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "filters={num_filters}\n",
        "activation=linear\n",
        "\n",
        "[control_channels]\n",
        "from=208\n",
        "\n",
        "[yolo]\n",
        "mask = 3,4,5\n",
        "anchors = 19,27,  44,40,  38,94,  96,68,  86,152,  180,137,  140,301,  303,264,  238,542,  436,615,  739,380,  925,792\n",
        "classes={num_classes}\n",
        "num=12\n",
        "jitter=.3\n",
        "ignore_thresh = .7\n",
        "truth_thresh = 1\n",
        "random=1\n",
        "scale_x_y = 1.05\n",
        "iou_thresh=0.213\n",
        "cls_normalizer=1.0\n",
        "iou_normalizer=0.07\n",
        "iou_loss=ciou\n",
        "nms_kind=greedynms\n",
        "beta_nms=0.6\n",
        "\n",
        "\n",
        "# YOLO-5\n",
        "\n",
        "[route]\n",
        "layers = 189\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "filters=512\n",
        "activation=silu\n",
        "\n",
        "[shift_channels]\n",
        "from=205\n",
        "\n",
        "[convolutional]\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "filters={num_filters}\n",
        "activation=linear\n",
        "\n",
        "[control_channels]\n",
        "from=209\n",
        "\n",
        "[yolo]\n",
        "mask = 6,7,8\n",
        "anchors = 19,27,  44,40,  38,94,  96,68,  86,152,  180,137,  140,301,  303,264,  238,542,  436,615,  739,380,  925,792\n",
        "classes={num_classes}\n",
        "num=12\n",
        "jitter=.3\n",
        "ignore_thresh = .7\n",
        "truth_thresh = 1\n",
        "random=1\n",
        "scale_x_y = 1.05\n",
        "iou_thresh=0.213\n",
        "cls_normalizer=1.0\n",
        "iou_normalizer=0.07\n",
        "iou_loss=ciou\n",
        "nms_kind=greedynms\n",
        "beta_nms=0.6\n",
        "\n",
        "\n",
        "# YOLO-6\n",
        "\n",
        "[route]\n",
        "layers = 202\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "filters=640\n",
        "activation=silu\n",
        "\n",
        "[shift_channels]\n",
        "from=206\n",
        "\n",
        "[convolutional]\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "filters={num_filters}\n",
        "activation=linear\n",
        "\n",
        "[control_channels]\n",
        "from=210\n",
        "\n",
        "[yolo]\n",
        "mask = 9,10,11\n",
        "anchors = 19,27,  44,40,  38,94,  96,68,  86,152,  180,137,  140,301,  303,264,  238,542,  436,615,  739,380,  925,792\n",
        "classes={num_classes}\n",
        "num=12\n",
        "jitter=.3\n",
        "ignore_thresh = .7\n",
        "truth_thresh = 1\n",
        "random=1\n",
        "scale_x_y = 1.05\n",
        "iou_thresh=0.213\n",
        "cls_normalizer=1.0\n",
        "iou_normalizer=0.07\n",
        "iou_loss=ciou\n",
        "nms_kind=greedynms\n",
        "beta_nms=0.6\n",
        "\n",
        "# ============ End of Head ============ #"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZLldIGy2ERgB",
        "outputId": "4f7a8cdd-623a-4230-df13-e73bddb9d53c"
      },
      "source": [
        "%cat /content/yolor/cfg/yolor_p6.cfg"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[net]\n",
            "batch=64\n",
            "subdivisions=8\n",
            "width=1280\n",
            "height=1280\n",
            "channels=3\n",
            "momentum=0.949\n",
            "decay=0.0005\n",
            "angle=0\n",
            "saturation = 1.5\n",
            "exposure = 1.5\n",
            "hue=.1\n",
            "\n",
            "learning_rate=0.00261\n",
            "burn_in=1000\n",
            "max_batches = 500500\n",
            "policy=steps\n",
            "steps=400000,450000\n",
            "scales=.1,.1\n",
            "\n",
            "mosaic=1\n",
            "\n",
            "\n",
            "# ============ Backbone ============ #\n",
            "\n",
            "# Stem \n",
            "\n",
            "# P1\n",
            "\n",
            "# Downsample\n",
            "\n",
            "# 0\n",
            "[reorg]\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=64\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "\n",
            "# P2\n",
            "\n",
            "# Downsample\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=128\n",
            "size=3\n",
            "stride=2\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "# Split\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=64\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[route]\n",
            "layers = -2\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=64\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "# Residual Block\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=64\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=64\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[shortcut]\n",
            "from=-3\n",
            "activation=linear\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=64\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=64\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[shortcut]\n",
            "from=-3\n",
            "activation=linear\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=64\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=64\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[shortcut]\n",
            "from=-3\n",
            "activation=linear\n",
            "\n",
            "# Transition first\n",
            "#\n",
            "#[convolutional]\n",
            "#batch_normalize=1\n",
            "#filters=64\n",
            "#size=1\n",
            "#stride=1\n",
            "#pad=1\n",
            "#activation=silu\n",
            "\n",
            "# Merge [-1, -(3k+3)]\n",
            "\n",
            "[route]\n",
            "layers = -1,-12\n",
            "\n",
            "# Transition last\n",
            "\n",
            "# 16 (previous+6+3k)\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=128\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "\n",
            "# P3\n",
            "\n",
            "# Downsample\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=256\n",
            "size=3\n",
            "stride=2\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "# Split\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=128\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[route]\n",
            "layers = -2\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=128\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "# Residual Block\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=128\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=128\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[shortcut]\n",
            "from=-3\n",
            "activation=linear\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=128\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=128\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[shortcut]\n",
            "from=-3\n",
            "activation=linear\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=128\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=128\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[shortcut]\n",
            "from=-3\n",
            "activation=linear\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=128\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=128\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[shortcut]\n",
            "from=-3\n",
            "activation=linear\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=128\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=128\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[shortcut]\n",
            "from=-3\n",
            "activation=linear\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=128\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=128\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[shortcut]\n",
            "from=-3\n",
            "activation=linear\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=128\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=128\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[shortcut]\n",
            "from=-3\n",
            "activation=linear\n",
            "\n",
            "# Transition first\n",
            "#\n",
            "#[convolutional]\n",
            "#batch_normalize=1\n",
            "#filters=128\n",
            "#size=1\n",
            "#stride=1\n",
            "#pad=1\n",
            "#activation=silu\n",
            "\n",
            "# Merge [-1, -(3k+3)]\n",
            "\n",
            "[route]\n",
            "layers = -1,-24\n",
            "\n",
            "# Transition last\n",
            "\n",
            "# 43 (previous+6+3k)\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=256\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "\n",
            "# P4\n",
            "\n",
            "# Downsample\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=384\n",
            "size=3\n",
            "stride=2\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "# Split\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=192\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[route]\n",
            "layers = -2\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=192\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "# Residual Block\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=192\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=192\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[shortcut]\n",
            "from=-3\n",
            "activation=linear\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=192\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=192\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[shortcut]\n",
            "from=-3\n",
            "activation=linear\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=192\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=192\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[shortcut]\n",
            "from=-3\n",
            "activation=linear\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=192\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=192\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[shortcut]\n",
            "from=-3\n",
            "activation=linear\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=192\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=192\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[shortcut]\n",
            "from=-3\n",
            "activation=linear\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=192\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=192\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[shortcut]\n",
            "from=-3\n",
            "activation=linear\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=192\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=192\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[shortcut]\n",
            "from=-3\n",
            "activation=linear\n",
            "\n",
            "# Transition first\n",
            "#\n",
            "#[convolutional]\n",
            "#batch_normalize=1\n",
            "#filters=192\n",
            "#size=1\n",
            "#stride=1\n",
            "#pad=1\n",
            "#activation=silu\n",
            "\n",
            "# Merge [-1, -(3k+3)]\n",
            "\n",
            "[route]\n",
            "layers = -1,-24\n",
            "\n",
            "# Transition last\n",
            "\n",
            "# 70 (previous+6+3k)\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=384\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "\n",
            "# P5\n",
            "\n",
            "# Downsample\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=512\n",
            "size=3\n",
            "stride=2\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "# Split\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=256\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[route]\n",
            "layers = -2\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=256\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "# Residual Block\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=256\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=256\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[shortcut]\n",
            "from=-3\n",
            "activation=linear\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=256\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=256\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[shortcut]\n",
            "from=-3\n",
            "activation=linear\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=256\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=256\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[shortcut]\n",
            "from=-3\n",
            "activation=linear\n",
            "\n",
            "# Transition first\n",
            "#\n",
            "#[convolutional]\n",
            "#batch_normalize=1\n",
            "#filters=256\n",
            "#size=1\n",
            "#stride=1\n",
            "#pad=1\n",
            "#activation=silu\n",
            "\n",
            "# Merge [-1, -(3k+3)]\n",
            "\n",
            "[route]\n",
            "layers = -1,-12\n",
            "\n",
            "# Transition last\n",
            "\n",
            "# 85 (previous+6+3k)\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=512\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "\n",
            "# P6\n",
            "\n",
            "# Downsample\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=640\n",
            "size=3\n",
            "stride=2\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "# Split\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=320\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[route]\n",
            "layers = -2\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=320\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "# Residual Block\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=320\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=320\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[shortcut]\n",
            "from=-3\n",
            "activation=linear\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=320\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=320\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[shortcut]\n",
            "from=-3\n",
            "activation=linear\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=320\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=320\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[shortcut]\n",
            "from=-3\n",
            "activation=linear\n",
            "\n",
            "# Transition first\n",
            "#\n",
            "#[convolutional]\n",
            "#batch_normalize=1\n",
            "#filters=320\n",
            "#size=1\n",
            "#stride=1\n",
            "#pad=1\n",
            "#activation=silu\n",
            "\n",
            "# Merge [-1, -(3k+3)]\n",
            "\n",
            "[route]\n",
            "layers = -1,-12\n",
            "\n",
            "# Transition last\n",
            "\n",
            "# 100 (previous+6+3k)\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=640\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "# ============ End of Backbone ============ #\n",
            "\n",
            "# ============ Neck ============ #\n",
            "\n",
            "# CSPSPP\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=320\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[route]\n",
            "layers = -2\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=320\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "filters=320\n",
            "activation=silu\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=320\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "### SPP ###\n",
            "[maxpool]\n",
            "stride=1\n",
            "size=5\n",
            "\n",
            "[route]\n",
            "layers=-2\n",
            "\n",
            "[maxpool]\n",
            "stride=1\n",
            "size=9\n",
            "\n",
            "[route]\n",
            "layers=-4\n",
            "\n",
            "[maxpool]\n",
            "stride=1\n",
            "size=13\n",
            "\n",
            "[route]\n",
            "layers=-1,-3,-5,-6\n",
            "### End SPP ###\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=320\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "filters=320\n",
            "activation=silu\n",
            "\n",
            "[route]\n",
            "layers = -1, -13\n",
            "\n",
            "# 115 (previous+6+5+2k)\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=320\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "# End of CSPSPP\n",
            "\n",
            "\n",
            "# FPN-5\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=256\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[upsample]\n",
            "stride=2\n",
            "\n",
            "[route]\n",
            "layers = 85\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=256\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[route]\n",
            "layers = -1, -3\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=256\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "# Split\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=256\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[route]\n",
            "layers = -2\n",
            "\n",
            "# Plain Block\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=256\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "filters=256\n",
            "activation=silu\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=256\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "filters=256\n",
            "activation=silu\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=256\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "filters=256\n",
            "activation=silu\n",
            "\n",
            "# Merge [-1, -(2k+2)]\n",
            "\n",
            "[route]\n",
            "layers = -1, -8\n",
            "\n",
            "# Transition last\n",
            "\n",
            "# 131 (previous+6+4+2k)\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=256\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "\n",
            "# FPN-4\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=192\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[upsample]\n",
            "stride=2\n",
            "\n",
            "[route]\n",
            "layers = 70\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=192\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[route]\n",
            "layers = -1, -3\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=192\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "# Split\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=192\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[route]\n",
            "layers = -2\n",
            "\n",
            "# Plain Block\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=192\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "filters=192\n",
            "activation=silu\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=192\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "filters=192\n",
            "activation=silu\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=192\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "filters=192\n",
            "activation=silu\n",
            "\n",
            "# Merge [-1, -(2k+2)]\n",
            "\n",
            "[route]\n",
            "layers = -1, -8\n",
            "\n",
            "# Transition last\n",
            "\n",
            "# 147 (previous+6+4+2k)\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=192\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "\n",
            "# FPN-3\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=128\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[upsample]\n",
            "stride=2\n",
            "\n",
            "[route]\n",
            "layers = 43\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=128\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[route]\n",
            "layers = -1, -3\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=128\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "# Split\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=128\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[route]\n",
            "layers = -2\n",
            "\n",
            "# Plain Block\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=128\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "filters=128\n",
            "activation=silu\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=128\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "filters=128\n",
            "activation=silu\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=128\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "filters=128\n",
            "activation=silu\n",
            "\n",
            "# Merge [-1, -(2k+2)]\n",
            "\n",
            "[route]\n",
            "layers = -1, -8\n",
            "\n",
            "# Transition last\n",
            "\n",
            "# 163 (previous+6+4+2k)\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=128\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "\n",
            "# PAN-4\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "size=3\n",
            "stride=2\n",
            "pad=1\n",
            "filters=192\n",
            "activation=silu\n",
            "\n",
            "[route]\n",
            "layers = -1, 147\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=192\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "# Split\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=192\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[route]\n",
            "layers = -2\n",
            "\n",
            "# Plain Block\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=192\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "filters=192\n",
            "activation=silu\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=192\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "filters=192\n",
            "activation=silu\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=192\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "filters=192\n",
            "activation=silu\n",
            "\n",
            "[route]\n",
            "layers = -1,-8\n",
            "\n",
            "# Transition last\n",
            "\n",
            "# 176 (previous+3+4+2k)\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=192\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "\n",
            "# PAN-5\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "size=3\n",
            "stride=2\n",
            "pad=1\n",
            "filters=256\n",
            "activation=silu\n",
            "\n",
            "[route]\n",
            "layers = -1, 131\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=256\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "# Split\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=256\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[route]\n",
            "layers = -2\n",
            "\n",
            "# Plain Block\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=256\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "filters=256\n",
            "activation=silu\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=256\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "filters=256\n",
            "activation=silu\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=256\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "filters=256\n",
            "activation=silu\n",
            "\n",
            "[route]\n",
            "layers = -1,-8\n",
            "\n",
            "# Transition last\n",
            "\n",
            "# 189 (previous+3+4+2k)\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=256\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "\n",
            "# PAN-6\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "size=3\n",
            "stride=2\n",
            "pad=1\n",
            "filters=320\n",
            "activation=silu\n",
            "\n",
            "[route]\n",
            "layers = -1, 115\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=320\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "# Split\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=320\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[route]\n",
            "layers = -2\n",
            "\n",
            "# Plain Block\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=320\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "filters=320\n",
            "activation=silu\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=320\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "filters=320\n",
            "activation=silu\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=320\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "filters=320\n",
            "activation=silu\n",
            "\n",
            "[route]\n",
            "layers = -1,-8\n",
            "\n",
            "# Transition last\n",
            "\n",
            "# 202 (previous+3+4+2k)\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=320\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=silu\n",
            "\n",
            "# ============ End of Neck ============ #\n",
            "\n",
            "# 203\n",
            "[implicit_add]\n",
            "filters=256\n",
            "\n",
            "# 204\n",
            "[implicit_add]\n",
            "filters=384\n",
            "\n",
            "# 205\n",
            "[implicit_add]\n",
            "filters=512\n",
            "\n",
            "# 206\n",
            "[implicit_add]\n",
            "filters=640\n",
            "\n",
            "# 207\n",
            "[implicit_mul]\n",
            "filters=21\n",
            "\n",
            "# 208\n",
            "[implicit_mul]\n",
            "filters=21\n",
            "\n",
            "# 209\n",
            "[implicit_mul]\n",
            "filters=21\n",
            "\n",
            "# 210\n",
            "[implicit_mul]\n",
            "filters=21\n",
            "\n",
            "# ============ Head ============ #\n",
            "\n",
            "# YOLO-3\n",
            "\n",
            "[route]\n",
            "layers = 163\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "filters=256\n",
            "activation=silu\n",
            "\n",
            "[shift_channels]\n",
            "from=203\n",
            "\n",
            "[convolutional]\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "filters=21\n",
            "activation=linear\n",
            "\n",
            "[control_channels]\n",
            "from=207\n",
            "\n",
            "[yolo]\n",
            "mask = 0,1,2\n",
            "anchors = 19,27,  44,40,  38,94,  96,68,  86,152,  180,137,  140,301,  303,264,  238,542,  436,615,  739,380,  925,792\n",
            "classes=2\n",
            "num=12\n",
            "jitter=.3\n",
            "ignore_thresh = .7\n",
            "truth_thresh = 1\n",
            "random=1\n",
            "scale_x_y = 1.05\n",
            "iou_thresh=0.213\n",
            "cls_normalizer=1.0\n",
            "iou_normalizer=0.07\n",
            "iou_loss=ciou\n",
            "nms_kind=greedynms\n",
            "beta_nms=0.6\n",
            "\n",
            "\n",
            "# YOLO-4\n",
            "\n",
            "[route]\n",
            "layers = 176\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "filters=384\n",
            "activation=silu\n",
            "\n",
            "[shift_channels]\n",
            "from=204\n",
            "\n",
            "[convolutional]\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "filters=21\n",
            "activation=linear\n",
            "\n",
            "[control_channels]\n",
            "from=208\n",
            "\n",
            "[yolo]\n",
            "mask = 3,4,5\n",
            "anchors = 19,27,  44,40,  38,94,  96,68,  86,152,  180,137,  140,301,  303,264,  238,542,  436,615,  739,380,  925,792\n",
            "classes=2\n",
            "num=12\n",
            "jitter=.3\n",
            "ignore_thresh = .7\n",
            "truth_thresh = 1\n",
            "random=1\n",
            "scale_x_y = 1.05\n",
            "iou_thresh=0.213\n",
            "cls_normalizer=1.0\n",
            "iou_normalizer=0.07\n",
            "iou_loss=ciou\n",
            "nms_kind=greedynms\n",
            "beta_nms=0.6\n",
            "\n",
            "\n",
            "# YOLO-5\n",
            "\n",
            "[route]\n",
            "layers = 189\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "filters=512\n",
            "activation=silu\n",
            "\n",
            "[shift_channels]\n",
            "from=205\n",
            "\n",
            "[convolutional]\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "filters=21\n",
            "activation=linear\n",
            "\n",
            "[control_channels]\n",
            "from=209\n",
            "\n",
            "[yolo]\n",
            "mask = 6,7,8\n",
            "anchors = 19,27,  44,40,  38,94,  96,68,  86,152,  180,137,  140,301,  303,264,  238,542,  436,615,  739,380,  925,792\n",
            "classes=2\n",
            "num=12\n",
            "jitter=.3\n",
            "ignore_thresh = .7\n",
            "truth_thresh = 1\n",
            "random=1\n",
            "scale_x_y = 1.05\n",
            "iou_thresh=0.213\n",
            "cls_normalizer=1.0\n",
            "iou_normalizer=0.07\n",
            "iou_loss=ciou\n",
            "nms_kind=greedynms\n",
            "beta_nms=0.6\n",
            "\n",
            "\n",
            "# YOLO-6\n",
            "\n",
            "[route]\n",
            "layers = 202\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "filters=640\n",
            "activation=silu\n",
            "\n",
            "[shift_channels]\n",
            "from=206\n",
            "\n",
            "[convolutional]\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "filters=21\n",
            "activation=linear\n",
            "\n",
            "[control_channels]\n",
            "from=210\n",
            "\n",
            "[yolo]\n",
            "mask = 9,10,11\n",
            "anchors = 19,27,  44,40,  38,94,  96,68,  86,152,  180,137,  140,301,  303,264,  238,542,  436,615,  739,380,  925,792\n",
            "classes=2\n",
            "num=12\n",
            "jitter=.3\n",
            "ignore_thresh = .7\n",
            "truth_thresh = 1\n",
            "random=1\n",
            "scale_x_y = 1.05\n",
            "iou_thresh=0.213\n",
            "cls_normalizer=1.0\n",
            "iou_normalizer=0.07\n",
            "iou_loss=ciou\n",
            "nms_kind=greedynms\n",
            "beta_nms=0.6\n",
            "\n",
            "# ============ End of Head ============ #\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o6t4nA4wWr8v"
      },
      "source": [
        "# Train Custom YOLOR Detector\n",
        "\n",
        "### Next, we'll fire off training!\n",
        "\n",
        "\n",
        "Here, we are able to pass a number of arguments:\n",
        "- **img:** define input image size\n",
        "- **batch:** determine batch size\n",
        "- **epochs:** define the number of training epochs. (Note: often, 3000+ are common here!)\n",
        "- **data:** set the path to our yaml file\n",
        "- **cfg:** specify our model configuration\n",
        "- **weights:** specify a custom path to weights. (Note: We can specify the pretrained weights we downloaded up above with the shell script)\n",
        "- **name:** result names\n",
        "-**hyp:** Define the hyperparamters for training"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git lfs install"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BWJcJyYz3uUp",
        "outputId": "28b936ca-7a42-4d1d-81ab-20269af9f327"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated git hooks.\n",
            "Git LFS initialized.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HEpv8Kww8ruo"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OqG-CDJZEiw2",
        "outputId": "103d8e74-258d-417b-852d-f6b8966924a3"
      },
      "source": [
        "%cd /content/yolor/\n",
        "!python train.py --batch-size 32 --img 416 416 --data {location} --cfg cfg/yolor_p6.cfg --weights '/content/yolor/yolor_p6.pt'  --device 0 --name yolor_p6 --hyp '/content/yolor/data/hyp.scratch.1280.yaml' --epochs 100"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/yolor\n",
            "2023-05-20 16:18:44.997103: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-05-20 16:18:47.195882: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Using torch 2.0.1+cu118 CUDA:0 (Tesla T4, 15101MB)\n",
            "\n",
            "Namespace(weights='/content/yolor/yolor_p6.pt', cfg='cfg/yolor_p6.cfg', data='/content/yolor/KUMC/database.yaml', hyp='/content/yolor/data/hyp.scratch.1280.yaml', epochs=100, batch_size=32, img_size=[416, 416], rect=False, resume=False, nosave=False, notest=False, noautoanchor=False, evolve=False, bucket='', cache_images=False, image_weights=False, device='0', multi_scale=False, single_cls=False, adam=False, sync_bn=False, local_rank=-1, log_imgs=16, workers=8, project='runs/train', name='yolor_p6', exist_ok=False, total_batch_size=32, world_size=1, global_rank=-1, save_dir='runs/train/yolor_p67')\n",
            "Start Tensorboard with \"tensorboard --logdir runs/train\", view at http://localhost:6006/\n",
            "Hyperparameters {'lr0': 0.01, 'lrf': 0.2, 'momentum': 0.937, 'weight_decay': 0.0005, 'warmup_epochs': 3.0, 'warmup_momentum': 0.8, 'warmup_bias_lr': 0.1, 'box': 0.05, 'cls': 0.5, 'cls_pw': 1.0, 'obj': 1.0, 'obj_pw': 1.0, 'iou_t': 0.2, 'anchor_t': 4.0, 'fl_gamma': 0.0, 'hsv_h': 0.015, 'hsv_s': 0.7, 'hsv_v': 0.4, 'degrees': 0.0, 'translate': 0.5, 'scale': 0.5, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.5, 'mosaic': 1.0, 'mixup': 0.0}\n",
            "Downloading https://github.com/WongKinYiu/yolor/releases/download/v1.0/yolor_p6.pt to /content/yolor/yolor_p6.pt...\n",
            "ERROR: Download failure.\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/yolor/train.py\", line 537, in <module>\n",
            "    train(hyp, opt, device, tb_writer, wandb)\n",
            "  File \"/content/yolor/train.py\", line 80, in train\n",
            "    ckpt = torch.load(weights, map_location=device)  # load checkpoint\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 791, in load\n",
            "    with _open_file_like(f, 'rb') as opened_file:\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 271, in _open_file_like\n",
            "    return _open_file(name_or_buffer, mode)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 252, in __init__\n",
            "    super().__init__(open(name, mode))\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/yolor/yolor_p6.pt'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FAbe94smXcg0"
      },
      "source": [
        "# Evaluate Custom YOLOR Detector Performance\n",
        "\n",
        "Training losses and performance metrics are saved to Tensorboard and also to a logfile defined above with the **--name** flag when we train. In our case, we named this `yolor_p6`. (If given no name, it defaults to `results.txt`.) The results file is plotted as a png after training completes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Kha-ehkX1qP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 821
        },
        "outputId": "9300f585-59ec-4715-9cfa-5b93babe8e98"
      },
      "source": [
        "# Start tensorboard\n",
        "# Launch after you have started training\n",
        "# logs save in the folder \"runs\"\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir runs"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        (async () => {\n",
              "            const url = new URL(await google.colab.kernel.proxyPort(6006, {'cache': true}));\n",
              "            url.searchParams.set('tensorboardColab', 'true');\n",
              "            const iframe = document.createElement('iframe');\n",
              "            iframe.src = url;\n",
              "            iframe.setAttribute('width', '100%');\n",
              "            iframe.setAttribute('height', '800');\n",
              "            iframe.setAttribute('frameborder', 0);\n",
              "            document.body.appendChild(iframe);\n",
              "        })();\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MGnkowATX4ZS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        },
        "outputId": "9046abb2-9e0b-4300-f197-b8e03f0b0924"
      },
      "source": [
        "from IPython.display import Image\n",
        "# we can also output some older school graphs if the tensor board isn't working for whatever reason... \n",
        "from utils.plots import plot_results  # plot results.txt as results.png\n",
        "Image(filename='/content/yolor/runs/train/yolor_p64/results.png', width=1000)  # view results.png"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-be507ba6b9e3>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# we can also output some older school graphs if the tensor board isn't working for whatever reason...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplots\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mplot_results\u001b[0m  \u001b[0;31m# plot results.txt as results.png\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/content/yolor/runs/train/yolor_p64/results.png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# view results.png\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/display.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, url, filename, format, embed, width, height, retina, unconfined, metadata)\u001b[0m\n\u001b[1;32m   1229\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretina\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mretina\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1230\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munconfined\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munconfined\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1231\u001b[0;31m         super(Image, self).__init__(data=data, url=url, filename=filename, \n\u001b[0m\u001b[1;32m   1232\u001b[0m                 metadata=metadata)\n\u001b[1;32m   1233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/display.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, url, filename, metadata)\u001b[0m\n\u001b[1;32m    635\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 637\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    638\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    639\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/display.py\u001b[0m in \u001b[0;36mreload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1261\u001b[0m         \u001b[0;34m\"\"\"Reload the raw data from file or URL.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1262\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1263\u001b[0;31m             \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1264\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretina\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1265\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_retina_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/display.py\u001b[0m in \u001b[0;36mreload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    660\u001b[0m         \u001b[0;34m\"\"\"Reload the raw data from file or URL.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 662\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_flags\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    663\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    664\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/yolor/runs/train/yolor_p64/results.png'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jyp7zrtBX6wc"
      },
      "source": [
        "# first, display our ground truth data\n",
        "print(\"GROUND TRUTH TRAINING DATA:\")\n",
        "Image(filename='/content/yolor/runs/train/yolor_p6/train_batch0.jpg', width=900)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kDDz3cWgq4gQ"
      },
      "source": [
        "print(\"AUGMENTED DATA:\")\n",
        "Image(filename='/content/yolor/runs/train/yolor_p6/train_batch1.jpg', width=900)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mqYf31oCYYRn"
      },
      "source": [
        "#Run Inference  With Trained Weights\n",
        "Run inference with a pretrained checkpoint on contents of `test/images` folder downloaded from Roboflow."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QwuHFc3nYf7J"
      },
      "source": [
        "# trained weights are saved by default in our weights folder\n",
        "%ls runs/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "liYDNniHYiKq"
      },
      "source": [
        "%ls runs/train/yolor_p6/weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%pwd"
      ],
      "metadata": {
        "id": "Q7mWvRGf1AwT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLG0HPpbtpK0"
      },
      "source": [
        "# Create names file for model\n",
        "%cd /content/yolor/Kvasir-SEG-1/\n",
        "import yaml\n",
        "import ast\n",
        "with open(\"data.yaml\", 'r') as stream:\n",
        "    names = str(yaml.safe_load(stream)['names'])\n",
        "\n",
        "namesFile = open(\"../data.names\", \"w+\")\n",
        "names = ast.literal_eval(names)\n",
        "for name in names:\n",
        "  namesFile.write(name +'\\n')\n",
        "namesFile.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SfObNHTCYqih"
      },
      "source": [
        "%cd /content/yolor\n",
        "%time\n",
        "!python detect.py --weights \"runs/train/yolor_p64/weights/best_overall.pt\" --conf 0.5 --source /content/yolor/Kvasir-SEG-1/test/images/ --names /content/yolor/data.names --cfg cfg/yolor_p6.cfg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBeuZJA4s2Zh"
      },
      "source": [
        "#display inference on ALL test images\n",
        "#this looks much better with longer training above\n",
        "\n",
        "import glob\n",
        "from IPython.display import Image, display\n",
        "\n",
        "for imageName in glob.glob('/content/yolor/inference/output/*.jpg'): #assuming JPG\n",
        "    display(Image(filename=imageName))\n",
        "    print(\"\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_XUnMCThYM3W"
      },
      "source": [
        "# Export Trained Weights for Future Inference\n",
        "\n",
        "Now that you have trained your custom detector, you can export the trained weights you have made here for inference on your device elsewhere"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mP8-UrwiYP8j"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZ-zspK3YQlr"
      },
      "source": [
        "%cp /content/yolor/runs/train/yolor_p6/weights/best.pt /content/gdrive/My\\ Drive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dQrUGu9nYI-T"
      },
      "source": [
        "## Congrats!\n",
        "\n",
        "Hope you enjoyed this!\n",
        "\n",
        "--Team [Roboflow](https://roboflow.ai)"
      ]
    }
  ]
}