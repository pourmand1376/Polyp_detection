{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Kvasir-SEG-YOLOX.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pourmand1376/Polyp_detection/blob/main/Kvasir_SEG_YOLOX.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xru6s6p6A18s"
      },
      "source": [
        "# How to Train YOLOX on Custom Objects\n",
        "\n",
        "This tutorial is based on the [YOLOX repository](https://github.com/Megvii-BaseDetection/YOLOX) by [the Megvii Team](https://github.com/Megvii-BaseDetection). This notebook shows training on **your own custom objects**. Many thanks to the Megvii Team for putting this repository together - we hope that in combination with clean data management tools at Roboflow, this technologoy will become easily accessible to any developer wishing to use computer vision in their projects.\n",
        "\n",
        "### Accompanying Blog Post\n",
        "\n",
        "We recommend that you follow along in this notebook while reading the blog post on [How to Train YOLOX](blog.roboflow.com/how-to-train-yolox-on-a-custom-dataset/), concurrently.\n",
        "\n",
        "### Steps Covered in this Tutorial\n",
        "\n",
        "In this tutorial, we will walk through the steps required to train YOLOR on your custom objects. We use a [public blood cell detection dataset](https://public.roboflow.ai/object-detection/bccd), which is open source and free to use. You can also use this notebook on your own data. We will use Roboflow to preprocess our images.\n",
        "\n",
        "To train our detector we take the following steps:\n",
        "\n",
        "* Install YOLOX dependencies\n",
        "* Download and Prepare custom YOLOX object detection data\n",
        "* Download Pre-Trained Weights for YOLOX\n",
        "* Run YOLOX training\n",
        "* Evaluate YOLOX performance\n",
        "* Run YOLOX inference on test images\n",
        "* Export saved YOLOX weights for future inference\n",
        "\n",
        "### **About**\n",
        "\n",
        "[Roboflow](https://roboflow.com) enables teams to deploy custom computer vision models quickly and accurately. Convert data from to annotation format, assess dataset health, preprocess, augment, and more. It's free for your first 1000 source images.\n",
        "\n",
        "**Looking for a vision model available via API without hassle? Try Roboflow Train.**\n",
        "\n",
        "![Roboflow Wordmark](https://i.imgur.com/dcLNMhV.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VfVlxlYYBR6z"
      },
      "source": [
        "# Install YOLOX Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "igwruhYxE_a7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d27ed7d-1251-4fee-e44b-376ce62db28e"
      },
      "source": [
        "!git clone https://github.com/roboflow-ai/YOLOX.git\n",
        "%cd YOLOX\n",
        "!pip3 install -U pip && pip3 install -r requirements.txt\n",
        "!pip3 install -v -e .  \n",
        "!pip uninstall -y torch torchvision torchaudio\n",
        "# May need to change in the future if Colab no longer uses CUDA 11.0\n",
        "!pip install torch==1.8.0+cu111 torchvision==0.9.0+cu111 torchaudio==0.8.0 -f https://download.pytorch.org/whl/torch_stable.html"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'YOLOX'...\n",
            "remote: Enumerating objects: 786, done.\u001b[K\n",
            "remote: Total 786 (delta 0), reused 0 (delta 0), pack-reused 786\u001b[K\n",
            "Receiving objects: 100% (786/786), 5.78 MiB | 18.84 MiB/s, done.\n",
            "Resolving deltas: 100% (416/416), done.\n",
            "/content/YOLOX\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (21.1.3)\n",
            "Collecting pip\n",
            "  Downloading pip-22.0.4-py3-none-any.whl (2.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1 MB 6.8 MB/s \n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 21.1.3\n",
            "    Uninstalling pip-21.1.3:\n",
            "      Successfully uninstalled pip-21.1.3\n",
            "Successfully installed pip-22.0.4\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 2)) (1.21.5)\n",
            "Requirement already satisfied: torch>=1.7 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 3)) (1.10.0+cu111)\n",
            "Requirement already satisfied: opencv_python in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 4)) (4.1.2.30)\n",
            "Collecting loguru\n",
            "  Downloading loguru-0.6.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 KB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-image in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 6)) (0.18.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 7)) (4.63.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 8)) (0.11.1+cu111)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 9)) (7.1.2)\n",
            "Collecting thop\n",
            "  Downloading thop-0.0.31.post2005241907-py3-none-any.whl (8.7 kB)\n",
            "Collecting ninja\n",
            "  Downloading ninja-1.10.2.3-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (108 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.1/108.1 KB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 12)) (0.8.9)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 13)) (2.8.0)\n",
            "Collecting onnx==1.8.1\n",
            "  Downloading onnx-1.8.1-cp37-cp37m-manylinux2010_x86_64.whl (14.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.5/14.5 MB\u001b[0m \u001b[31m52.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting onnxruntime==1.8.0\n",
            "  Downloading onnxruntime-1.8.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m67.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting onnx-simplifier==0.3.5\n",
            "  Downloading onnx-simplifier-0.3.5.tar.gz (13 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from onnx==1.8.1->-r requirements.txt (line 16)) (1.15.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from onnx==1.8.1->-r requirements.txt (line 16)) (3.17.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.7/dist-packages (from onnx==1.8.1->-r requirements.txt (line 16)) (3.10.0.2)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.7/dist-packages (from onnxruntime==1.8.0->-r requirements.txt (line 17)) (2.0)\n",
            "Collecting onnxoptimizer>=0.2.5\n",
            "  Downloading onnxoptimizer-0.2.6-cp37-cp37m-manylinux2014_x86_64.whl (466 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m466.1/466.1 KB\u001b[0m \u001b[31m34.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->-r requirements.txt (line 6)) (2.6.3)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image->-r requirements.txt (line 6)) (2021.11.2)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->-r requirements.txt (line 6)) (3.2.2)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->-r requirements.txt (line 6)) (2.4.1)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image->-r requirements.txt (line 6)) (1.2.0)\n",
            "Requirement already satisfied: scipy>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image->-r requirements.txt (line 6)) (1.4.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 13)) (3.3.6)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 13)) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 13)) (1.8.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 13)) (57.4.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 13)) (0.4.6)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 13)) (1.44.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 13)) (0.6.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 13)) (1.0.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 13)) (1.35.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 13)) (0.37.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 13)) (2.23.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 13)) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 13)) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 13)) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->-r requirements.txt (line 13)) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard->-r requirements.txt (line 13)) (4.11.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->-r requirements.txt (line 6)) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->-r requirements.txt (line 6)) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->-r requirements.txt (line 6)) (1.3.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->-r requirements.txt (line 6)) (3.0.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->-r requirements.txt (line 13)) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->-r requirements.txt (line 13)) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->-r requirements.txt (line 13)) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->-r requirements.txt (line 13)) (3.0.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard->-r requirements.txt (line 13)) (3.7.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 13)) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->-r requirements.txt (line 13)) (3.2.0)\n",
            "Building wheels for collected packages: onnx-simplifier\n",
            "  Building wheel for onnx-simplifier (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for onnx-simplifier: filename=onnx_simplifier-0.3.5-py3-none-any.whl size=12878 sha256=08e631c15ca1237b8badb25e3fca70d4710de4190458123c6fdf15e4fa84d7be\n",
            "  Stored in directory: /root/.cache/pip/wheels/8a/b4/1b/6acdd4eb854b215cd4aa1c18ca79399f9d34728edaff47ecce\n",
            "Successfully built onnx-simplifier\n",
            "Installing collected packages: ninja, loguru, thop, onnxruntime, onnx, onnxoptimizer, onnx-simplifier\n",
            "Successfully installed loguru-0.6.0 ninja-1.10.2.3 onnx-1.8.1 onnx-simplifier-0.3.5 onnxoptimizer-0.2.6 onnxruntime-1.8.0 thop-0.0.31.post2005241907\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mUsing pip 22.0.4 from /usr/local/lib/python3.7/dist-packages/pip (python 3.7)\n",
            "Obtaining file:///content/YOLOX\n",
            "  Running command python setup.py egg_info\n",
            "  running egg_info\n",
            "  creating /tmp/pip-pip-egg-info-qxt1n0oa/yolox.egg-info\n",
            "  writing /tmp/pip-pip-egg-info-qxt1n0oa/yolox.egg-info/PKG-INFO\n",
            "  writing dependency_links to /tmp/pip-pip-egg-info-qxt1n0oa/yolox.egg-info/dependency_links.txt\n",
            "  writing top-level names to /tmp/pip-pip-egg-info-qxt1n0oa/yolox.egg-info/top_level.txt\n",
            "  writing manifest file '/tmp/pip-pip-egg-info-qxt1n0oa/yolox.egg-info/SOURCES.txt'\n",
            "  adding license file 'LICENSE'\n",
            "  writing manifest file '/tmp/pip-pip-egg-info-qxt1n0oa/yolox.egg-info/SOURCES.txt'\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Installing collected packages: yolox\n",
            "  Running setup.py develop for yolox\n",
            "    Running command python setup.py develop\n",
            "    running develop\n",
            "    running egg_info\n",
            "    creating yolox.egg-info\n",
            "    writing yolox.egg-info/PKG-INFO\n",
            "    writing dependency_links to yolox.egg-info/dependency_links.txt\n",
            "    writing top-level names to yolox.egg-info/top_level.txt\n",
            "    writing manifest file 'yolox.egg-info/SOURCES.txt'\n",
            "    adding license file 'LICENSE'\n",
            "    writing manifest file 'yolox.egg-info/SOURCES.txt'\n",
            "    running build_ext\n",
            "    building 'yolox._C' extension\n",
            "    creating /content/YOLOX/build\n",
            "    creating /content/YOLOX/build/temp.linux-x86_64-3.7\n",
            "    creating /content/YOLOX/build/temp.linux-x86_64-3.7/content\n",
            "    creating /content/YOLOX/build/temp.linux-x86_64-3.7/content/YOLOX\n",
            "    creating /content/YOLOX/build/temp.linux-x86_64-3.7/content/YOLOX/yolox\n",
            "    creating /content/YOLOX/build/temp.linux-x86_64-3.7/content/YOLOX/yolox/layers\n",
            "    creating /content/YOLOX/build/temp.linux-x86_64-3.7/content/YOLOX/yolox/layers/csrc\n",
            "    creating /content/YOLOX/build/temp.linux-x86_64-3.7/content/YOLOX/yolox/layers/csrc/cocoeval\n",
            "    Emitting ninja build file /content/YOLOX/build/temp.linux-x86_64-3.7/build.ninja...\n",
            "    Compiling objects...\n",
            "    Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
            "    [1/2] c++ -MMD -MF /content/YOLOX/build/temp.linux-x86_64-3.7/content/YOLOX/yolox/layers/csrc/cocoeval/cocoeval.o.d -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-pX47U3/python3.7-3.7.12=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-pX47U3/python3.7-3.7.12=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/content/YOLOX/yolox/layers/csrc -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/include/python3.7m -c -c /content/YOLOX/yolox/layers/csrc/cocoeval/cocoeval.cpp -o /content/YOLOX/build/temp.linux-x86_64-3.7/content/YOLOX/yolox/layers/csrc/cocoeval/cocoeval.o -O3 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "    [2/2] c++ -MMD -MF /content/YOLOX/build/temp.linux-x86_64-3.7/content/YOLOX/yolox/layers/csrc/vision.o.d -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-pX47U3/python3.7-3.7.12=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-pX47U3/python3.7-3.7.12=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/content/YOLOX/yolox/layers/csrc -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/include/python3.7m -c -c /content/YOLOX/yolox/layers/csrc/vision.cpp -o /content/YOLOX/build/temp.linux-x86_64-3.7/content/YOLOX/yolox/layers/csrc/vision.o -O3 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "    creating build/lib.linux-x86_64-3.7\n",
            "    creating build/lib.linux-x86_64-3.7/yolox\n",
            "    x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fdebug-prefix-map=/build/python3.7-pX47U3/python3.7-3.7.12=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 /content/YOLOX/build/temp.linux-x86_64-3.7/content/YOLOX/yolox/layers/csrc/vision.o /content/YOLOX/build/temp.linux-x86_64-3.7/content/YOLOX/yolox/layers/csrc/cocoeval/cocoeval.o -L/usr/local/lib/python3.7/dist-packages/torch/lib -lc10 -ltorch -ltorch_cpu -ltorch_python -o build/lib.linux-x86_64-3.7/yolox/_C.cpython-37m-x86_64-linux-gnu.so\n",
            "    copying build/lib.linux-x86_64-3.7/yolox/_C.cpython-37m-x86_64-linux-gnu.so -> yolox\n",
            "    Creating /usr/local/lib/python3.7/dist-packages/yolox.egg-link (link to .)\n",
            "    Adding yolox 0.1.0 to easy-install.pth file\n",
            "\n",
            "    Installed /content/YOLOX\n",
            "Successfully installed yolox-0.1.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mFound existing installation: torch 1.10.0+cu111\n",
            "Uninstalling torch-1.10.0+cu111:\n",
            "  Successfully uninstalled torch-1.10.0+cu111\n",
            "Found existing installation: torchvision 0.11.1+cu111\n",
            "Uninstalling torchvision-0.11.1+cu111:\n",
            "  Successfully uninstalled torchvision-0.11.1+cu111\n",
            "Found existing installation: torchaudio 0.10.0+cu111\n",
            "Uninstalling torchaudio-0.10.0+cu111:\n",
            "  Successfully uninstalled torchaudio-0.10.0+cu111\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mLooking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.8.0+cu111\n",
            "  Downloading https://download.pytorch.org/whl/cu111/torch-1.8.0%2Bcu111-cp37-cp37m-linux_x86_64.whl (1982.2 MB)\n",
            "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m2.0/2.0 GB\u001b[0m \u001b[31m74.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0mtcmalloc: large alloc 1982251008 bytes == 0x55f2c6314000 @  0x7f5a3fbc21e7 0x55f2c290b5d7 0x55f2c28d53bc 0x55f2c29b618a 0x55f2c28d81cd 0x55f2c29cab3d 0x55f2c294c458 0x55f2c294702f 0x55f2c28d9aba 0x55f2c2948108 0x55f2c294702f 0x55f2c28d9aba 0x55f2c2948108 0x55f2c294702f 0x55f2c28d9aba 0x55f2c2948108 0x55f2c294702f 0x55f2c28d9aba 0x55f2c2948108 0x55f2c294702f 0x55f2c28d9aba 0x55f2c2948108 0x55f2c28d99da 0x55f2c2948108 0x55f2c294702f 0x55f2c28d9aba 0x55f2c2948cd4 0x55f2c294702f 0x55f2c28d9aba 0x55f2c2948108 0x55f2c294702f\n",
            "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m2.0/2.0 GB\u001b[0m \u001b[31m71.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0mtcmalloc: large alloc 2477817856 bytes == 0x55f33c580000 @  0x7f5a3fbc3615 0x55f2c28d53bc 0x55f2c29b618a 0x55f2c28d81cd 0x55f2c29cab3d 0x55f2c294c458 0x55f2c294702f 0x55f2c28d9aba 0x55f2c2948108 0x55f2c294702f 0x55f2c28d9aba 0x55f2c2948108 0x55f2c294702f 0x55f2c28d9aba 0x55f2c2948108 0x55f2c294702f 0x55f2c28d9aba 0x55f2c2948108 0x55f2c294702f 0x55f2c28d9aba 0x55f2c2948108 0x55f2c28d99da 0x55f2c2948108 0x55f2c294702f 0x55f2c28d9aba 0x55f2c2948cd4 0x55f2c294702f 0x55f2c28d9aba 0x55f2c2948108 0x55f2c294702f 0x55f2c28da151\n",
            "tcmalloc: large alloc 1982251008 bytes == 0x55f2c6314000 @  0x7f5a3fbc21e7 0x55f2c290a518 0x55f2c28d4d17 0x55f2c28d6d00 0x55f2c28d81cd 0x55f2c29cab3d 0x55f2c294c458 0x55f2c294702f 0x55f2c28d9aba 0x55f2c2948108 0x55f2c294702f 0x55f2c28da151 0x55f2c28da571 0x55f2c2a4a442 0x55f2c28d8b32 0x55f2c294ca6d 0x55f2c28d99da 0x55f2c294c2c0 0x55f2c294702f 0x55f2c28d9aba 0x55f2c294c2c0 0x55f2c294702f 0x55f2c28d9aba 0x55f2c2948cd4 0x55f2c29cb986 0x55f2c2948350 0x55f2c29cb986 0x55f2c2948350 0x55f2c29cb986 0x55f2c2948350 0x55f2c28d9f19\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 GB\u001b[0m \u001b[31m843.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision==0.9.0+cu111\n",
            "  Downloading https://download.pytorch.org/whl/cu111/torchvision-0.9.0%2Bcu111-cp37-cp37m-linux_x86_64.whl (17.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchaudio==0.8.0\n",
            "  Downloading torchaudio-0.8.0-cp37-cp37m-manylinux1_x86_64.whl (1.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.0+cu111) (3.10.0.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.8.0+cu111) (1.21.5)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.9.0+cu111) (7.1.2)\n",
            "Installing collected packages: torch, torchvision, torchaudio\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.11.0 requires torch==1.10.0, but you have torch 1.8.0+cu111 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed torch-1.8.0+cu111 torchaudio-0.8.0 torchvision-0.9.0+cu111\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "llsu3xhVBZYC"
      },
      "source": [
        "## Install Nvidia Apex"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ksHd57LFFMzK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02ad13d3-f0ed-4d5d-dad1-24a81fa51d56"
      },
      "source": [
        "%cd /content/\n",
        "!git clone https://github.com/NVIDIA/apex\n",
        "%cd apex\n",
        "!pip install -v --disable-pip-version-check --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ./"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'apex'...\n",
            "remote: Enumerating objects: 9079, done.\u001b[K\n",
            "remote: Counting objects: 100% (150/150), done.\u001b[K\n",
            "remote: Compressing objects: 100% (125/125), done.\u001b[K\n",
            "remote: Total 9079 (delta 83), reused 41 (delta 24), pack-reused 8929\u001b[K\n",
            "Receiving objects: 100% (9079/9079), 14.59 MiB | 19.87 MiB/s, done.\n",
            "Resolving deltas: 100% (6196/6196), done.\n",
            "/content/apex\n",
            "\u001b[33mWARNING: Disabling all use of wheels due to the use of --build-option / --global-option / --install-option.\u001b[0m\u001b[33m\n",
            "\u001b[0mUsing pip 22.0.4 from /usr/local/lib/python3.7/dist-packages/pip (python 3.7)\n",
            "Processing /content/apex\n",
            "  Running command python setup.py egg_info\n",
            "\n",
            "\n",
            "  torch.__version__  = 1.8.0+cu111\n",
            "\n",
            "\n",
            "  running egg_info\n",
            "  creating /tmp/pip-pip-egg-info-cygeeytc/apex.egg-info\n",
            "  writing /tmp/pip-pip-egg-info-cygeeytc/apex.egg-info/PKG-INFO\n",
            "  writing dependency_links to /tmp/pip-pip-egg-info-cygeeytc/apex.egg-info/dependency_links.txt\n",
            "  writing top-level names to /tmp/pip-pip-egg-info-cygeeytc/apex.egg-info/top_level.txt\n",
            "  writing manifest file '/tmp/pip-pip-egg-info-cygeeytc/apex.egg-info/SOURCES.txt'\n",
            "  adding license file 'LICENSE'\n",
            "  writing manifest file '/tmp/pip-pip-egg-info-cygeeytc/apex.egg-info/SOURCES.txt'\n",
            "  /content/apex/setup.py:109: UserWarning: Option --pyprof not specified. Not installing PyProf dependencies!\n",
            "    warnings.warn(\"Option --pyprof not specified. Not installing PyProf dependencies!\")\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Skipping wheel build for apex, due to binaries being disabled for it.\n",
            "Installing collected packages: apex\n",
            "  Running command Running setup.py install for apex\n",
            "\n",
            "\n",
            "  torch.__version__  = 1.8.0+cu111\n",
            "\n",
            "\n",
            "  /content/apex/setup.py:109: UserWarning: Option --pyprof not specified. Not installing PyProf dependencies!\n",
            "    warnings.warn(\"Option --pyprof not specified. Not installing PyProf dependencies!\")\n",
            "\n",
            "  Compiling cuda extensions with\n",
            "  nvcc: NVIDIA (R) Cuda compiler driver\n",
            "  Copyright (c) 2005-2020 NVIDIA Corporation\n",
            "  Built on Mon_Oct_12_20:09:46_PDT_2020\n",
            "  Cuda compilation tools, release 11.1, V11.1.105\n",
            "  Build cuda_11.1.TC455_06.29190527_0\n",
            "  from /usr/local/cuda/bin\n",
            "\n",
            "  running install\n",
            "  running build\n",
            "  running build_py\n",
            "  creating build\n",
            "  creating build/lib.linux-x86_64-3.7\n",
            "  creating build/lib.linux-x86_64-3.7/apex\n",
            "  copying apex/__init__.py -> build/lib.linux-x86_64-3.7/apex\n",
            "  copying apex/_autocast_utils.py -> build/lib.linux-x86_64-3.7/apex\n",
            "  creating build/lib.linux-x86_64-3.7/apex/pyprof\n",
            "  copying apex/pyprof/__init__.py -> build/lib.linux-x86_64-3.7/apex/pyprof\n",
            "  creating build/lib.linux-x86_64-3.7/apex/optimizers\n",
            "  copying apex/optimizers/fused_adam.py -> build/lib.linux-x86_64-3.7/apex/optimizers\n",
            "  copying apex/optimizers/fused_adagrad.py -> build/lib.linux-x86_64-3.7/apex/optimizers\n",
            "  copying apex/optimizers/__init__.py -> build/lib.linux-x86_64-3.7/apex/optimizers\n",
            "  copying apex/optimizers/fused_sgd.py -> build/lib.linux-x86_64-3.7/apex/optimizers\n",
            "  copying apex/optimizers/fused_lamb.py -> build/lib.linux-x86_64-3.7/apex/optimizers\n",
            "  copying apex/optimizers/fused_novograd.py -> build/lib.linux-x86_64-3.7/apex/optimizers\n",
            "  copying apex/optimizers/fused_mixed_precision_lamb.py -> build/lib.linux-x86_64-3.7/apex/optimizers\n",
            "  creating build/lib.linux-x86_64-3.7/apex/parallel\n",
            "  copying apex/parallel/LARC.py -> build/lib.linux-x86_64-3.7/apex/parallel\n",
            "  copying apex/parallel/__init__.py -> build/lib.linux-x86_64-3.7/apex/parallel\n",
            "  copying apex/parallel/distributed.py -> build/lib.linux-x86_64-3.7/apex/parallel\n",
            "  copying apex/parallel/sync_batchnorm.py -> build/lib.linux-x86_64-3.7/apex/parallel\n",
            "  copying apex/parallel/optimized_sync_batchnorm.py -> build/lib.linux-x86_64-3.7/apex/parallel\n",
            "  copying apex/parallel/optimized_sync_batchnorm_kernel.py -> build/lib.linux-x86_64-3.7/apex/parallel\n",
            "  copying apex/parallel/multiproc.py -> build/lib.linux-x86_64-3.7/apex/parallel\n",
            "  copying apex/parallel/sync_batchnorm_kernel.py -> build/lib.linux-x86_64-3.7/apex/parallel\n",
            "  creating build/lib.linux-x86_64-3.7/apex/mlp\n",
            "  copying apex/mlp/__init__.py -> build/lib.linux-x86_64-3.7/apex/mlp\n",
            "  copying apex/mlp/mlp.py -> build/lib.linux-x86_64-3.7/apex/mlp\n",
            "  creating build/lib.linux-x86_64-3.7/apex/transformer\n",
            "  copying apex/transformer/enums.py -> build/lib.linux-x86_64-3.7/apex/transformer\n",
            "  copying apex/transformer/microbatches.py -> build/lib.linux-x86_64-3.7/apex/transformer\n",
            "  copying apex/transformer/__init__.py -> build/lib.linux-x86_64-3.7/apex/transformer\n",
            "  copying apex/transformer/log_util.py -> build/lib.linux-x86_64-3.7/apex/transformer\n",
            "  copying apex/transformer/utils.py -> build/lib.linux-x86_64-3.7/apex/transformer\n",
            "  copying apex/transformer/parallel_state.py -> build/lib.linux-x86_64-3.7/apex/transformer\n",
            "  creating build/lib.linux-x86_64-3.7/apex/normalization\n",
            "  copying apex/normalization/__init__.py -> build/lib.linux-x86_64-3.7/apex/normalization\n",
            "  copying apex/normalization/fused_layer_norm.py -> build/lib.linux-x86_64-3.7/apex/normalization\n",
            "  creating build/lib.linux-x86_64-3.7/apex/RNN\n",
            "  copying apex/RNN/__init__.py -> build/lib.linux-x86_64-3.7/apex/RNN\n",
            "  copying apex/RNN/cells.py -> build/lib.linux-x86_64-3.7/apex/RNN\n",
            "  copying apex/RNN/RNNBackend.py -> build/lib.linux-x86_64-3.7/apex/RNN\n",
            "  copying apex/RNN/models.py -> build/lib.linux-x86_64-3.7/apex/RNN\n",
            "  creating build/lib.linux-x86_64-3.7/apex/fused_dense\n",
            "  copying apex/fused_dense/__init__.py -> build/lib.linux-x86_64-3.7/apex/fused_dense\n",
            "  copying apex/fused_dense/fused_dense.py -> build/lib.linux-x86_64-3.7/apex/fused_dense\n",
            "  creating build/lib.linux-x86_64-3.7/apex/amp\n",
            "  copying apex/amp/wrap.py -> build/lib.linux-x86_64-3.7/apex/amp\n",
            "  copying apex/amp/scaler.py -> build/lib.linux-x86_64-3.7/apex/amp\n",
            "  copying apex/amp/__init__.py -> build/lib.linux-x86_64-3.7/apex/amp\n",
            "  copying apex/amp/amp.py -> build/lib.linux-x86_64-3.7/apex/amp\n",
            "  copying apex/amp/compat.py -> build/lib.linux-x86_64-3.7/apex/amp\n",
            "  copying apex/amp/frontend.py -> build/lib.linux-x86_64-3.7/apex/amp\n",
            "  copying apex/amp/utils.py -> build/lib.linux-x86_64-3.7/apex/amp\n",
            "  copying apex/amp/handle.py -> build/lib.linux-x86_64-3.7/apex/amp\n",
            "  copying apex/amp/__version__.py -> build/lib.linux-x86_64-3.7/apex/amp\n",
            "  copying apex/amp/_amp_state.py -> build/lib.linux-x86_64-3.7/apex/amp\n",
            "  copying apex/amp/opt.py -> build/lib.linux-x86_64-3.7/apex/amp\n",
            "  copying apex/amp/_initialize.py -> build/lib.linux-x86_64-3.7/apex/amp\n",
            "  copying apex/amp/rnn_compat.py -> build/lib.linux-x86_64-3.7/apex/amp\n",
            "  copying apex/amp/_process_optimizer.py -> build/lib.linux-x86_64-3.7/apex/amp\n",
            "  creating build/lib.linux-x86_64-3.7/apex/contrib\n",
            "  copying apex/contrib/__init__.py -> build/lib.linux-x86_64-3.7/apex/contrib\n",
            "  creating build/lib.linux-x86_64-3.7/apex/multi_tensor_apply\n",
            "  copying apex/multi_tensor_apply/__init__.py -> build/lib.linux-x86_64-3.7/apex/multi_tensor_apply\n",
            "  copying apex/multi_tensor_apply/multi_tensor_apply.py -> build/lib.linux-x86_64-3.7/apex/multi_tensor_apply\n",
            "  creating build/lib.linux-x86_64-3.7/apex/reparameterization\n",
            "  copying apex/reparameterization/__init__.py -> build/lib.linux-x86_64-3.7/apex/reparameterization\n",
            "  copying apex/reparameterization/weight_norm.py -> build/lib.linux-x86_64-3.7/apex/reparameterization\n",
            "  copying apex/reparameterization/reparameterization.py -> build/lib.linux-x86_64-3.7/apex/reparameterization\n",
            "  creating build/lib.linux-x86_64-3.7/apex/fp16_utils\n",
            "  copying apex/fp16_utils/__init__.py -> build/lib.linux-x86_64-3.7/apex/fp16_utils\n",
            "  copying apex/fp16_utils/fp16util.py -> build/lib.linux-x86_64-3.7/apex/fp16_utils\n",
            "  copying apex/fp16_utils/fp16_optimizer.py -> build/lib.linux-x86_64-3.7/apex/fp16_utils\n",
            "  copying apex/fp16_utils/loss_scaler.py -> build/lib.linux-x86_64-3.7/apex/fp16_utils\n",
            "  creating build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/pointwise.py -> build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/linear.py -> build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/dropout.py -> build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/blas.py -> build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/convert.py -> build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/normalization.py -> build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/__init__.py -> build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/usage.py -> build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/prof.py -> build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/data.py -> build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/recurrentCell.py -> build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/misc.py -> build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/__main__.py -> build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/activation.py -> build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/output.py -> build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/randomSample.py -> build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/optim.py -> build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/embedding.py -> build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/conv.py -> build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/reduction.py -> build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/softmax.py -> build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/loss.py -> build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/utility.py -> build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/base.py -> build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/index_slice_join_mutate.py -> build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/pooling.py -> build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
            "  creating build/lib.linux-x86_64-3.7/apex/pyprof/nvtx\n",
            "  copying apex/pyprof/nvtx/__init__.py -> build/lib.linux-x86_64-3.7/apex/pyprof/nvtx\n",
            "  copying apex/pyprof/nvtx/nvmarker.py -> build/lib.linux-x86_64-3.7/apex/pyprof/nvtx\n",
            "  creating build/lib.linux-x86_64-3.7/apex/pyprof/parse\n",
            "  copying apex/pyprof/parse/__init__.py -> build/lib.linux-x86_64-3.7/apex/pyprof/parse\n",
            "  copying apex/pyprof/parse/__main__.py -> build/lib.linux-x86_64-3.7/apex/pyprof/parse\n",
            "  copying apex/pyprof/parse/parse.py -> build/lib.linux-x86_64-3.7/apex/pyprof/parse\n",
            "  copying apex/pyprof/parse/kernel.py -> build/lib.linux-x86_64-3.7/apex/pyprof/parse\n",
            "  copying apex/pyprof/parse/nvvp.py -> build/lib.linux-x86_64-3.7/apex/pyprof/parse\n",
            "  copying apex/pyprof/parse/db.py -> build/lib.linux-x86_64-3.7/apex/pyprof/parse\n",
            "  creating build/lib.linux-x86_64-3.7/apex/transformer/pipeline_parallel\n",
            "  copying apex/transformer/pipeline_parallel/__init__.py -> build/lib.linux-x86_64-3.7/apex/transformer/pipeline_parallel\n",
            "  copying apex/transformer/pipeline_parallel/_timers.py -> build/lib.linux-x86_64-3.7/apex/transformer/pipeline_parallel\n",
            "  copying apex/transformer/pipeline_parallel/p2p_communication.py -> build/lib.linux-x86_64-3.7/apex/transformer/pipeline_parallel\n",
            "  copying apex/transformer/pipeline_parallel/utils.py -> build/lib.linux-x86_64-3.7/apex/transformer/pipeline_parallel\n",
            "  creating build/lib.linux-x86_64-3.7/apex/transformer/tensor_parallel\n",
            "  copying apex/transformer/tensor_parallel/random.py -> build/lib.linux-x86_64-3.7/apex/transformer/tensor_parallel\n",
            "  copying apex/transformer/tensor_parallel/layers.py -> build/lib.linux-x86_64-3.7/apex/transformer/tensor_parallel\n",
            "  copying apex/transformer/tensor_parallel/mappings.py -> build/lib.linux-x86_64-3.7/apex/transformer/tensor_parallel\n",
            "  copying apex/transformer/tensor_parallel/__init__.py -> build/lib.linux-x86_64-3.7/apex/transformer/tensor_parallel\n",
            "  copying apex/transformer/tensor_parallel/data.py -> build/lib.linux-x86_64-3.7/apex/transformer/tensor_parallel\n",
            "  copying apex/transformer/tensor_parallel/cross_entropy.py -> build/lib.linux-x86_64-3.7/apex/transformer/tensor_parallel\n",
            "  copying apex/transformer/tensor_parallel/utils.py -> build/lib.linux-x86_64-3.7/apex/transformer/tensor_parallel\n",
            "  copying apex/transformer/tensor_parallel/memory.py -> build/lib.linux-x86_64-3.7/apex/transformer/tensor_parallel\n",
            "  creating build/lib.linux-x86_64-3.7/apex/transformer/testing\n",
            "  copying apex/transformer/testing/commons.py -> build/lib.linux-x86_64-3.7/apex/transformer/testing\n",
            "  copying apex/transformer/testing/__init__.py -> build/lib.linux-x86_64-3.7/apex/transformer/testing\n",
            "  copying apex/transformer/testing/standalone_bert.py -> build/lib.linux-x86_64-3.7/apex/transformer/testing\n",
            "  copying apex/transformer/testing/standalone_gpt.py -> build/lib.linux-x86_64-3.7/apex/transformer/testing\n",
            "  copying apex/transformer/testing/global_vars.py -> build/lib.linux-x86_64-3.7/apex/transformer/testing\n",
            "  copying apex/transformer/testing/arguments.py -> build/lib.linux-x86_64-3.7/apex/transformer/testing\n",
            "  creating build/lib.linux-x86_64-3.7/apex/transformer/amp\n",
            "  copying apex/transformer/amp/__init__.py -> build/lib.linux-x86_64-3.7/apex/transformer/amp\n",
            "  copying apex/transformer/amp/grad_scaler.py -> build/lib.linux-x86_64-3.7/apex/transformer/amp\n",
            "  creating build/lib.linux-x86_64-3.7/apex/transformer/_data\n",
            "  copying apex/transformer/_data/__init__.py -> build/lib.linux-x86_64-3.7/apex/transformer/_data\n",
            "  copying apex/transformer/_data/_batchsampler.py -> build/lib.linux-x86_64-3.7/apex/transformer/_data\n",
            "  creating build/lib.linux-x86_64-3.7/apex/transformer/functional\n",
            "  copying apex/transformer/functional/__init__.py -> build/lib.linux-x86_64-3.7/apex/transformer/functional\n",
            "  copying apex/transformer/functional/fused_softmax.py -> build/lib.linux-x86_64-3.7/apex/transformer/functional\n",
            "  creating build/lib.linux-x86_64-3.7/apex/transformer/pipeline_parallel/schedules\n",
            "  copying apex/transformer/pipeline_parallel/schedules/fwd_bwd_pipelining_without_interleaving.py -> build/lib.linux-x86_64-3.7/apex/transformer/pipeline_parallel/schedules\n",
            "  copying apex/transformer/pipeline_parallel/schedules/fwd_bwd_pipelining_with_interleaving.py -> build/lib.linux-x86_64-3.7/apex/transformer/pipeline_parallel/schedules\n",
            "  copying apex/transformer/pipeline_parallel/schedules/__init__.py -> build/lib.linux-x86_64-3.7/apex/transformer/pipeline_parallel/schedules\n",
            "  copying apex/transformer/pipeline_parallel/schedules/common.py -> build/lib.linux-x86_64-3.7/apex/transformer/pipeline_parallel/schedules\n",
            "  copying apex/transformer/pipeline_parallel/schedules/fwd_bwd_no_pipelining.py -> build/lib.linux-x86_64-3.7/apex/transformer/pipeline_parallel/schedules\n",
            "  creating build/lib.linux-x86_64-3.7/apex/amp/lists\n",
            "  copying apex/amp/lists/__init__.py -> build/lib.linux-x86_64-3.7/apex/amp/lists\n",
            "  copying apex/amp/lists/tensor_overrides.py -> build/lib.linux-x86_64-3.7/apex/amp/lists\n",
            "  copying apex/amp/lists/torch_overrides.py -> build/lib.linux-x86_64-3.7/apex/amp/lists\n",
            "  copying apex/amp/lists/functional_overrides.py -> build/lib.linux-x86_64-3.7/apex/amp/lists\n",
            "  creating build/lib.linux-x86_64-3.7/apex/contrib/xentropy\n",
            "  copying apex/contrib/xentropy/__init__.py -> build/lib.linux-x86_64-3.7/apex/contrib/xentropy\n",
            "  copying apex/contrib/xentropy/softmax_xentropy.py -> build/lib.linux-x86_64-3.7/apex/contrib/xentropy\n",
            "  creating build/lib.linux-x86_64-3.7/apex/contrib/optimizers\n",
            "  copying apex/contrib/optimizers/fused_adam.py -> build/lib.linux-x86_64-3.7/apex/contrib/optimizers\n",
            "  copying apex/contrib/optimizers/__init__.py -> build/lib.linux-x86_64-3.7/apex/contrib/optimizers\n",
            "  copying apex/contrib/optimizers/fused_sgd.py -> build/lib.linux-x86_64-3.7/apex/contrib/optimizers\n",
            "  copying apex/contrib/optimizers/distributed_fused_lamb.py -> build/lib.linux-x86_64-3.7/apex/contrib/optimizers\n",
            "  copying apex/contrib/optimizers/fp16_optimizer.py -> build/lib.linux-x86_64-3.7/apex/contrib/optimizers\n",
            "  copying apex/contrib/optimizers/distributed_fused_adam_v3.py -> build/lib.linux-x86_64-3.7/apex/contrib/optimizers\n",
            "  copying apex/contrib/optimizers/distributed_fused_adam_v2.py -> build/lib.linux-x86_64-3.7/apex/contrib/optimizers\n",
            "  copying apex/contrib/optimizers/fused_lamb.py -> build/lib.linux-x86_64-3.7/apex/contrib/optimizers\n",
            "  copying apex/contrib/optimizers/distributed_fused_adam.py -> build/lib.linux-x86_64-3.7/apex/contrib/optimizers\n",
            "  creating build/lib.linux-x86_64-3.7/apex/contrib/transducer\n",
            "  copying apex/contrib/transducer/__init__.py -> build/lib.linux-x86_64-3.7/apex/contrib/transducer\n",
            "  copying apex/contrib/transducer/transducer.py -> build/lib.linux-x86_64-3.7/apex/contrib/transducer\n",
            "  creating build/lib.linux-x86_64-3.7/apex/contrib/layer_norm\n",
            "  copying apex/contrib/layer_norm/__init__.py -> build/lib.linux-x86_64-3.7/apex/contrib/layer_norm\n",
            "  copying apex/contrib/layer_norm/layer_norm.py -> build/lib.linux-x86_64-3.7/apex/contrib/layer_norm\n",
            "  creating build/lib.linux-x86_64-3.7/apex/contrib/multihead_attn\n",
            "  copying apex/contrib/multihead_attn/mask_softmax_dropout_func.py -> build/lib.linux-x86_64-3.7/apex/contrib/multihead_attn\n",
            "  copying apex/contrib/multihead_attn/__init__.py -> build/lib.linux-x86_64-3.7/apex/contrib/multihead_attn\n",
            "  copying apex/contrib/multihead_attn/fast_encdec_multihead_attn_norm_add_func.py -> build/lib.linux-x86_64-3.7/apex/contrib/multihead_attn\n",
            "  copying apex/contrib/multihead_attn/fast_self_multihead_attn_func.py -> build/lib.linux-x86_64-3.7/apex/contrib/multihead_attn\n",
            "  copying apex/contrib/multihead_attn/self_multihead_attn_func.py -> build/lib.linux-x86_64-3.7/apex/contrib/multihead_attn\n",
            "  copying apex/contrib/multihead_attn/fast_self_multihead_attn_norm_add_func.py -> build/lib.linux-x86_64-3.7/apex/contrib/multihead_attn\n",
            "  copying apex/contrib/multihead_attn/encdec_multihead_attn_func.py -> build/lib.linux-x86_64-3.7/apex/contrib/multihead_attn\n",
            "  copying apex/contrib/multihead_attn/fast_encdec_multihead_attn_func.py -> build/lib.linux-x86_64-3.7/apex/contrib/multihead_attn\n",
            "  copying apex/contrib/multihead_attn/encdec_multihead_attn.py -> build/lib.linux-x86_64-3.7/apex/contrib/multihead_attn\n",
            "  copying apex/contrib/multihead_attn/self_multihead_attn.py -> build/lib.linux-x86_64-3.7/apex/contrib/multihead_attn\n",
            "  creating build/lib.linux-x86_64-3.7/apex/contrib/groupbn\n",
            "  copying apex/contrib/groupbn/__init__.py -> build/lib.linux-x86_64-3.7/apex/contrib/groupbn\n",
            "  copying apex/contrib/groupbn/batch_norm.py -> build/lib.linux-x86_64-3.7/apex/contrib/groupbn\n",
            "  creating build/lib.linux-x86_64-3.7/apex/contrib/fmha\n",
            "  copying apex/contrib/fmha/__init__.py -> build/lib.linux-x86_64-3.7/apex/contrib/fmha\n",
            "  copying apex/contrib/fmha/fmha.py -> build/lib.linux-x86_64-3.7/apex/contrib/fmha\n",
            "  creating build/lib.linux-x86_64-3.7/apex/contrib/sparsity\n",
            "  copying apex/contrib/sparsity/sparse_masklib.py -> build/lib.linux-x86_64-3.7/apex/contrib/sparsity\n",
            "  copying apex/contrib/sparsity/__init__.py -> build/lib.linux-x86_64-3.7/apex/contrib/sparsity\n",
            "  copying apex/contrib/sparsity/asp.py -> build/lib.linux-x86_64-3.7/apex/contrib/sparsity\n",
            "  copying apex/contrib/sparsity/permutation_lib.py -> build/lib.linux-x86_64-3.7/apex/contrib/sparsity\n",
            "  creating build/lib.linux-x86_64-3.7/apex/contrib/bottleneck\n",
            "  copying apex/contrib/bottleneck/__init__.py -> build/lib.linux-x86_64-3.7/apex/contrib/bottleneck\n",
            "  copying apex/contrib/bottleneck/bottleneck.py -> build/lib.linux-x86_64-3.7/apex/contrib/bottleneck\n",
            "  copying apex/contrib/bottleneck/bottleneck_module_test.py -> build/lib.linux-x86_64-3.7/apex/contrib/bottleneck\n",
            "  copying apex/contrib/bottleneck/test.py -> build/lib.linux-x86_64-3.7/apex/contrib/bottleneck\n",
            "  creating build/lib.linux-x86_64-3.7/apex/contrib/sparsity/permutation_search_kernels\n",
            "  copying apex/contrib/sparsity/permutation_search_kernels/__init__.py -> build/lib.linux-x86_64-3.7/apex/contrib/sparsity/permutation_search_kernels\n",
            "  copying apex/contrib/sparsity/permutation_search_kernels/exhaustive_search.py -> build/lib.linux-x86_64-3.7/apex/contrib/sparsity/permutation_search_kernels\n",
            "  copying apex/contrib/sparsity/permutation_search_kernels/permutation_utilities.py -> build/lib.linux-x86_64-3.7/apex/contrib/sparsity/permutation_search_kernels\n",
            "  copying apex/contrib/sparsity/permutation_search_kernels/call_permutation_search_kernels.py -> build/lib.linux-x86_64-3.7/apex/contrib/sparsity/permutation_search_kernels\n",
            "  running build_ext\n",
            "  building 'apex_C' extension\n",
            "  creating /content/apex/build/temp.linux-x86_64-3.7\n",
            "  creating /content/apex/build/temp.linux-x86_64-3.7/csrc\n",
            "  Emitting ninja build file /content/apex/build/temp.linux-x86_64-3.7/build.ninja...\n",
            "  Compiling objects...\n",
            "  Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
            "  [1/1] c++ -MMD -MF /content/apex/build/temp.linux-x86_64-3.7/csrc/flatten_unflatten.o.d -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-pX47U3/python3.7-3.7.12=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-pX47U3/python3.7-3.7.12=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/include/python3.7m -c -c /content/apex/csrc/flatten_unflatten.cpp -o /content/apex/build/temp.linux-x86_64-3.7/csrc/flatten_unflatten.o -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=apex_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "  In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Parallel.h:140:0,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/utils.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:5,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/nn.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:13,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from /content/apex/csrc/flatten_unflatten.cpp:1:\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ParallelOpenMP.h:83:0: warning: ignoring #pragma omp parallel [-Wunknown-pragmas]\n",
            "   #pragma omp parallel for if ((end - begin) >= grain_size)\n",
            "\n",
            "  In file included from /content/apex/csrc/flatten_unflatten.cpp:2:0:\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/utils/tensor_flatten.h: In member function ‘at::DeprecatedTypeProperties& torch::utils::TensorGroup::type()’:\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/utils/tensor_flatten.h:44:28: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "       return tensors[0].type();\n",
            "                              ^\n",
            "  In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from /content/apex/csrc/flatten_unflatten.cpp:1:\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:303:30: note: declared here\n",
            "     DeprecatedTypeProperties & type() const {\n",
            "                                ^~~~\n",
            "  x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fdebug-prefix-map=/build/python3.7-pX47U3/python3.7-3.7.12=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 /content/apex/build/temp.linux-x86_64-3.7/csrc/flatten_unflatten.o -L/usr/local/lib/python3.7/dist-packages/torch/lib -lc10 -ltorch -ltorch_cpu -ltorch_python -o build/lib.linux-x86_64-3.7/apex_C.cpython-37m-x86_64-linux-gnu.so\n",
            "  building 'amp_C' extension\n",
            "  Emitting ninja build file /content/apex/build/temp.linux-x86_64-3.7/build.ninja...\n",
            "  Compiling objects...\n",
            "  Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
            "  [1/14] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /content/apex/build/temp.linux-x86_64-3.7/csrc/multi_tensor_adam.o.d -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c -c /content/apex/csrc/multi_tensor_adam.cu -o /content/apex/build/temp.linux-x86_64-3.7/csrc/multi_tensor_adam.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=compute_37 -gencode=arch=compute_37,code=sm_37 -std=c++14\n",
            "  nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
            "  [2/14] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /content/apex/build/temp.linux-x86_64-3.7/csrc/multi_tensor_sgd_kernel.o.d -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c -c /content/apex/csrc/multi_tensor_sgd_kernel.cu -o /content/apex/build/temp.linux-x86_64-3.7/csrc/multi_tensor_sgd_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=compute_37 -gencode=arch=compute_37,code=sm_37 -std=c++14\n",
            "  nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
            "  [3/14] c++ -MMD -MF /content/apex/build/temp.linux-x86_64-3.7/csrc/amp_C_frontend.o.d -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-pX47U3/python3.7-3.7.12=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-pX47U3/python3.7-3.7.12=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c -c /content/apex/csrc/amp_C_frontend.cpp -o /content/apex/build/temp.linux-x86_64-3.7/csrc/amp_C_frontend.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "  In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Parallel.h:140:0,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/utils.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:5,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/nn.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:13,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from /content/apex/csrc/amp_C_frontend.cpp:1:\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ParallelOpenMP.h:83:0: warning: ignoring #pragma omp parallel [-Wunknown-pragmas]\n",
            "   #pragma omp parallel for if ((end - begin) >= grain_size)\n",
            "\n",
            "  [4/14] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /content/apex/build/temp.linux-x86_64-3.7/csrc/multi_tensor_scale_kernel.o.d -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c -c /content/apex/csrc/multi_tensor_scale_kernel.cu -o /content/apex/build/temp.linux-x86_64-3.7/csrc/multi_tensor_scale_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=compute_37 -gencode=arch=compute_37,code=sm_37 -std=c++14\n",
            "  nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
            "  [5/14] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /content/apex/build/temp.linux-x86_64-3.7/csrc/multi_tensor_axpby_kernel.o.d -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c -c /content/apex/csrc/multi_tensor_axpby_kernel.cu -o /content/apex/build/temp.linux-x86_64-3.7/csrc/multi_tensor_axpby_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=compute_37 -gencode=arch=compute_37,code=sm_37 -std=c++14\n",
            "  nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
            "  [6/14] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /content/apex/build/temp.linux-x86_64-3.7/csrc/multi_tensor_l2norm_kernel.o.d -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c -c /content/apex/csrc/multi_tensor_l2norm_kernel.cu -o /content/apex/build/temp.linux-x86_64-3.7/csrc/multi_tensor_l2norm_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=compute_37 -gencode=arch=compute_37,code=sm_37 -std=c++14\n",
            "  nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
            "  [7/14] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /content/apex/build/temp.linux-x86_64-3.7/csrc/multi_tensor_l2norm_kernel_mp.o.d -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c -c /content/apex/csrc/multi_tensor_l2norm_kernel_mp.cu -o /content/apex/build/temp.linux-x86_64-3.7/csrc/multi_tensor_l2norm_kernel_mp.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=compute_37 -gencode=arch=compute_37,code=sm_37 -std=c++14\n",
            "  nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
            "  [8/14] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /content/apex/build/temp.linux-x86_64-3.7/csrc/multi_tensor_l2norm_scale_kernel.o.d -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c -c /content/apex/csrc/multi_tensor_l2norm_scale_kernel.cu -o /content/apex/build/temp.linux-x86_64-3.7/csrc/multi_tensor_l2norm_scale_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=compute_37 -gencode=arch=compute_37,code=sm_37 -std=c++14\n",
            "  nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
            "  [9/14] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /content/apex/build/temp.linux-x86_64-3.7/csrc/multi_tensor_lamb_stage_1.o.d -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c -c /content/apex/csrc/multi_tensor_lamb_stage_1.cu -o /content/apex/build/temp.linux-x86_64-3.7/csrc/multi_tensor_lamb_stage_1.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=compute_37 -gencode=arch=compute_37,code=sm_37 -std=c++14\n",
            "  nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
            "  [10/14] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /content/apex/build/temp.linux-x86_64-3.7/csrc/multi_tensor_lamb_stage_2.o.d -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c -c /content/apex/csrc/multi_tensor_lamb_stage_2.cu -o /content/apex/build/temp.linux-x86_64-3.7/csrc/multi_tensor_lamb_stage_2.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=compute_37 -gencode=arch=compute_37,code=sm_37 -std=c++14\n",
            "  nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
            "  [11/14] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /content/apex/build/temp.linux-x86_64-3.7/csrc/multi_tensor_adagrad.o.d -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c -c /content/apex/csrc/multi_tensor_adagrad.cu -o /content/apex/build/temp.linux-x86_64-3.7/csrc/multi_tensor_adagrad.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=compute_37 -gencode=arch=compute_37,code=sm_37 -std=c++14\n",
            "  nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
            "  [12/14] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /content/apex/build/temp.linux-x86_64-3.7/csrc/multi_tensor_novograd.o.d -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c -c /content/apex/csrc/multi_tensor_novograd.cu -o /content/apex/build/temp.linux-x86_64-3.7/csrc/multi_tensor_novograd.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=compute_37 -gencode=arch=compute_37,code=sm_37 -std=c++14\n",
            "  nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
            "  [13/14] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /content/apex/build/temp.linux-x86_64-3.7/csrc/multi_tensor_lamb.o.d -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c -c /content/apex/csrc/multi_tensor_lamb.cu -o /content/apex/build/temp.linux-x86_64-3.7/csrc/multi_tensor_lamb.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=compute_37 -gencode=arch=compute_37,code=sm_37 -std=c++14\n",
            "  nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
            "  [14/14] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /content/apex/build/temp.linux-x86_64-3.7/csrc/multi_tensor_lamb_mp.o.d -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c -c /content/apex/csrc/multi_tensor_lamb_mp.cu -o /content/apex/build/temp.linux-x86_64-3.7/csrc/multi_tensor_lamb_mp.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=compute_37 -gencode=arch=compute_37,code=sm_37 -std=c++14\n",
            "  nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
            "  x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fdebug-prefix-map=/build/python3.7-pX47U3/python3.7-3.7.12=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 /content/apex/build/temp.linux-x86_64-3.7/csrc/amp_C_frontend.o /content/apex/build/temp.linux-x86_64-3.7/csrc/multi_tensor_sgd_kernel.o /content/apex/build/temp.linux-x86_64-3.7/csrc/multi_tensor_scale_kernel.o /content/apex/build/temp.linux-x86_64-3.7/csrc/multi_tensor_axpby_kernel.o /content/apex/build/temp.linux-x86_64-3.7/csrc/multi_tensor_l2norm_kernel.o /content/apex/build/temp.linux-x86_64-3.7/csrc/multi_tensor_l2norm_kernel_mp.o /content/apex/build/temp.linux-x86_64-3.7/csrc/multi_tensor_l2norm_scale_kernel.o /content/apex/build/temp.linux-x86_64-3.7/csrc/multi_tensor_lamb_stage_1.o /content/apex/build/temp.linux-x86_64-3.7/csrc/multi_tensor_lamb_stage_2.o /content/apex/build/temp.linux-x86_64-3.7/csrc/multi_tensor_adam.o /content/apex/build/temp.linux-x86_64-3.7/csrc/multi_tensor_adagrad.o /content/apex/build/temp.linux-x86_64-3.7/csrc/multi_tensor_novograd.o /content/apex/build/temp.linux-x86_64-3.7/csrc/multi_tensor_lamb.o /content/apex/build/temp.linux-x86_64-3.7/csrc/multi_tensor_lamb_mp.o -L/usr/local/lib/python3.7/dist-packages/torch/lib -L/usr/local/cuda/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda_cu -ltorch_cuda_cpp -o build/lib.linux-x86_64-3.7/amp_C.cpython-37m-x86_64-linux-gnu.so\n",
            "  building 'syncbn' extension\n",
            "  Emitting ninja build file /content/apex/build/temp.linux-x86_64-3.7/build.ninja...\n",
            "  Compiling objects...\n",
            "  Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
            "  [1/2] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /content/apex/build/temp.linux-x86_64-3.7/csrc/welford.o.d -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c -c /content/apex/csrc/welford.cu -o /content/apex/build/temp.linux-x86_64-3.7/csrc/welford.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=syncbn -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=compute_37 -gencode=arch=compute_37,code=sm_37 -std=c++14\n",
            "  nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
            "  [2/2] c++ -MMD -MF /content/apex/build/temp.linux-x86_64-3.7/csrc/syncbn.o.d -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-pX47U3/python3.7-3.7.12=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-pX47U3/python3.7-3.7.12=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c -c /content/apex/csrc/syncbn.cpp -o /content/apex/build/temp.linux-x86_64-3.7/csrc/syncbn.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=syncbn -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "  In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Parallel.h:140:0,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/utils.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:5,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/nn.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:13,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from /content/apex/csrc/syncbn.cpp:1:\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ParallelOpenMP.h:83:0: warning: ignoring #pragma omp parallel [-Wunknown-pragmas]\n",
            "   #pragma omp parallel for if ((end - begin) >= grain_size)\n",
            "\n",
            "  x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fdebug-prefix-map=/build/python3.7-pX47U3/python3.7-3.7.12=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 /content/apex/build/temp.linux-x86_64-3.7/csrc/syncbn.o /content/apex/build/temp.linux-x86_64-3.7/csrc/welford.o -L/usr/local/lib/python3.7/dist-packages/torch/lib -L/usr/local/cuda/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda_cu -ltorch_cuda_cpp -o build/lib.linux-x86_64-3.7/syncbn.cpython-37m-x86_64-linux-gnu.so\n",
            "  building 'fused_layer_norm_cuda' extension\n",
            "  Emitting ninja build file /content/apex/build/temp.linux-x86_64-3.7/build.ninja...\n",
            "  Compiling objects...\n",
            "  Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
            "  [1/2] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /content/apex/build/temp.linux-x86_64-3.7/csrc/layer_norm_cuda_kernel.o.d -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c -c /content/apex/csrc/layer_norm_cuda_kernel.cu -o /content/apex/build/temp.linux-x86_64-3.7/csrc/layer_norm_cuda_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -maxrregcount=50 -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=fused_layer_norm_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=compute_37 -gencode=arch=compute_37,code=sm_37 -std=c++14\n",
            "  nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
            "  [2/2] c++ -MMD -MF /content/apex/build/temp.linux-x86_64-3.7/csrc/layer_norm_cuda.o.d -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-pX47U3/python3.7-3.7.12=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-pX47U3/python3.7-3.7.12=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c -c /content/apex/csrc/layer_norm_cuda.cpp -o /content/apex/build/temp.linux-x86_64-3.7/csrc/layer_norm_cuda.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=fused_layer_norm_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "  In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Parallel.h:140:0,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/utils.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:5,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/nn.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:13,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from /content/apex/csrc/layer_norm_cuda.cpp:1:\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ParallelOpenMP.h:83:0: warning: ignoring #pragma omp parallel [-Wunknown-pragmas]\n",
            "   #pragma omp parallel for if ((end - begin) >= grain_size)\n",
            "\n",
            "  In file included from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:7,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from /content/apex/csrc/layer_norm_cuda.cpp:1:\n",
            "  /content/apex/csrc/layer_norm_cuda.cpp: In function ‘std::vector<at::Tensor> layer_norm(at::Tensor, c10::IntArrayRef, double)’:\n",
            "  /content/apex/csrc/layer_norm_cuda.cpp:145:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "   #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                                            ^\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/c10/macros/Macros.h:173:65: note: in definition of macro ‘C10_UNLIKELY’\n",
            "   #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
            "                                                                   ^~~~\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:362:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
            "     if (C10_UNLIKELY_OR_CONST(!(cond))) {                                 \\\n",
            "         ^~~~~~~~~~~~~~~~~~~~~\n",
            "  /content/apex/csrc/layer_norm_cuda.cpp:145:23: note: in expansion of macro ‘TORCH_CHECK’\n",
            "   #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                         ^~~~~~~~~~~\n",
            "  /content/apex/csrc/layer_norm_cuda.cpp:147:24: note: in expansion of macro ‘CHECK_CUDA’\n",
            "   #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
            "                          ^~~~~~~~~~\n",
            "  /content/apex/csrc/layer_norm_cuda.cpp:157:3: note: in expansion of macro ‘CHECK_INPUT’\n",
            "     CHECK_INPUT(input);\n",
            "     ^\n",
            "  In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from /content/apex/csrc/layer_norm_cuda.cpp:1:\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:303:30: note: declared here\n",
            "     DeprecatedTypeProperties & type() const {\n",
            "                                ^~~~\n",
            "  In file included from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:7,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from /content/apex/csrc/layer_norm_cuda.cpp:1:\n",
            "  /content/apex/csrc/layer_norm_cuda.cpp: In function ‘std::vector<at::Tensor> layer_norm_affine(at::Tensor, c10::IntArrayRef, at::Tensor, at::Tensor, double)’:\n",
            "  /content/apex/csrc/layer_norm_cuda.cpp:145:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "   #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                                            ^\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/c10/macros/Macros.h:173:65: note: in definition of macro ‘C10_UNLIKELY’\n",
            "   #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
            "                                                                   ^~~~\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:362:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
            "     if (C10_UNLIKELY_OR_CONST(!(cond))) {                                 \\\n",
            "         ^~~~~~~~~~~~~~~~~~~~~\n",
            "  /content/apex/csrc/layer_norm_cuda.cpp:145:23: note: in expansion of macro ‘TORCH_CHECK’\n",
            "   #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                         ^~~~~~~~~~~\n",
            "  /content/apex/csrc/layer_norm_cuda.cpp:147:24: note: in expansion of macro ‘CHECK_CUDA’\n",
            "   #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
            "                          ^~~~~~~~~~\n",
            "  /content/apex/csrc/layer_norm_cuda.cpp:178:3: note: in expansion of macro ‘CHECK_INPUT’\n",
            "     CHECK_INPUT(input);\n",
            "     ^\n",
            "  In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from /content/apex/csrc/layer_norm_cuda.cpp:1:\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:303:30: note: declared here\n",
            "     DeprecatedTypeProperties & type() const {\n",
            "                                ^~~~\n",
            "  In file included from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:7,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from /content/apex/csrc/layer_norm_cuda.cpp:1:\n",
            "  /content/apex/csrc/layer_norm_cuda.cpp:145:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "   #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                                            ^\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/c10/macros/Macros.h:173:65: note: in definition of macro ‘C10_UNLIKELY’\n",
            "   #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
            "                                                                   ^~~~\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:362:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
            "     if (C10_UNLIKELY_OR_CONST(!(cond))) {                                 \\\n",
            "         ^~~~~~~~~~~~~~~~~~~~~\n",
            "  /content/apex/csrc/layer_norm_cuda.cpp:145:23: note: in expansion of macro ‘TORCH_CHECK’\n",
            "   #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                         ^~~~~~~~~~~\n",
            "  /content/apex/csrc/layer_norm_cuda.cpp:147:24: note: in expansion of macro ‘CHECK_CUDA’\n",
            "   #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
            "                          ^~~~~~~~~~\n",
            "  /content/apex/csrc/layer_norm_cuda.cpp:179:3: note: in expansion of macro ‘CHECK_INPUT’\n",
            "     CHECK_INPUT(gamma);\n",
            "     ^\n",
            "  In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from /content/apex/csrc/layer_norm_cuda.cpp:1:\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:303:30: note: declared here\n",
            "     DeprecatedTypeProperties & type() const {\n",
            "                                ^~~~\n",
            "  In file included from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:7,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from /content/apex/csrc/layer_norm_cuda.cpp:1:\n",
            "  /content/apex/csrc/layer_norm_cuda.cpp:145:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "   #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                                            ^\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/c10/macros/Macros.h:173:65: note: in definition of macro ‘C10_UNLIKELY’\n",
            "   #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
            "                                                                   ^~~~\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:362:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
            "     if (C10_UNLIKELY_OR_CONST(!(cond))) {                                 \\\n",
            "         ^~~~~~~~~~~~~~~~~~~~~\n",
            "  /content/apex/csrc/layer_norm_cuda.cpp:145:23: note: in expansion of macro ‘TORCH_CHECK’\n",
            "   #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                         ^~~~~~~~~~~\n",
            "  /content/apex/csrc/layer_norm_cuda.cpp:147:24: note: in expansion of macro ‘CHECK_CUDA’\n",
            "   #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
            "                          ^~~~~~~~~~\n",
            "  /content/apex/csrc/layer_norm_cuda.cpp:180:3: note: in expansion of macro ‘CHECK_INPUT’\n",
            "     CHECK_INPUT(beta);\n",
            "     ^\n",
            "  In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from /content/apex/csrc/layer_norm_cuda.cpp:1:\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:303:30: note: declared here\n",
            "     DeprecatedTypeProperties & type() const {\n",
            "                                ^~~~\n",
            "  In file included from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:7,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from /content/apex/csrc/layer_norm_cuda.cpp:1:\n",
            "  /content/apex/csrc/layer_norm_cuda.cpp: In function ‘std::vector<at::Tensor> layer_norm_affine_mixed_dtypes(at::Tensor, c10::IntArrayRef, at::Tensor, at::Tensor, double)’:\n",
            "  /content/apex/csrc/layer_norm_cuda.cpp:145:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "   #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                                            ^\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/c10/macros/Macros.h:173:65: note: in definition of macro ‘C10_UNLIKELY’\n",
            "   #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
            "                                                                   ^~~~\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:362:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
            "     if (C10_UNLIKELY_OR_CONST(!(cond))) {                                 \\\n",
            "         ^~~~~~~~~~~~~~~~~~~~~\n",
            "  /content/apex/csrc/layer_norm_cuda.cpp:145:23: note: in expansion of macro ‘TORCH_CHECK’\n",
            "   #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                         ^~~~~~~~~~~\n",
            "  /content/apex/csrc/layer_norm_cuda.cpp:147:24: note: in expansion of macro ‘CHECK_CUDA’\n",
            "   #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
            "                          ^~~~~~~~~~\n",
            "  /content/apex/csrc/layer_norm_cuda.cpp:202:3: note: in expansion of macro ‘CHECK_INPUT’\n",
            "     CHECK_INPUT(input);\n",
            "     ^\n",
            "  In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from /content/apex/csrc/layer_norm_cuda.cpp:1:\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:303:30: note: declared here\n",
            "     DeprecatedTypeProperties & type() const {\n",
            "                                ^~~~\n",
            "  In file included from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:7,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from /content/apex/csrc/layer_norm_cuda.cpp:1:\n",
            "  /content/apex/csrc/layer_norm_cuda.cpp: In function ‘at::Tensor layer_norm_gradient(at::Tensor, at::Tensor, at::Tensor, at::Tensor, c10::IntArrayRef, double)’:\n",
            "  /content/apex/csrc/layer_norm_cuda.cpp:145:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "   #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                                            ^\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/c10/macros/Macros.h:173:65: note: in definition of macro ‘C10_UNLIKELY’\n",
            "   #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
            "                                                                   ^~~~\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:362:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
            "     if (C10_UNLIKELY_OR_CONST(!(cond))) {                                 \\\n",
            "         ^~~~~~~~~~~~~~~~~~~~~\n",
            "  /content/apex/csrc/layer_norm_cuda.cpp:145:23: note: in expansion of macro ‘TORCH_CHECK’\n",
            "   #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                         ^~~~~~~~~~~\n",
            "  /content/apex/csrc/layer_norm_cuda.cpp:147:24: note: in expansion of macro ‘CHECK_CUDA’\n",
            "   #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
            "                          ^~~~~~~~~~\n",
            "  /content/apex/csrc/layer_norm_cuda.cpp:244:3: note: in expansion of macro ‘CHECK_INPUT’\n",
            "     CHECK_INPUT(dout);\n",
            "     ^\n",
            "  In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from /content/apex/csrc/layer_norm_cuda.cpp:1:\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:303:30: note: declared here\n",
            "     DeprecatedTypeProperties & type() const {\n",
            "                                ^~~~\n",
            "  In file included from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:7,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from /content/apex/csrc/layer_norm_cuda.cpp:1:\n",
            "  /content/apex/csrc/layer_norm_cuda.cpp:145:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "   #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                                            ^\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/c10/macros/Macros.h:173:65: note: in definition of macro ‘C10_UNLIKELY’\n",
            "   #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
            "                                                                   ^~~~\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:362:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
            "     if (C10_UNLIKELY_OR_CONST(!(cond))) {                                 \\\n",
            "         ^~~~~~~~~~~~~~~~~~~~~\n",
            "  /content/apex/csrc/layer_norm_cuda.cpp:145:23: note: in expansion of macro ‘TORCH_CHECK’\n",
            "   #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                         ^~~~~~~~~~~\n",
            "  /content/apex/csrc/layer_norm_cuda.cpp:147:24: note: in expansion of macro ‘CHECK_CUDA’\n",
            "   #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
            "                          ^~~~~~~~~~\n",
            "  /content/apex/csrc/layer_norm_cuda.cpp:245:3: note: in expansion of macro ‘CHECK_INPUT’\n",
            "     CHECK_INPUT(mean);\n",
            "     ^\n",
            "  In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from /content/apex/csrc/layer_norm_cuda.cpp:1:\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:303:30: note: declared here\n",
            "     DeprecatedTypeProperties & type() const {\n",
            "                                ^~~~\n",
            "  In file included from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:7,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from /content/apex/csrc/layer_norm_cuda.cpp:1:\n",
            "  /content/apex/csrc/layer_norm_cuda.cpp:145:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "   #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                                            ^\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/c10/macros/Macros.h:173:65: note: in definition of macro ‘C10_UNLIKELY’\n",
            "   #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
            "                                                                   ^~~~\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:362:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
            "     if (C10_UNLIKELY_OR_CONST(!(cond))) {                                 \\\n",
            "         ^~~~~~~~~~~~~~~~~~~~~\n",
            "  /content/apex/csrc/layer_norm_cuda.cpp:145:23: note: in expansion of macro ‘TORCH_CHECK’\n",
            "   #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                         ^~~~~~~~~~~\n",
            "  /content/apex/csrc/layer_norm_cuda.cpp:147:24: note: in expansion of macro ‘CHECK_CUDA’\n",
            "   #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
            "                          ^~~~~~~~~~\n",
            "  /content/apex/csrc/layer_norm_cuda.cpp:246:3: note: in expansion of macro ‘CHECK_INPUT’\n",
            "     CHECK_INPUT(invvar);\n",
            "     ^\n",
            "  In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from /content/apex/csrc/layer_norm_cuda.cpp:1:\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:303:30: note: declared here\n",
            "     DeprecatedTypeProperties & type() const {\n",
            "                                ^~~~\n",
            "  In file included from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:7,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from /content/apex/csrc/layer_norm_cuda.cpp:1:\n",
            "  /content/apex/csrc/layer_norm_cuda.cpp:145:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "   #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                                            ^\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/c10/macros/Macros.h:173:65: note: in definition of macro ‘C10_UNLIKELY’\n",
            "   #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
            "                                                                   ^~~~\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:362:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
            "     if (C10_UNLIKELY_OR_CONST(!(cond))) {                                 \\\n",
            "         ^~~~~~~~~~~~~~~~~~~~~\n",
            "  /content/apex/csrc/layer_norm_cuda.cpp:145:23: note: in expansion of macro ‘TORCH_CHECK’\n",
            "   #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                         ^~~~~~~~~~~\n",
            "  /content/apex/csrc/layer_norm_cuda.cpp:147:24: note: in expansion of macro ‘CHECK_CUDA’\n",
            "   #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
            "                          ^~~~~~~~~~\n",
            "  /content/apex/csrc/layer_norm_cuda.cpp:247:3: note: in expansion of macro ‘CHECK_INPUT’\n",
            "     CHECK_INPUT(input);\n",
            "     ^\n",
            "  In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from /content/apex/csrc/layer_norm_cuda.cpp:1:\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:303:30: note: declared here\n",
            "     DeprecatedTypeProperties & type() const {\n",
            "                                ^~~~\n",
            "  In file included from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:7,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from /content/apex/csrc/layer_norm_cuda.cpp:1:\n",
            "  /content/apex/csrc/layer_norm_cuda.cpp: In function ‘std::vector<at::Tensor> layer_norm_gradient_affine(at::Tensor, at::Tensor, at::Tensor, at::Tensor, c10::IntArrayRef, at::Tensor, at::Tensor, double)’:\n",
            "  /content/apex/csrc/layer_norm_cuda.cpp:145:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "   #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                                            ^\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/c10/macros/Macros.h:173:65: note: in definition of macro ‘C10_UNLIKELY’\n",
            "   #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
            "                                                                   ^~~~\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:362:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
            "     if (C10_UNLIKELY_OR_CONST(!(cond))) {                                 \\\n",
            "         ^~~~~~~~~~~~~~~~~~~~~\n",
            "  /content/apex/csrc/layer_norm_cuda.cpp:145:23: note: in expansion of macro ‘TORCH_CHECK’\n",
            "   #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                         ^~~~~~~~~~~\n",
            "  /content/apex/csrc/layer_norm_cuda.cpp:147:24: note: in expansion of macro ‘CHECK_CUDA’\n",
            "   #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
            "                          ^~~~~~~~~~\n",
            "  /content/apex/csrc/layer_norm_cuda.cpp:270:3: note: in expansion of macro ‘CHECK_INPUT’\n",
            "     CHECK_INPUT(dout);\n",
            "     ^\n",
            "  In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from /content/apex/csrc/layer_norm_cuda.cpp:1:\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:303:30: note: declared here\n",
            "     DeprecatedTypeProperties & type() const {\n",
            "                                ^~~~\n",
            "  In file included from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:7,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from /content/apex/csrc/layer_norm_cuda.cpp:1:\n",
            "  /content/apex/csrc/layer_norm_cuda.cpp:145:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "   #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                                            ^\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/c10/macros/Macros.h:173:65: note: in definition of macro ‘C10_UNLIKELY’\n",
            "   #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
            "                                                                   ^~~~\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:362:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
            "     if (C10_UNLIKELY_OR_CONST(!(cond))) {                                 \\\n",
            "         ^~~~~~~~~~~~~~~~~~~~~\n",
            "  /content/apex/csrc/layer_norm_cuda.cpp:145:23: note: in expansion of macro ‘TORCH_CHECK’\n",
            "   #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                         ^~~~~~~~~~~\n",
            "  /content/apex/csrc/layer_norm_cuda.cpp:147:24: note: in expansion of macro ‘CHECK_CUDA’\n",
            "   #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
            "                          ^~~~~~~~~~\n",
            "  /content/apex/csrc/layer_norm_cuda.cpp:271:3: note: in expansion of macro ‘CHECK_INPUT’\n",
            "     CHECK_INPUT(mean);\n",
            "     ^\n",
            "  In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from /content/apex/csrc/layer_norm_cuda.cpp:1:\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:303:30: note: declared here\n",
            "     DeprecatedTypeProperties & type() const {\n",
            "                                ^~~~\n",
            "  In file included from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:7,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from /content/apex/csrc/layer_norm_cuda.cpp:1:\n",
            "  /content/apex/csrc/layer_norm_cuda.cpp:145:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "   #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                                            ^\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/c10/macros/Macros.h:173:65: note: in definition of macro ‘C10_UNLIKELY’\n",
            "   #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
            "                                                                   ^~~~\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:362:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
            "     if (C10_UNLIKELY_OR_CONST(!(cond))) {                                 \\\n",
            "         ^~~~~~~~~~~~~~~~~~~~~\n",
            "  /content/apex/csrc/layer_norm_cuda.cpp:145:23: note: in expansion of macro ‘TORCH_CHECK’\n",
            "   #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                         ^~~~~~~~~~~\n",
            "  /content/apex/csrc/layer_norm_cuda.cpp:147:24: note: in expansion of macro ‘CHECK_CUDA’\n",
            "   #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
            "                          ^~~~~~~~~~\n",
            "  /content/apex/csrc/layer_norm_cuda.cpp:272:3: note: in expansion of macro ‘CHECK_INPUT’\n",
            "     CHECK_INPUT(invvar);\n",
            "     ^\n",
            "  In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from /content/apex/csrc/layer_norm_cuda.cpp:1:\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:303:30: note: declared here\n",
            "     DeprecatedTypeProperties & type() const {\n",
            "                                ^~~~\n",
            "  In file included from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:7,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from /content/apex/csrc/layer_norm_cuda.cpp:1:\n",
            "  /content/apex/csrc/layer_norm_cuda.cpp:145:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "   #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                                            ^\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/c10/macros/Macros.h:173:65: note: in definition of macro ‘C10_UNLIKELY’\n",
            "   #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
            "                                                                   ^~~~\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:362:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
            "     if (C10_UNLIKELY_OR_CONST(!(cond))) {                                 \\\n",
            "         ^~~~~~~~~~~~~~~~~~~~~\n",
            "  /content/apex/csrc/layer_norm_cuda.cpp:145:23: note: in expansion of macro ‘TORCH_CHECK’\n",
            "   #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                         ^~~~~~~~~~~\n",
            "  /content/apex/csrc/layer_norm_cuda.cpp:147:24: note: in expansion of macro ‘CHECK_CUDA’\n",
            "   #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
            "                          ^~~~~~~~~~\n",
            "  /content/apex/csrc/layer_norm_cuda.cpp:273:3: note: in expansion of macro ‘CHECK_INPUT’\n",
            "     CHECK_INPUT(input);\n",
            "     ^\n",
            "  In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from /content/apex/csrc/layer_norm_cuda.cpp:1:\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:303:30: note: declared here\n",
            "     DeprecatedTypeProperties & type() const {\n",
            "                                ^~~~\n",
            "  In file included from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:7,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from /content/apex/csrc/layer_norm_cuda.cpp:1:\n",
            "  /content/apex/csrc/layer_norm_cuda.cpp:145:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "   #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                                            ^\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/c10/macros/Macros.h:173:65: note: in definition of macro ‘C10_UNLIKELY’\n",
            "   #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
            "                                                                   ^~~~\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:362:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
            "     if (C10_UNLIKELY_OR_CONST(!(cond))) {                                 \\\n",
            "         ^~~~~~~~~~~~~~~~~~~~~\n",
            "  /content/apex/csrc/layer_norm_cuda.cpp:145:23: note: in expansion of macro ‘TORCH_CHECK’\n",
            "   #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                         ^~~~~~~~~~~\n",
            "  /content/apex/csrc/layer_norm_cuda.cpp:147:24: note: in expansion of macro ‘CHECK_CUDA’\n",
            "   #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
            "                          ^~~~~~~~~~\n",
            "  /content/apex/csrc/layer_norm_cuda.cpp:274:3: note: in expansion of macro ‘CHECK_INPUT’\n",
            "     CHECK_INPUT(gamma);\n",
            "     ^\n",
            "  In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from /content/apex/csrc/layer_norm_cuda.cpp:1:\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:303:30: note: declared here\n",
            "     DeprecatedTypeProperties & type() const {\n",
            "                                ^~~~\n",
            "  In file included from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:7,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from /content/apex/csrc/layer_norm_cuda.cpp:1:\n",
            "  /content/apex/csrc/layer_norm_cuda.cpp:145:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "   #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                                            ^\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/c10/macros/Macros.h:173:65: note: in definition of macro ‘C10_UNLIKELY’\n",
            "   #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
            "                                                                   ^~~~\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:362:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
            "     if (C10_UNLIKELY_OR_CONST(!(cond))) {                                 \\\n",
            "         ^~~~~~~~~~~~~~~~~~~~~\n",
            "  /content/apex/csrc/layer_norm_cuda.cpp:145:23: note: in expansion of macro ‘TORCH_CHECK’\n",
            "   #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                         ^~~~~~~~~~~\n",
            "  /content/apex/csrc/layer_norm_cuda.cpp:147:24: note: in expansion of macro ‘CHECK_CUDA’\n",
            "   #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
            "                          ^~~~~~~~~~\n",
            "  /content/apex/csrc/layer_norm_cuda.cpp:275:3: note: in expansion of macro ‘CHECK_INPUT’\n",
            "     CHECK_INPUT(beta);\n",
            "     ^\n",
            "  In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from /content/apex/csrc/layer_norm_cuda.cpp:1:\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:303:30: note: declared here\n",
            "     DeprecatedTypeProperties & type() const {\n",
            "                                ^~~~\n",
            "  In file included from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:7,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from /content/apex/csrc/layer_norm_cuda.cpp:1:\n",
            "  /content/apex/csrc/layer_norm_cuda.cpp: In function ‘std::vector<at::Tensor> rms_norm(at::Tensor, c10::IntArrayRef, double)’:\n",
            "  /content/apex/csrc/layer_norm_cuda.cpp:301:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "   #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                                            ^\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/c10/macros/Macros.h:173:65: note: in definition of macro ‘C10_UNLIKELY’\n",
            "   #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
            "                                                                   ^~~~\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:362:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
            "     if (C10_UNLIKELY_OR_CONST(!(cond))) {                                 \\\n",
            "         ^~~~~~~~~~~~~~~~~~~~~\n",
            "  /content/apex/csrc/layer_norm_cuda.cpp:301:23: note: in expansion of macro ‘TORCH_CHECK’\n",
            "   #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                         ^~~~~~~~~~~\n",
            "  /content/apex/csrc/layer_norm_cuda.cpp:303:24: note: in expansion of macro ‘CHECK_CUDA’\n",
            "   #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
            "                          ^~~~~~~~~~\n",
            "  /content/apex/csrc/layer_norm_cuda.cpp:313:3: note: in expansion of macro ‘CHECK_INPUT’\n",
            "     CHECK_INPUT(input);\n",
            "     ^\n",
            "  In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from /content/apex/csrc/layer_norm_cuda.cpp:1:\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:303:30: note: declared here\n",
            "     DeprecatedTypeProperties & type() const {\n",
            "                                ^~~~\n",
            "  In file included from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:7,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from /content/apex/csrc/layer_norm_cuda.cpp:1:\n",
            "  /content/apex/csrc/layer_norm_cuda.cpp: In function ‘std::vector<at::Tensor> rms_norm_affine(at::Tensor, c10::IntArrayRef, at::Tensor, double)’:\n",
            "  /content/apex/csrc/layer_norm_cuda.cpp:301:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "   #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                                            ^\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/c10/macros/Macros.h:173:65: note: in definition of macro ‘C10_UNLIKELY’\n",
            "   #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
            "                                                                   ^~~~\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:362:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
            "     if (C10_UNLIKELY_OR_CONST(!(cond))) {                                 \\\n",
            "         ^~~~~~~~~~~~~~~~~~~~~\n",
            "  /content/apex/csrc/layer_norm_cuda.cpp:301:23: note: in expansion of macro ‘TORCH_CHECK’\n",
            "   #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                         ^~~~~~~~~~~\n",
            "  /content/apex/csrc/layer_norm_cuda.cpp:303:24: note: in expansion of macro ‘CHECK_CUDA’\n",
            "   #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
            "                          ^~~~~~~~~~\n",
            "  /content/apex/csrc/layer_norm_cuda.cpp:332:3: note: in expansion of macro ‘CHECK_INPUT’\n",
            "     CHECK_INPUT(input);\n",
            "     ^\n",
            "  In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from /content/apex/csrc/layer_norm_cuda.cpp:1:\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:303:30: note: declared here\n",
            "     DeprecatedTypeProperties & type() const {\n",
            "                                ^~~~\n",
            "  In file included from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:7,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from /content/apex/csrc/layer_norm_cuda.cpp:1:\n",
            "  /content/apex/csrc/layer_norm_cuda.cpp:301:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "   #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                                            ^\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/c10/macros/Macros.h:173:65: note: in definition of macro ‘C10_UNLIKELY’\n",
            "   #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
            "                                                                   ^~~~\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:362:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
            "     if (C10_UNLIKELY_OR_CONST(!(cond))) {                                 \\\n",
            "         ^~~~~~~~~~~~~~~~~~~~~\n",
            "  /content/apex/csrc/layer_norm_cuda.cpp:301:23: note: in expansion of macro ‘TORCH_CHECK’\n",
            "   #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                         ^~~~~~~~~~~\n",
            "  /content/apex/csrc/layer_norm_cuda.cpp:303:24: note: in expansion of macro ‘CHECK_CUDA’\n",
            "   #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
            "                          ^~~~~~~~~~\n",
            "  /content/apex/csrc/layer_norm_cuda.cpp:333:3: note: in expansion of macro ‘CHECK_INPUT’\n",
            "     CHECK_INPUT(gamma);\n",
            "     ^\n",
            "  In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from /content/apex/csrc/layer_norm_cuda.cpp:1:\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:303:30: note: declared here\n",
            "     DeprecatedTypeProperties & type() const {\n",
            "                                ^~~~\n",
            "  In file included from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:7,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from /content/apex/csrc/layer_norm_cuda.cpp:1:\n",
            "  /content/apex/csrc/layer_norm_cuda.cpp: In function ‘std::vector<at::Tensor> rms_norm_affine_mixed_dtypes(at::Tensor, c10::IntArrayRef, at::Tensor, double)’:\n",
            "  /content/apex/csrc/layer_norm_cuda.cpp:301:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "   #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                                            ^\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/c10/macros/Macros.h:173:65: note: in definition of macro ‘C10_UNLIKELY’\n",
            "   #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
            "                                                                   ^~~~\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:362:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
            "     if (C10_UNLIKELY_OR_CONST(!(cond))) {                                 \\\n",
            "         ^~~~~~~~~~~~~~~~~~~~~\n",
            "  /content/apex/csrc/layer_norm_cuda.cpp:301:23: note: in expansion of macro ‘TORCH_CHECK’\n",
            "   #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                         ^~~~~~~~~~~\n",
            "  /content/apex/csrc/layer_norm_cuda.cpp:303:24: note: in expansion of macro ‘CHECK_CUDA’\n",
            "   #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
            "                          ^~~~~~~~~~\n",
            "  /content/apex/csrc/layer_norm_cuda.cpp:353:3: note: in expansion of macro ‘CHECK_INPUT’\n",
            "     CHECK_INPUT(input);\n",
            "     ^\n",
            "  In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from /content/apex/csrc/layer_norm_cuda.cpp:1:\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:303:30: note: declared here\n",
            "     DeprecatedTypeProperties & type() const {\n",
            "                                ^~~~\n",
            "  In file included from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:7,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from /content/apex/csrc/layer_norm_cuda.cpp:1:\n",
            "  /content/apex/csrc/layer_norm_cuda.cpp: In function ‘at::Tensor rms_norm_gradient(at::Tensor, at::Tensor, at::Tensor, c10::IntArrayRef, double)’:\n",
            "  /content/apex/csrc/layer_norm_cuda.cpp:301:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "   #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                                            ^\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/c10/macros/Macros.h:173:65: note: in definition of macro ‘C10_UNLIKELY’\n",
            "   #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
            "                                                                   ^~~~\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:362:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
            "     if (C10_UNLIKELY_OR_CONST(!(cond))) {                                 \\\n",
            "         ^~~~~~~~~~~~~~~~~~~~~\n",
            "  /content/apex/csrc/layer_norm_cuda.cpp:301:23: note: in expansion of macro ‘TORCH_CHECK’\n",
            "   #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                         ^~~~~~~~~~~\n",
            "  /content/apex/csrc/layer_norm_cuda.cpp:303:24: note: in expansion of macro ‘CHECK_CUDA’\n",
            "   #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
            "                          ^~~~~~~~~~\n",
            "  /content/apex/csrc/layer_norm_cuda.cpp:390:3: note: in expansion of macro ‘CHECK_INPUT’\n",
            "     CHECK_INPUT(dout);\n",
            "     ^\n",
            "  In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from /content/apex/csrc/layer_norm_cuda.cpp:1:\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:303:30: note: declared here\n",
            "     DeprecatedTypeProperties & type() const {\n",
            "                                ^~~~\n",
            "  In file included from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:7,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from /content/apex/csrc/layer_norm_cuda.cpp:1:\n",
            "  /content/apex/csrc/layer_norm_cuda.cpp:301:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "   #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                                            ^\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/c10/macros/Macros.h:173:65: note: in definition of macro ‘C10_UNLIKELY’\n",
            "   #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
            "                                                                   ^~~~\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:362:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
            "     if (C10_UNLIKELY_OR_CONST(!(cond))) {                                 \\\n",
            "         ^~~~~~~~~~~~~~~~~~~~~\n",
            "  /content/apex/csrc/layer_norm_cuda.cpp:301:23: note: in expansion of macro ‘TORCH_CHECK’\n",
            "   #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                         ^~~~~~~~~~~\n",
            "  /content/apex/csrc/layer_norm_cuda.cpp:303:24: note: in expansion of macro ‘CHECK_CUDA’\n",
            "   #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
            "                          ^~~~~~~~~~\n",
            "  /content/apex/csrc/layer_norm_cuda.cpp:391:3: note: in expansion of macro ‘CHECK_INPUT’\n",
            "     CHECK_INPUT(invvar);\n",
            "     ^\n",
            "  In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from /content/apex/csrc/layer_norm_cuda.cpp:1:\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:303:30: note: declared here\n",
            "     DeprecatedTypeProperties & type() const {\n",
            "                                ^~~~\n",
            "  In file included from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:7,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from /content/apex/csrc/layer_norm_cuda.cpp:1:\n",
            "  /content/apex/csrc/layer_norm_cuda.cpp:301:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "   #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                                            ^\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/c10/macros/Macros.h:173:65: note: in definition of macro ‘C10_UNLIKELY’\n",
            "   #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
            "                                                                   ^~~~\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:362:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
            "     if (C10_UNLIKELY_OR_CONST(!(cond))) {                                 \\\n",
            "         ^~~~~~~~~~~~~~~~~~~~~\n",
            "  /content/apex/csrc/layer_norm_cuda.cpp:301:23: note: in expansion of macro ‘TORCH_CHECK’\n",
            "   #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                         ^~~~~~~~~~~\n",
            "  /content/apex/csrc/layer_norm_cuda.cpp:303:24: note: in expansion of macro ‘CHECK_CUDA’\n",
            "   #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
            "                          ^~~~~~~~~~\n",
            "  /content/apex/csrc/layer_norm_cuda.cpp:392:3: note: in expansion of macro ‘CHECK_INPUT’\n",
            "     CHECK_INPUT(input);\n",
            "     ^\n",
            "  In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from /content/apex/csrc/layer_norm_cuda.cpp:1:\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:303:30: note: declared here\n",
            "     DeprecatedTypeProperties & type() const {\n",
            "                                ^~~~\n",
            "  In file included from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:7,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from /content/apex/csrc/layer_norm_cuda.cpp:1:\n",
            "  /content/apex/csrc/layer_norm_cuda.cpp: In function ‘std::vector<at::Tensor> rms_norm_gradient_affine(at::Tensor, at::Tensor, at::Tensor, c10::IntArrayRef, at::Tensor, double)’:\n",
            "  /content/apex/csrc/layer_norm_cuda.cpp:301:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "   #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                                            ^\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/c10/macros/Macros.h:173:65: note: in definition of macro ‘C10_UNLIKELY’\n",
            "   #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
            "                                                                   ^~~~\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:362:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
            "     if (C10_UNLIKELY_OR_CONST(!(cond))) {                                 \\\n",
            "         ^~~~~~~~~~~~~~~~~~~~~\n",
            "  /content/apex/csrc/layer_norm_cuda.cpp:301:23: note: in expansion of macro ‘TORCH_CHECK’\n",
            "   #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                         ^~~~~~~~~~~\n",
            "  /content/apex/csrc/layer_norm_cuda.cpp:303:24: note: in expansion of macro ‘CHECK_CUDA’\n",
            "   #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
            "                          ^~~~~~~~~~\n",
            "  /content/apex/csrc/layer_norm_cuda.cpp:413:3: note: in expansion of macro ‘CHECK_INPUT’\n",
            "     CHECK_INPUT(dout);\n",
            "     ^\n",
            "  In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from /content/apex/csrc/layer_norm_cuda.cpp:1:\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:303:30: note: declared here\n",
            "     DeprecatedTypeProperties & type() const {\n",
            "                                ^~~~\n",
            "  In file included from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:7,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from /content/apex/csrc/layer_norm_cuda.cpp:1:\n",
            "  /content/apex/csrc/layer_norm_cuda.cpp:301:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "   #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                                            ^\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/c10/macros/Macros.h:173:65: note: in definition of macro ‘C10_UNLIKELY’\n",
            "   #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
            "                                                                   ^~~~\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:362:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
            "     if (C10_UNLIKELY_OR_CONST(!(cond))) {                                 \\\n",
            "         ^~~~~~~~~~~~~~~~~~~~~\n",
            "  /content/apex/csrc/layer_norm_cuda.cpp:301:23: note: in expansion of macro ‘TORCH_CHECK’\n",
            "   #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                         ^~~~~~~~~~~\n",
            "  /content/apex/csrc/layer_norm_cuda.cpp:303:24: note: in expansion of macro ‘CHECK_CUDA’\n",
            "   #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
            "                          ^~~~~~~~~~\n",
            "  /content/apex/csrc/layer_norm_cuda.cpp:414:3: note: in expansion of macro ‘CHECK_INPUT’\n",
            "     CHECK_INPUT(invvar);\n",
            "     ^\n",
            "  In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from /content/apex/csrc/layer_norm_cuda.cpp:1:\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:303:30: note: declared here\n",
            "     DeprecatedTypeProperties & type() const {\n",
            "                                ^~~~\n",
            "  In file included from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:7,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from /content/apex/csrc/layer_norm_cuda.cpp:1:\n",
            "  /content/apex/csrc/layer_norm_cuda.cpp:301:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "   #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                                            ^\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/c10/macros/Macros.h:173:65: note: in definition of macro ‘C10_UNLIKELY’\n",
            "   #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
            "                                                                   ^~~~\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:362:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
            "     if (C10_UNLIKELY_OR_CONST(!(cond))) {                                 \\\n",
            "         ^~~~~~~~~~~~~~~~~~~~~\n",
            "  /content/apex/csrc/layer_norm_cuda.cpp:301:23: note: in expansion of macro ‘TORCH_CHECK’\n",
            "   #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                         ^~~~~~~~~~~\n",
            "  /content/apex/csrc/layer_norm_cuda.cpp:303:24: note: in expansion of macro ‘CHECK_CUDA’\n",
            "   #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
            "                          ^~~~~~~~~~\n",
            "  /content/apex/csrc/layer_norm_cuda.cpp:415:3: note: in expansion of macro ‘CHECK_INPUT’\n",
            "     CHECK_INPUT(input);\n",
            "     ^\n",
            "  In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from /content/apex/csrc/layer_norm_cuda.cpp:1:\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:303:30: note: declared here\n",
            "     DeprecatedTypeProperties & type() const {\n",
            "                                ^~~~\n",
            "  In file included from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:7,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from /content/apex/csrc/layer_norm_cuda.cpp:1:\n",
            "  /content/apex/csrc/layer_norm_cuda.cpp:301:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "   #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                                            ^\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/c10/macros/Macros.h:173:65: note: in definition of macro ‘C10_UNLIKELY’\n",
            "   #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
            "                                                                   ^~~~\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:362:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
            "     if (C10_UNLIKELY_OR_CONST(!(cond))) {                                 \\\n",
            "         ^~~~~~~~~~~~~~~~~~~~~\n",
            "  /content/apex/csrc/layer_norm_cuda.cpp:301:23: note: in expansion of macro ‘TORCH_CHECK’\n",
            "   #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                         ^~~~~~~~~~~\n",
            "  /content/apex/csrc/layer_norm_cuda.cpp:303:24: note: in expansion of macro ‘CHECK_CUDA’\n",
            "   #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
            "                          ^~~~~~~~~~\n",
            "  /content/apex/csrc/layer_norm_cuda.cpp:416:3: note: in expansion of macro ‘CHECK_INPUT’\n",
            "     CHECK_INPUT(gamma);\n",
            "     ^\n",
            "  In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from /content/apex/csrc/layer_norm_cuda.cpp:1:\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:303:30: note: declared here\n",
            "     DeprecatedTypeProperties & type() const {\n",
            "                                ^~~~\n",
            "  x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fdebug-prefix-map=/build/python3.7-pX47U3/python3.7-3.7.12=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 /content/apex/build/temp.linux-x86_64-3.7/csrc/layer_norm_cuda.o /content/apex/build/temp.linux-x86_64-3.7/csrc/layer_norm_cuda_kernel.o -L/usr/local/lib/python3.7/dist-packages/torch/lib -L/usr/local/cuda/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda_cu -ltorch_cuda_cpp -o build/lib.linux-x86_64-3.7/fused_layer_norm_cuda.cpython-37m-x86_64-linux-gnu.so\n",
            "  building 'mlp_cuda' extension\n",
            "  Emitting ninja build file /content/apex/build/temp.linux-x86_64-3.7/build.ninja...\n",
            "  Compiling objects...\n",
            "  Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
            "  [1/2] c++ -MMD -MF /content/apex/build/temp.linux-x86_64-3.7/csrc/mlp.o.d -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-pX47U3/python3.7-3.7.12=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-pX47U3/python3.7-3.7.12=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c -c /content/apex/csrc/mlp.cpp -o /content/apex/build/temp.linux-x86_64-3.7/csrc/mlp.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=mlp_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "  In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Parallel.h:140:0,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/utils.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:5,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/nn.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:13,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from /content/apex/csrc/mlp.cpp:1:\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ParallelOpenMP.h:83:0: warning: ignoring #pragma omp parallel [-Wunknown-pragmas]\n",
            "   #pragma omp parallel for if ((end - begin) >= grain_size)\n",
            "\n",
            "  /content/apex/csrc/mlp.cpp: In function ‘std::vector<at::Tensor> mlp_forward(int, int, std::vector<at::Tensor>)’:\n",
            "  /content/apex/csrc/mlp.cpp:57:21: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
            "     for (int i = 0; i < num_layers; i++) {\n",
            "                     ~~^~~~~~~~~~~~\n",
            "  /content/apex/csrc/mlp.cpp:64:77: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     auto out = at::empty({batch_size, output_features.back()}, inputs[0].type());\n",
            "                                                                               ^\n",
            "  In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from /content/apex/csrc/mlp.cpp:1:\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:303:30: note: declared here\n",
            "     DeprecatedTypeProperties & type() const {\n",
            "                                ^~~~\n",
            "  /content/apex/csrc/mlp.cpp:65:86: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     auto reserved_space = at::empty({static_cast<long>(reserved_size)}, inputs[0].type());\n",
            "                                                                                        ^\n",
            "  In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from /content/apex/csrc/mlp.cpp:1:\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:303:30: note: declared here\n",
            "     DeprecatedTypeProperties & type() const {\n",
            "                                ^~~~\n",
            "  /content/apex/csrc/mlp.cpp:67:59: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     auto lt_workspace = at::empty({1 << 22}, inputs[0].type());\n",
            "                                                             ^\n",
            "  In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from /content/apex/csrc/mlp.cpp:1:\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:303:30: note: declared here\n",
            "     DeprecatedTypeProperties & type() const {\n",
            "                                ^~~~\n",
            "  In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:13:0,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from /content/apex/csrc/mlp.cpp:1:\n",
            "  /content/apex/csrc/mlp.cpp: In lambda function:\n",
            "  /content/apex/csrc/mlp.cpp:69:54: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
            "                                                        ^\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:209:28: note: in definition of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       const auto& the_type = TYPE;                                               \\\n",
            "                              ^~~~\n",
            "  In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from /content/apex/csrc/mlp.cpp:1:\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:303:30: note: declared here\n",
            "     DeprecatedTypeProperties & type() const {\n",
            "                                ^~~~\n",
            "  In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:13:0,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from /content/apex/csrc/mlp.cpp:1:\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:211:56: warning: ‘c10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)’ is deprecated: passing at::DeprecatedTypeProperties to an AT_DISPATCH macro is deprecated, pass an at::ScalarType instead [-Wdeprecated-declarations]\n",
            "       at::ScalarType _st = ::detail::scalar_type(the_type);                      \\\n",
            "                                                          ^\n",
            "  /content/apex/csrc/mlp.cpp:69:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "     AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
            "     ^\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:109:23: note: declared here\n",
            "   inline at::ScalarType scalar_type(const at::DeprecatedTypeProperties& t) {\n",
            "                         ^~~~~~~~~~~\n",
            "  /content/apex/csrc/mlp.cpp: In lambda function:\n",
            "  /content/apex/csrc/mlp.cpp:72:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
            "       for (int i = 0; i < num_layers; i++) {\n",
            "                       ~~^~~\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:56:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "       return __VA_ARGS__();                                                        \\\n",
            "              ^~~~~~~~~~~\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:214:7: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Double, double, __VA_ARGS__)  \\\n",
            "         ^~~~~~~~~~~~~~~~~~~~\n",
            "  /content/apex/csrc/mlp.cpp:69:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "     AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
            "     ^\n",
            "  /content/apex/csrc/mlp.cpp:78:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
            "       auto result = mlp_fp<scalar_t>(\n",
            "            ^\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:56:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "       return __VA_ARGS__();                                                        \\\n",
            "              ^~~~~~~~~~~\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:214:7: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Double, double, __VA_ARGS__)  \\\n",
            "         ^~~~~~~~~~~~~~~~~~~~\n",
            "  /content/apex/csrc/mlp.cpp:69:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "     AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
            "     ^\n",
            "  /content/apex/csrc/mlp.cpp: In lambda function:\n",
            "  /content/apex/csrc/mlp.cpp:72:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
            "       for (int i = 0; i < num_layers; i++) {\n",
            "                       ~~^~~\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:56:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "       return __VA_ARGS__();                                                        \\\n",
            "              ^~~~~~~~~~~\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:215:7: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Float, float, __VA_ARGS__)    \\\n",
            "         ^~~~~~~~~~~~~~~~~~~~\n",
            "  /content/apex/csrc/mlp.cpp:69:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "     AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
            "     ^\n",
            "  /content/apex/csrc/mlp.cpp:78:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
            "       auto result = mlp_fp<scalar_t>(\n",
            "            ^\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:56:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "       return __VA_ARGS__();                                                        \\\n",
            "              ^~~~~~~~~~~\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:215:7: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Float, float, __VA_ARGS__)    \\\n",
            "         ^~~~~~~~~~~~~~~~~~~~\n",
            "  /content/apex/csrc/mlp.cpp:69:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "     AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
            "     ^\n",
            "  /content/apex/csrc/mlp.cpp: In lambda function:\n",
            "  /content/apex/csrc/mlp.cpp:72:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
            "       for (int i = 0; i < num_layers; i++) {\n",
            "                       ~~^~~\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:56:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "       return __VA_ARGS__();                                                        \\\n",
            "              ^~~~~~~~~~~\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:216:7: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Half, at::Half, __VA_ARGS__)  \\\n",
            "         ^~~~~~~~~~~~~~~~~~~~\n",
            "  /content/apex/csrc/mlp.cpp:69:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "     AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
            "     ^\n",
            "  /content/apex/csrc/mlp.cpp:78:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
            "       auto result = mlp_fp<scalar_t>(\n",
            "            ^\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:56:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "       return __VA_ARGS__();                                                        \\\n",
            "              ^~~~~~~~~~~\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:216:7: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Half, at::Half, __VA_ARGS__)  \\\n",
            "         ^~~~~~~~~~~~~~~~~~~~\n",
            "  /content/apex/csrc/mlp.cpp:69:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "     AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
            "     ^\n",
            "  /content/apex/csrc/mlp.cpp: In function ‘std::vector<at::Tensor> mlp_backward(int, int, at::Tensor, std::vector<at::Tensor>, std::vector<at::Tensor>)’:\n",
            "  /content/apex/csrc/mlp.cpp:115:21: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
            "     for (int i = 0; i < num_layers; i++) {\n",
            "                     ~~^~~~~~~~~~~~\n",
            "  /content/apex/csrc/mlp.cpp:120:21: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
            "     for (int i = 0; i < inputs.size(); i++) {\n",
            "                     ~~^~~~~~~~~~~~~~~\n",
            "  /content/apex/csrc/mlp.cpp:121:67: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "       outputs.push_back(at::empty(inputs[i].sizes(), inputs[i].type()));  // clone for testing now\n",
            "                                                                     ^\n",
            "  In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from /content/apex/csrc/mlp.cpp:1:\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:303:30: note: declared here\n",
            "     DeprecatedTypeProperties & type() const {\n",
            "                                ^~~~\n",
            "  In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:13:0,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from /content/apex/csrc/mlp.cpp:1:\n",
            "  /content/apex/csrc/mlp.cpp: In lambda function:\n",
            "  /content/apex/csrc/mlp.cpp:124:54: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "                                                        ^\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:209:28: note: in definition of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       const auto& the_type = TYPE;                                               \\\n",
            "                              ^~~~\n",
            "  In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from /content/apex/csrc/mlp.cpp:1:\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:303:30: note: declared here\n",
            "     DeprecatedTypeProperties & type() const {\n",
            "                                ^~~~\n",
            "  In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:13:0,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from /content/apex/csrc/mlp.cpp:1:\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:211:56: warning: ‘c10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)’ is deprecated: passing at::DeprecatedTypeProperties to an AT_DISPATCH macro is deprecated, pass an at::ScalarType instead [-Wdeprecated-declarations]\n",
            "       at::ScalarType _st = ::detail::scalar_type(the_type);                      \\\n",
            "                                                          ^\n",
            "  /content/apex/csrc/mlp.cpp:124:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "     AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "     ^\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:109:23: note: declared here\n",
            "   inline at::ScalarType scalar_type(const at::DeprecatedTypeProperties& t) {\n",
            "                         ^~~~~~~~~~~\n",
            "  /content/apex/csrc/mlp.cpp: In lambda function:\n",
            "  /content/apex/csrc/mlp.cpp:126:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
            "       for (int i = 0; i < num_layers; i++) {\n",
            "                       ~~^~~\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:56:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "       return __VA_ARGS__();                                                        \\\n",
            "              ^~~~~~~~~~~\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:214:7: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Double, double, __VA_ARGS__)  \\\n",
            "         ^~~~~~~~~~~~~~~~~~~~\n",
            "  /content/apex/csrc/mlp.cpp:124:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "     AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "     ^\n",
            "  /content/apex/csrc/mlp.cpp:130:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
            "       for (int i = 0; i < inputs.size(); i++) {\n",
            "                       ~~^~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:56:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "       return __VA_ARGS__();                                                        \\\n",
            "              ^~~~~~~~~~~\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:214:7: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Double, double, __VA_ARGS__)  \\\n",
            "         ^~~~~~~~~~~~~~~~~~~~\n",
            "  /content/apex/csrc/mlp.cpp:124:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "     AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "     ^\n",
            "  /content/apex/csrc/mlp.cpp:138:99: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "       auto work_space = at::empty({static_cast<long>(work_size / sizeof(scalar_t))}, inputs[0].type());\n",
            "                                                                                                     ^\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:56:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "       return __VA_ARGS__();                                                        \\\n",
            "              ^~~~~~~~~~~\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:214:7: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Double, double, __VA_ARGS__)  \\\n",
            "         ^~~~~~~~~~~~~~~~~~~~\n",
            "  /content/apex/csrc/mlp.cpp:124:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "     AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "     ^\n",
            "  In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from /content/apex/csrc/mlp.cpp:1:\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:303:30: note: declared here\n",
            "     DeprecatedTypeProperties & type() const {\n",
            "                                ^~~~\n",
            "  In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:13:0,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from /content/apex/csrc/mlp.cpp:1:\n",
            "  /content/apex/csrc/mlp.cpp:140:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
            "       auto result = mlp_bp<scalar_t>(\n",
            "            ^\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:56:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "       return __VA_ARGS__();                                                        \\\n",
            "              ^~~~~~~~~~~\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:214:7: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Double, double, __VA_ARGS__)  \\\n",
            "         ^~~~~~~~~~~~~~~~~~~~\n",
            "  /content/apex/csrc/mlp.cpp:124:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "     AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "     ^\n",
            "  /content/apex/csrc/mlp.cpp: In lambda function:\n",
            "  /content/apex/csrc/mlp.cpp:126:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
            "       for (int i = 0; i < num_layers; i++) {\n",
            "                       ~~^~~\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:56:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "       return __VA_ARGS__();                                                        \\\n",
            "              ^~~~~~~~~~~\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:215:7: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Float, float, __VA_ARGS__)    \\\n",
            "         ^~~~~~~~~~~~~~~~~~~~\n",
            "  /content/apex/csrc/mlp.cpp:124:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "     AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "     ^\n",
            "  /content/apex/csrc/mlp.cpp:130:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
            "       for (int i = 0; i < inputs.size(); i++) {\n",
            "                       ~~^~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:56:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "       return __VA_ARGS__();                                                        \\\n",
            "              ^~~~~~~~~~~\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:215:7: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Float, float, __VA_ARGS__)    \\\n",
            "         ^~~~~~~~~~~~~~~~~~~~\n",
            "  /content/apex/csrc/mlp.cpp:124:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "     AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "     ^\n",
            "  /content/apex/csrc/mlp.cpp:138:99: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "       auto work_space = at::empty({static_cast<long>(work_size / sizeof(scalar_t))}, inputs[0].type());\n",
            "                                                                                                     ^\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:56:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "       return __VA_ARGS__();                                                        \\\n",
            "              ^~~~~~~~~~~\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:215:7: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Float, float, __VA_ARGS__)    \\\n",
            "         ^~~~~~~~~~~~~~~~~~~~\n",
            "  /content/apex/csrc/mlp.cpp:124:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "     AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "     ^\n",
            "  In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from /content/apex/csrc/mlp.cpp:1:\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:303:30: note: declared here\n",
            "     DeprecatedTypeProperties & type() const {\n",
            "                                ^~~~\n",
            "  In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:13:0,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from /content/apex/csrc/mlp.cpp:1:\n",
            "  /content/apex/csrc/mlp.cpp:140:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
            "       auto result = mlp_bp<scalar_t>(\n",
            "            ^\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:56:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "       return __VA_ARGS__();                                                        \\\n",
            "              ^~~~~~~~~~~\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:215:7: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Float, float, __VA_ARGS__)    \\\n",
            "         ^~~~~~~~~~~~~~~~~~~~\n",
            "  /content/apex/csrc/mlp.cpp:124:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "     AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "     ^\n",
            "  /content/apex/csrc/mlp.cpp: In lambda function:\n",
            "  /content/apex/csrc/mlp.cpp:126:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
            "       for (int i = 0; i < num_layers; i++) {\n",
            "                       ~~^~~\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:56:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "       return __VA_ARGS__();                                                        \\\n",
            "              ^~~~~~~~~~~\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:216:7: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Half, at::Half, __VA_ARGS__)  \\\n",
            "         ^~~~~~~~~~~~~~~~~~~~\n",
            "  /content/apex/csrc/mlp.cpp:124:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "     AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "     ^\n",
            "  /content/apex/csrc/mlp.cpp:130:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
            "       for (int i = 0; i < inputs.size(); i++) {\n",
            "                       ~~^~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:56:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "       return __VA_ARGS__();                                                        \\\n",
            "              ^~~~~~~~~~~\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:216:7: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Half, at::Half, __VA_ARGS__)  \\\n",
            "         ^~~~~~~~~~~~~~~~~~~~\n",
            "  /content/apex/csrc/mlp.cpp:124:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "     AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "     ^\n",
            "  /content/apex/csrc/mlp.cpp:138:99: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "       auto work_space = at::empty({static_cast<long>(work_size / sizeof(scalar_t))}, inputs[0].type());\n",
            "                                                                                                     ^\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:56:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "       return __VA_ARGS__();                                                        \\\n",
            "              ^~~~~~~~~~~\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:216:7: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Half, at::Half, __VA_ARGS__)  \\\n",
            "         ^~~~~~~~~~~~~~~~~~~~\n",
            "  /content/apex/csrc/mlp.cpp:124:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "     AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "     ^\n",
            "  In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from /content/apex/csrc/mlp.cpp:1:\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:303:30: note: declared here\n",
            "     DeprecatedTypeProperties & type() const {\n",
            "                                ^~~~\n",
            "  In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:13:0,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from /content/apex/csrc/mlp.cpp:1:\n",
            "  /content/apex/csrc/mlp.cpp:140:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
            "       auto result = mlp_bp<scalar_t>(\n",
            "            ^\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:56:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "       return __VA_ARGS__();                                                        \\\n",
            "              ^~~~~~~~~~~\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:216:7: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Half, at::Half, __VA_ARGS__)  \\\n",
            "         ^~~~~~~~~~~~~~~~~~~~\n",
            "  /content/apex/csrc/mlp.cpp:124:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "     AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "     ^\n",
            "  [2/2] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /content/apex/build/temp.linux-x86_64-3.7/csrc/mlp_cuda.o.d -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c -c /content/apex/csrc/mlp_cuda.cu -o /content/apex/build/temp.linux-x86_64-3.7/csrc/mlp_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=mlp_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=compute_37 -gencode=arch=compute_37,code=sm_37 -std=c++14\n",
            "  nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
            "  x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fdebug-prefix-map=/build/python3.7-pX47U3/python3.7-3.7.12=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 /content/apex/build/temp.linux-x86_64-3.7/csrc/mlp.o /content/apex/build/temp.linux-x86_64-3.7/csrc/mlp_cuda.o -L/usr/local/lib/python3.7/dist-packages/torch/lib -L/usr/local/cuda/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda_cu -ltorch_cuda_cpp -o build/lib.linux-x86_64-3.7/mlp_cuda.cpython-37m-x86_64-linux-gnu.so\n",
            "  building 'fused_dense_cuda' extension\n",
            "  Emitting ninja build file /content/apex/build/temp.linux-x86_64-3.7/build.ninja...\n",
            "  Compiling objects...\n",
            "  Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
            "  [1/2] c++ -MMD -MF /content/apex/build/temp.linux-x86_64-3.7/csrc/fused_dense.o.d -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-pX47U3/python3.7-3.7.12=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-pX47U3/python3.7-3.7.12=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c -c /content/apex/csrc/fused_dense.cpp -o /content/apex/build/temp.linux-x86_64-3.7/csrc/fused_dense.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=fused_dense_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "  In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Parallel.h:140:0,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/utils.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:5,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/nn.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:13,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from /content/apex/csrc/fused_dense.cpp:1:\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ParallelOpenMP.h:83:0: warning: ignoring #pragma omp parallel [-Wunknown-pragmas]\n",
            "   #pragma omp parallel for if ((end - begin) >= grain_size)\n",
            "\n",
            "  /content/apex/csrc/fused_dense.cpp: In function ‘at::Tensor linear_bias_forward(at::Tensor, at::Tensor, at::Tensor)’:\n",
            "  /content/apex/csrc/fused_dense.cpp:30:63: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     auto out = at::empty({batch_size, out_features}, input.type());\n",
            "                                                                 ^\n",
            "  In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from /content/apex/csrc/fused_dense.cpp:1:\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:303:30: note: declared here\n",
            "     DeprecatedTypeProperties & type() const {\n",
            "                                ^~~~\n",
            "  /content/apex/csrc/fused_dense.cpp:33:55: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     auto lt_workspace = at::empty({1 << 22}, input.type());\n",
            "                                                         ^\n",
            "  In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from /content/apex/csrc/fused_dense.cpp:1:\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:303:30: note: declared here\n",
            "     DeprecatedTypeProperties & type() const {\n",
            "                                ^~~~\n",
            "  In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:13:0,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from /content/apex/csrc/fused_dense.cpp:1:\n",
            "  /content/apex/csrc/fused_dense.cpp: In lambda function:\n",
            "  /content/apex/csrc/fused_dense.cpp:35:50: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     AT_DISPATCH_FLOATING_TYPES_AND_HALF(input.type(), \"linear_bias_forward\", [&] {\n",
            "                                                    ^\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:209:28: note: in definition of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       const auto& the_type = TYPE;                                               \\\n",
            "                              ^~~~\n",
            "  In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from /content/apex/csrc/fused_dense.cpp:1:\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:303:30: note: declared here\n",
            "     DeprecatedTypeProperties & type() const {\n",
            "                                ^~~~\n",
            "  In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:13:0,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from /content/apex/csrc/fused_dense.cpp:1:\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:211:56: warning: ‘c10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)’ is deprecated: passing at::DeprecatedTypeProperties to an AT_DISPATCH macro is deprecated, pass an at::ScalarType instead [-Wdeprecated-declarations]\n",
            "       at::ScalarType _st = ::detail::scalar_type(the_type);                      \\\n",
            "                                                          ^\n",
            "  /content/apex/csrc/fused_dense.cpp:35:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "     AT_DISPATCH_FLOATING_TYPES_AND_HALF(input.type(), \"linear_bias_forward\", [&] {\n",
            "     ^\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:109:23: note: declared here\n",
            "   inline at::ScalarType scalar_type(const at::DeprecatedTypeProperties& t) {\n",
            "                         ^~~~~~~~~~~\n",
            "  /content/apex/csrc/fused_dense.cpp: In lambda function:\n",
            "  /content/apex/csrc/fused_dense.cpp:37:15: warning: unused variable ‘b_ptr’ [-Wunused-variable]\n",
            "       scalar_t* b_ptr = bias.data_ptr<scalar_t>();\n",
            "                 ^\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:56:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "       return __VA_ARGS__();                                                        \\\n",
            "              ^~~~~~~~~~~\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:214:7: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Double, double, __VA_ARGS__)  \\\n",
            "         ^~~~~~~~~~~~~~~~~~~~\n",
            "  /content/apex/csrc/fused_dense.cpp:35:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "     AT_DISPATCH_FLOATING_TYPES_AND_HALF(input.type(), \"linear_bias_forward\", [&] {\n",
            "     ^\n",
            "  /content/apex/csrc/fused_dense.cpp:38:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
            "       auto result = linear_bias_forward_cuda<scalar_t>(\n",
            "            ^\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:56:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "       return __VA_ARGS__();                                                        \\\n",
            "              ^~~~~~~~~~~\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:214:7: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Double, double, __VA_ARGS__)  \\\n",
            "         ^~~~~~~~~~~~~~~~~~~~\n",
            "  /content/apex/csrc/fused_dense.cpp:35:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "     AT_DISPATCH_FLOATING_TYPES_AND_HALF(input.type(), \"linear_bias_forward\", [&] {\n",
            "     ^\n",
            "  /content/apex/csrc/fused_dense.cpp: In lambda function:\n",
            "  /content/apex/csrc/fused_dense.cpp:37:15: warning: unused variable ‘b_ptr’ [-Wunused-variable]\n",
            "       scalar_t* b_ptr = bias.data_ptr<scalar_t>();\n",
            "                 ^\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:56:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "       return __VA_ARGS__();                                                        \\\n",
            "              ^~~~~~~~~~~\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:215:7: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Float, float, __VA_ARGS__)    \\\n",
            "         ^~~~~~~~~~~~~~~~~~~~\n",
            "  /content/apex/csrc/fused_dense.cpp:35:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "     AT_DISPATCH_FLOATING_TYPES_AND_HALF(input.type(), \"linear_bias_forward\", [&] {\n",
            "     ^\n",
            "  /content/apex/csrc/fused_dense.cpp:38:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
            "       auto result = linear_bias_forward_cuda<scalar_t>(\n",
            "            ^\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:56:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "       return __VA_ARGS__();                                                        \\\n",
            "              ^~~~~~~~~~~\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:215:7: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Float, float, __VA_ARGS__)    \\\n",
            "         ^~~~~~~~~~~~~~~~~~~~\n",
            "  /content/apex/csrc/fused_dense.cpp:35:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "     AT_DISPATCH_FLOATING_TYPES_AND_HALF(input.type(), \"linear_bias_forward\", [&] {\n",
            "     ^\n",
            "  /content/apex/csrc/fused_dense.cpp: In lambda function:\n",
            "  /content/apex/csrc/fused_dense.cpp:37:15: warning: unused variable ‘b_ptr’ [-Wunused-variable]\n",
            "       scalar_t* b_ptr = bias.data_ptr<scalar_t>();\n",
            "                 ^\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:56:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "       return __VA_ARGS__();                                                        \\\n",
            "              ^~~~~~~~~~~\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:216:7: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Half, at::Half, __VA_ARGS__)  \\\n",
            "         ^~~~~~~~~~~~~~~~~~~~\n",
            "  /content/apex/csrc/fused_dense.cpp:35:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "     AT_DISPATCH_FLOATING_TYPES_AND_HALF(input.type(), \"linear_bias_forward\", [&] {\n",
            "     ^\n",
            "  /content/apex/csrc/fused_dense.cpp:38:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
            "       auto result = linear_bias_forward_cuda<scalar_t>(\n",
            "            ^\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:56:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "       return __VA_ARGS__();                                                        \\\n",
            "              ^~~~~~~~~~~\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:216:7: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Half, at::Half, __VA_ARGS__)  \\\n",
            "         ^~~~~~~~~~~~~~~~~~~~\n",
            "  /content/apex/csrc/fused_dense.cpp:35:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "     AT_DISPATCH_FLOATING_TYPES_AND_HALF(input.type(), \"linear_bias_forward\", [&] {\n",
            "     ^\n",
            "  /content/apex/csrc/fused_dense.cpp: In function ‘std::vector<at::Tensor> linear_bias_backward(at::Tensor, at::Tensor, at::Tensor)’:\n",
            "  /content/apex/csrc/fused_dense.cpp:64:69: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     auto d_weight = at::empty({out_features, in_features}, input.type());\n",
            "                                                                       ^\n",
            "  In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from /content/apex/csrc/fused_dense.cpp:1:\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:303:30: note: declared here\n",
            "     DeprecatedTypeProperties & type() const {\n",
            "                                ^~~~\n",
            "  /content/apex/csrc/fused_dense.cpp:68:54: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     auto d_bias = at::empty({out_features}, input.type());\n",
            "                                                        ^\n",
            "  In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from /content/apex/csrc/fused_dense.cpp:1:\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:303:30: note: declared here\n",
            "     DeprecatedTypeProperties & type() const {\n",
            "                                ^~~~\n",
            "  /content/apex/csrc/fused_dense.cpp:70:66: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     auto d_input = at::empty({batch_size, in_features}, input.type());\n",
            "                                                                    ^\n",
            "  In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from /content/apex/csrc/fused_dense.cpp:1:\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:303:30: note: declared here\n",
            "     DeprecatedTypeProperties & type() const {\n",
            "                                ^~~~\n",
            "  /content/apex/csrc/fused_dense.cpp:73:55: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     auto lt_workspace = at::empty({1 << 22}, input.type());\n",
            "                                                         ^\n",
            "  In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from /content/apex/csrc/fused_dense.cpp:1:\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:303:30: note: declared here\n",
            "     DeprecatedTypeProperties & type() const {\n",
            "                                ^~~~\n",
            "  In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:13:0,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from /content/apex/csrc/fused_dense.cpp:1:\n",
            "  /content/apex/csrc/fused_dense.cpp: In lambda function:\n",
            "  /content/apex/csrc/fused_dense.cpp:75:50: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     AT_DISPATCH_FLOATING_TYPES_AND_HALF(input.type(), \"linear_bias_backward\", [&] {\n",
            "                                                    ^\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:209:28: note: in definition of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       const auto& the_type = TYPE;                                               \\\n",
            "                              ^~~~\n",
            "  In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from /content/apex/csrc/fused_dense.cpp:1:\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:303:30: note: declared here\n",
            "     DeprecatedTypeProperties & type() const {\n",
            "                                ^~~~\n",
            "  In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:13:0,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from /content/apex/csrc/fused_dense.cpp:1:\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:211:56: warning: ‘c10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)’ is deprecated: passing at::DeprecatedTypeProperties to an AT_DISPATCH macro is deprecated, pass an at::ScalarType instead [-Wdeprecated-declarations]\n",
            "       at::ScalarType _st = ::detail::scalar_type(the_type);                      \\\n",
            "                                                          ^\n",
            "  /content/apex/csrc/fused_dense.cpp:75:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "     AT_DISPATCH_FLOATING_TYPES_AND_HALF(input.type(), \"linear_bias_backward\", [&] {\n",
            "     ^\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:109:23: note: declared here\n",
            "   inline at::ScalarType scalar_type(const at::DeprecatedTypeProperties& t) {\n",
            "                         ^~~~~~~~~~~\n",
            "  /content/apex/csrc/fused_dense.cpp: In lambda function:\n",
            "  /content/apex/csrc/fused_dense.cpp:77:15: warning: unused variable ‘d_b_ptr’ [-Wunused-variable]\n",
            "       scalar_t* d_b_ptr = d_bias.data_ptr<scalar_t>();\n",
            "                 ^\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:56:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "       return __VA_ARGS__();                                                        \\\n",
            "              ^~~~~~~~~~~\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:214:7: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Double, double, __VA_ARGS__)  \\\n",
            "         ^~~~~~~~~~~~~~~~~~~~\n",
            "  /content/apex/csrc/fused_dense.cpp:75:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "     AT_DISPATCH_FLOATING_TYPES_AND_HALF(input.type(), \"linear_bias_backward\", [&] {\n",
            "     ^\n",
            "  /content/apex/csrc/fused_dense.cpp:78:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
            "       auto result = linear_bias_backward_cuda<scalar_t>(\n",
            "            ^\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:56:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "       return __VA_ARGS__();                                                        \\\n",
            "              ^~~~~~~~~~~\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:214:7: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Double, double, __VA_ARGS__)  \\\n",
            "         ^~~~~~~~~~~~~~~~~~~~\n",
            "  /content/apex/csrc/fused_dense.cpp:75:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "     AT_DISPATCH_FLOATING_TYPES_AND_HALF(input.type(), \"linear_bias_backward\", [&] {\n",
            "     ^\n",
            "  /content/apex/csrc/fused_dense.cpp: In lambda function:\n",
            "  /content/apex/csrc/fused_dense.cpp:77:15: warning: unused variable ‘d_b_ptr’ [-Wunused-variable]\n",
            "       scalar_t* d_b_ptr = d_bias.data_ptr<scalar_t>();\n",
            "                 ^\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:56:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "       return __VA_ARGS__();                                                        \\\n",
            "              ^~~~~~~~~~~\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:215:7: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Float, float, __VA_ARGS__)    \\\n",
            "         ^~~~~~~~~~~~~~~~~~~~\n",
            "  /content/apex/csrc/fused_dense.cpp:75:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "     AT_DISPATCH_FLOATING_TYPES_AND_HALF(input.type(), \"linear_bias_backward\", [&] {\n",
            "     ^\n",
            "  /content/apex/csrc/fused_dense.cpp:78:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
            "       auto result = linear_bias_backward_cuda<scalar_t>(\n",
            "            ^\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:56:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "       return __VA_ARGS__();                                                        \\\n",
            "              ^~~~~~~~~~~\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:215:7: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Float, float, __VA_ARGS__)    \\\n",
            "         ^~~~~~~~~~~~~~~~~~~~\n",
            "  /content/apex/csrc/fused_dense.cpp:75:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "     AT_DISPATCH_FLOATING_TYPES_AND_HALF(input.type(), \"linear_bias_backward\", [&] {\n",
            "     ^\n",
            "  /content/apex/csrc/fused_dense.cpp: In lambda function:\n",
            "  /content/apex/csrc/fused_dense.cpp:77:15: warning: unused variable ‘d_b_ptr’ [-Wunused-variable]\n",
            "       scalar_t* d_b_ptr = d_bias.data_ptr<scalar_t>();\n",
            "                 ^\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:56:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "       return __VA_ARGS__();                                                        \\\n",
            "              ^~~~~~~~~~~\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:216:7: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Half, at::Half, __VA_ARGS__)  \\\n",
            "         ^~~~~~~~~~~~~~~~~~~~\n",
            "  /content/apex/csrc/fused_dense.cpp:75:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "     AT_DISPATCH_FLOATING_TYPES_AND_HALF(input.type(), \"linear_bias_backward\", [&] {\n",
            "     ^\n",
            "  /content/apex/csrc/fused_dense.cpp:78:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
            "       auto result = linear_bias_backward_cuda<scalar_t>(\n",
            "            ^\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:56:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "       return __VA_ARGS__();                                                        \\\n",
            "              ^~~~~~~~~~~\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:216:7: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Half, at::Half, __VA_ARGS__)  \\\n",
            "         ^~~~~~~~~~~~~~~~~~~~\n",
            "  /content/apex/csrc/fused_dense.cpp:75:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "     AT_DISPATCH_FLOATING_TYPES_AND_HALF(input.type(), \"linear_bias_backward\", [&] {\n",
            "     ^\n",
            "  /content/apex/csrc/fused_dense.cpp: In function ‘std::vector<at::Tensor> linear_gelu_linear_forward(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor)’:\n",
            "  /content/apex/csrc/fused_dense.cpp:106:70: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     auto output1 = at::empty({batch_size, hidden_features}, input.type());\n",
            "                                                                        ^\n",
            "  In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from /content/apex/csrc/fused_dense.cpp:1:\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:303:30: note: declared here\n",
            "     DeprecatedTypeProperties & type() const {\n",
            "                                ^~~~\n",
            "  /content/apex/csrc/fused_dense.cpp:107:70: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     auto gelu_in = at::empty({batch_size, hidden_features}, input.type());\n",
            "                                                                        ^\n",
            "  In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from /content/apex/csrc/fused_dense.cpp:1:\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:303:30: note: declared here\n",
            "     DeprecatedTypeProperties & type() const {\n",
            "                                ^~~~\n",
            "  /content/apex/csrc/fused_dense.cpp:108:67: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     auto output2 = at::empty({batch_size, out_features}, input.type());\n",
            "                                                                     ^\n",
            "  In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from /content/apex/csrc/fused_dense.cpp:1:\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:303:30: note: declared here\n",
            "     DeprecatedTypeProperties & type() const {\n",
            "                                ^~~~\n",
            "  /content/apex/csrc/fused_dense.cpp:111:55: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     auto lt_workspace = at::empty({1 << 22}, input.type());\n",
            "                                                         ^\n",
            "  In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from /content/apex/csrc/fused_dense.cpp:1:\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:303:30: note: declared here\n",
            "     DeprecatedTypeProperties & type() const {\n",
            "                                ^~~~\n",
            "  In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:13:0,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from /content/apex/csrc/fused_dense.cpp:1:\n",
            "  /content/apex/csrc/fused_dense.cpp: In lambda function:\n",
            "  /content/apex/csrc/fused_dense.cpp:113:50: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     AT_DISPATCH_FLOATING_TYPES_AND_HALF(input.type(), \"linear_gelu_linear_forward\", [&] {\n",
            "                                                    ^\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:209:28: note: in definition of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       const auto& the_type = TYPE;                                               \\\n",
            "                              ^~~~\n",
            "  In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from /content/apex/csrc/fused_dense.cpp:1:\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:303:30: note: declared here\n",
            "     DeprecatedTypeProperties & type() const {\n",
            "                                ^~~~\n",
            "  In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:13:0,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from /content/apex/csrc/fused_dense.cpp:1:\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:211:56: warning: ‘c10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)’ is deprecated: passing at::DeprecatedTypeProperties to an AT_DISPATCH macro is deprecated, pass an at::ScalarType instead [-Wdeprecated-declarations]\n",
            "       at::ScalarType _st = ::detail::scalar_type(the_type);                      \\\n",
            "                                                          ^\n",
            "  /content/apex/csrc/fused_dense.cpp:113:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "     AT_DISPATCH_FLOATING_TYPES_AND_HALF(input.type(), \"linear_gelu_linear_forward\", [&] {\n",
            "     ^\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:109:23: note: declared here\n",
            "   inline at::ScalarType scalar_type(const at::DeprecatedTypeProperties& t) {\n",
            "                         ^~~~~~~~~~~\n",
            "  /content/apex/csrc/fused_dense.cpp: In lambda function:\n",
            "  /content/apex/csrc/fused_dense.cpp:118:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
            "       auto result = linear_gelu_linear_forward_cuda<scalar_t>(\n",
            "            ^\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:56:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "       return __VA_ARGS__();                                                        \\\n",
            "              ^~~~~~~~~~~\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:214:7: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Double, double, __VA_ARGS__)  \\\n",
            "         ^~~~~~~~~~~~~~~~~~~~\n",
            "  /content/apex/csrc/fused_dense.cpp:113:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "     AT_DISPATCH_FLOATING_TYPES_AND_HALF(input.type(), \"linear_gelu_linear_forward\", [&] {\n",
            "     ^\n",
            "  /content/apex/csrc/fused_dense.cpp: In lambda function:\n",
            "  /content/apex/csrc/fused_dense.cpp:118:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
            "       auto result = linear_gelu_linear_forward_cuda<scalar_t>(\n",
            "            ^\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:56:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "       return __VA_ARGS__();                                                        \\\n",
            "              ^~~~~~~~~~~\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:215:7: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Float, float, __VA_ARGS__)    \\\n",
            "         ^~~~~~~~~~~~~~~~~~~~\n",
            "  /content/apex/csrc/fused_dense.cpp:113:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "     AT_DISPATCH_FLOATING_TYPES_AND_HALF(input.type(), \"linear_gelu_linear_forward\", [&] {\n",
            "     ^\n",
            "  /content/apex/csrc/fused_dense.cpp: In lambda function:\n",
            "  /content/apex/csrc/fused_dense.cpp:118:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
            "       auto result = linear_gelu_linear_forward_cuda<scalar_t>(\n",
            "            ^\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:56:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "       return __VA_ARGS__();                                                        \\\n",
            "              ^~~~~~~~~~~\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:216:7: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Half, at::Half, __VA_ARGS__)  \\\n",
            "         ^~~~~~~~~~~~~~~~~~~~\n",
            "  /content/apex/csrc/fused_dense.cpp:113:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "     AT_DISPATCH_FLOATING_TYPES_AND_HALF(input.type(), \"linear_gelu_linear_forward\", [&] {\n",
            "     ^\n",
            "  /content/apex/csrc/fused_dense.cpp: In function ‘std::vector<at::Tensor> linear_gelu_linear_backward(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor)’:\n",
            "  /content/apex/csrc/fused_dense.cpp:149:73: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     auto d_weight1 = at::empty({hidden_features, in_features}, input.type());\n",
            "                                                                           ^\n",
            "  In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from /content/apex/csrc/fused_dense.cpp:1:\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:303:30: note: declared here\n",
            "     DeprecatedTypeProperties & type() const {\n",
            "                                ^~~~\n",
            "  /content/apex/csrc/fused_dense.cpp:150:74: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     auto d_weight2 = at::empty({out_features, hidden_features}, input.type());\n",
            "                                                                            ^\n",
            "  In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from /content/apex/csrc/fused_dense.cpp:1:\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:303:30: note: declared here\n",
            "     DeprecatedTypeProperties & type() const {\n",
            "                                ^~~~\n",
            "  /content/apex/csrc/fused_dense.cpp:151:58: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     auto d_bias1 = at::empty({hidden_features}, input.type());\n",
            "                                                            ^\n",
            "  In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from /content/apex/csrc/fused_dense.cpp:1:\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:303:30: note: declared here\n",
            "     DeprecatedTypeProperties & type() const {\n",
            "                                ^~~~\n",
            "  /content/apex/csrc/fused_dense.cpp:152:55: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     auto d_bias2 = at::empty({out_features}, input.type());\n",
            "                                                         ^\n",
            "  In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from /content/apex/csrc/fused_dense.cpp:1:\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:303:30: note: declared here\n",
            "     DeprecatedTypeProperties & type() const {\n",
            "                                ^~~~\n",
            "  /content/apex/csrc/fused_dense.cpp:153:66: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     auto d_input = at::empty({batch_size, in_features}, input.type());\n",
            "                                                                    ^\n",
            "  In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from /content/apex/csrc/fused_dense.cpp:1:\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:303:30: note: declared here\n",
            "     DeprecatedTypeProperties & type() const {\n",
            "                                ^~~~\n",
            "  /content/apex/csrc/fused_dense.cpp:154:72: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     auto d_output1 = at::empty({batch_size, hidden_features}, input.type());\n",
            "                                                                          ^\n",
            "  In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from /content/apex/csrc/fused_dense.cpp:1:\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:303:30: note: declared here\n",
            "     DeprecatedTypeProperties & type() const {\n",
            "                                ^~~~\n",
            "  /content/apex/csrc/fused_dense.cpp:157:55: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     auto lt_workspace = at::empty({1 << 22}, input.type());\n",
            "                                                         ^\n",
            "  In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from /content/apex/csrc/fused_dense.cpp:1:\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:303:30: note: declared here\n",
            "     DeprecatedTypeProperties & type() const {\n",
            "                                ^~~~\n",
            "  In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:13:0,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from /content/apex/csrc/fused_dense.cpp:1:\n",
            "  /content/apex/csrc/fused_dense.cpp: In lambda function:\n",
            "  /content/apex/csrc/fused_dense.cpp:159:50: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     AT_DISPATCH_FLOATING_TYPES_AND_HALF(input.type(), \"linear_bias_backward\", [&] {\n",
            "                                                    ^\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:209:28: note: in definition of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       const auto& the_type = TYPE;                                               \\\n",
            "                              ^~~~\n",
            "  In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from /content/apex/csrc/fused_dense.cpp:1:\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:303:30: note: declared here\n",
            "     DeprecatedTypeProperties & type() const {\n",
            "                                ^~~~\n",
            "  In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:13:0,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from /content/apex/csrc/fused_dense.cpp:1:\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:211:56: warning: ‘c10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)’ is deprecated: passing at::DeprecatedTypeProperties to an AT_DISPATCH macro is deprecated, pass an at::ScalarType instead [-Wdeprecated-declarations]\n",
            "       at::ScalarType _st = ::detail::scalar_type(the_type);                      \\\n",
            "                                                          ^\n",
            "  /content/apex/csrc/fused_dense.cpp:159:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "     AT_DISPATCH_FLOATING_TYPES_AND_HALF(input.type(), \"linear_bias_backward\", [&] {\n",
            "     ^\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:109:23: note: declared here\n",
            "   inline at::ScalarType scalar_type(const at::DeprecatedTypeProperties& t) {\n",
            "                         ^~~~~~~~~~~\n",
            "  /content/apex/csrc/fused_dense.cpp: In lambda function:\n",
            "  /content/apex/csrc/fused_dense.cpp:162:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
            "       auto result = linear_gelu_linear_backward_cuda<scalar_t>(\n",
            "            ^\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:56:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "       return __VA_ARGS__();                                                        \\\n",
            "              ^~~~~~~~~~~\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:214:7: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Double, double, __VA_ARGS__)  \\\n",
            "         ^~~~~~~~~~~~~~~~~~~~\n",
            "  /content/apex/csrc/fused_dense.cpp:159:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "     AT_DISPATCH_FLOATING_TYPES_AND_HALF(input.type(), \"linear_bias_backward\", [&] {\n",
            "     ^\n",
            "  /content/apex/csrc/fused_dense.cpp: In lambda function:\n",
            "  /content/apex/csrc/fused_dense.cpp:162:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
            "       auto result = linear_gelu_linear_backward_cuda<scalar_t>(\n",
            "            ^\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:56:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "       return __VA_ARGS__();                                                        \\\n",
            "              ^~~~~~~~~~~\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:215:7: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Float, float, __VA_ARGS__)    \\\n",
            "         ^~~~~~~~~~~~~~~~~~~~\n",
            "  /content/apex/csrc/fused_dense.cpp:159:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "     AT_DISPATCH_FLOATING_TYPES_AND_HALF(input.type(), \"linear_bias_backward\", [&] {\n",
            "     ^\n",
            "  /content/apex/csrc/fused_dense.cpp: In lambda function:\n",
            "  /content/apex/csrc/fused_dense.cpp:162:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
            "       auto result = linear_gelu_linear_backward_cuda<scalar_t>(\n",
            "            ^\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:56:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "       return __VA_ARGS__();                                                        \\\n",
            "              ^~~~~~~~~~~\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:216:7: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Half, at::Half, __VA_ARGS__)  \\\n",
            "         ^~~~~~~~~~~~~~~~~~~~\n",
            "  /content/apex/csrc/fused_dense.cpp:159:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "     AT_DISPATCH_FLOATING_TYPES_AND_HALF(input.type(), \"linear_bias_backward\", [&] {\n",
            "     ^\n",
            "  [2/2] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /content/apex/build/temp.linux-x86_64-3.7/csrc/fused_dense_cuda.o.d -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c -c /content/apex/csrc/fused_dense_cuda.cu -o /content/apex/build/temp.linux-x86_64-3.7/csrc/fused_dense_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=fused_dense_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=compute_37 -gencode=arch=compute_37,code=sm_37 -std=c++14\n",
            "  nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
            "  /content/apex/csrc/fused_dense_cuda.cu(1148): warning: variable \"beta_zero\" was declared but never referenced\n",
            "\n",
            "  /content/apex/csrc/fused_dense_cuda.cu(1272): warning: variable \"alpha\" was declared but never referenced\n",
            "\n",
            "  /content/apex/csrc/fused_dense_cuda.cu(1273): warning: variable \"beta_zero\" was declared but never referenced\n",
            "\n",
            "  /content/apex/csrc/fused_dense_cuda.cu(1274): warning: variable \"status\" was declared but never referenced\n",
            "\n",
            "  /content/apex/csrc/fused_dense_cuda.cu(1329): warning: variable \"alpha\" was declared but never referenced\n",
            "\n",
            "  /content/apex/csrc/fused_dense_cuda.cu(1330): warning: variable \"beta_zero\" was declared but never referenced\n",
            "\n",
            "  x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fdebug-prefix-map=/build/python3.7-pX47U3/python3.7-3.7.12=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 /content/apex/build/temp.linux-x86_64-3.7/csrc/fused_dense.o /content/apex/build/temp.linux-x86_64-3.7/csrc/fused_dense_cuda.o -L/usr/local/lib/python3.7/dist-packages/torch/lib -L/usr/local/cuda/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda_cu -ltorch_cuda_cpp -o build/lib.linux-x86_64-3.7/fused_dense_cuda.cpython-37m-x86_64-linux-gnu.so\n",
            "  building 'scaled_upper_triang_masked_softmax_cuda' extension\n",
            "  creating /content/apex/build/temp.linux-x86_64-3.7/csrc/megatron\n",
            "  Emitting ninja build file /content/apex/build/temp.linux-x86_64-3.7/build.ninja...\n",
            "  Compiling objects...\n",
            "  Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
            "  [1/2] c++ -MMD -MF /content/apex/build/temp.linux-x86_64-3.7/csrc/megatron/scaled_upper_triang_masked_softmax.o.d -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-pX47U3/python3.7-3.7.12=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-pX47U3/python3.7-3.7.12=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/content/apex/csrc -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c -c /content/apex/csrc/megatron/scaled_upper_triang_masked_softmax.cpp -o /content/apex/build/temp.linux-x86_64-3.7/csrc/megatron/scaled_upper_triang_masked_softmax.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=scaled_upper_triang_masked_softmax_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "  In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Parallel.h:140:0,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/utils.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:5,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/nn.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:13,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from /content/apex/csrc/megatron/scaled_upper_triang_masked_softmax.cpp:18:\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ParallelOpenMP.h:83:0: warning: ignoring #pragma omp parallel [-Wunknown-pragmas]\n",
            "   #pragma omp parallel for if ((end - begin) >= grain_size)\n",
            "\n",
            "  [2/2] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /content/apex/build/temp.linux-x86_64-3.7/csrc/megatron/scaled_upper_triang_masked_softmax_cuda.o.d -I/content/apex/csrc -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c -c /content/apex/csrc/megatron/scaled_upper_triang_masked_softmax_cuda.cu -o /content/apex/build/temp.linux-x86_64-3.7/csrc/megatron/scaled_upper_triang_masked_softmax_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -O3 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=scaled_upper_triang_masked_softmax_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=compute_37 -gencode=arch=compute_37,code=sm_37 -std=c++14\n",
            "  nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
            "  x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fdebug-prefix-map=/build/python3.7-pX47U3/python3.7-3.7.12=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 /content/apex/build/temp.linux-x86_64-3.7/csrc/megatron/scaled_upper_triang_masked_softmax.o /content/apex/build/temp.linux-x86_64-3.7/csrc/megatron/scaled_upper_triang_masked_softmax_cuda.o -L/usr/local/lib/python3.7/dist-packages/torch/lib -L/usr/local/cuda/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda_cu -ltorch_cuda_cpp -o build/lib.linux-x86_64-3.7/scaled_upper_triang_masked_softmax_cuda.cpython-37m-x86_64-linux-gnu.so\n",
            "  building 'scaled_masked_softmax_cuda' extension\n",
            "  Emitting ninja build file /content/apex/build/temp.linux-x86_64-3.7/build.ninja...\n",
            "  Compiling objects...\n",
            "  Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
            "  [1/2] c++ -MMD -MF /content/apex/build/temp.linux-x86_64-3.7/csrc/megatron/scaled_masked_softmax.o.d -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-pX47U3/python3.7-3.7.12=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-pX47U3/python3.7-3.7.12=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/content/apex/csrc -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c -c /content/apex/csrc/megatron/scaled_masked_softmax.cpp -o /content/apex/build/temp.linux-x86_64-3.7/csrc/megatron/scaled_masked_softmax.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=scaled_masked_softmax_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "  In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Parallel.h:140:0,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/utils.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:5,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/nn.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:13,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from /content/apex/csrc/megatron/scaled_masked_softmax.cpp:18:\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ParallelOpenMP.h:83:0: warning: ignoring #pragma omp parallel [-Wunknown-pragmas]\n",
            "   #pragma omp parallel for if ((end - begin) >= grain_size)\n",
            "\n",
            "  [2/2] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /content/apex/build/temp.linux-x86_64-3.7/csrc/megatron/scaled_masked_softmax_cuda.o.d -I/content/apex/csrc -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c -c /content/apex/csrc/megatron/scaled_masked_softmax_cuda.cu -o /content/apex/build/temp.linux-x86_64-3.7/csrc/megatron/scaled_masked_softmax_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -O3 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=scaled_masked_softmax_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=compute_37 -gencode=arch=compute_37,code=sm_37 -std=c++14\n",
            "  nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
            "  x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fdebug-prefix-map=/build/python3.7-pX47U3/python3.7-3.7.12=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 /content/apex/build/temp.linux-x86_64-3.7/csrc/megatron/scaled_masked_softmax.o /content/apex/build/temp.linux-x86_64-3.7/csrc/megatron/scaled_masked_softmax_cuda.o -L/usr/local/lib/python3.7/dist-packages/torch/lib -L/usr/local/cuda/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda_cu -ltorch_cuda_cpp -o build/lib.linux-x86_64-3.7/scaled_masked_softmax_cuda.cpython-37m-x86_64-linux-gnu.so\n",
            "  building 'fused_weight_gradient_mlp_cuda' extension\n",
            "  Emitting ninja build file /content/apex/build/temp.linux-x86_64-3.7/build.ninja...\n",
            "  Compiling objects...\n",
            "  Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
            "  [1/3] c++ -MMD -MF /content/apex/build/temp.linux-x86_64-3.7/csrc/megatron/fused_weight_gradient_dense.o.d -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-pX47U3/python3.7-3.7.12=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-pX47U3/python3.7-3.7.12=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/content/apex/csrc -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c -c /content/apex/csrc/megatron/fused_weight_gradient_dense.cpp -o /content/apex/build/temp.linux-x86_64-3.7/csrc/megatron/fused_weight_gradient_dense.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=fused_weight_gradient_mlp_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "  In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Parallel.h:140:0,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/utils.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:5,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/nn.h:3,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:13,\n",
            "                   from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from /content/apex/csrc/megatron/fused_weight_gradient_dense.cpp:1:\n",
            "  /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ParallelOpenMP.h:83:0: warning: ignoring #pragma omp parallel [-Wunknown-pragmas]\n",
            "   #pragma omp parallel for if ((end - begin) >= grain_size)\n",
            "\n",
            "  [2/3] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /content/apex/build/temp.linux-x86_64-3.7/csrc/megatron/fused_weight_gradient_dense_cuda.o.d -I/content/apex/csrc -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c -c /content/apex/csrc/megatron/fused_weight_gradient_dense_cuda.cu -o /content/apex/build/temp.linux-x86_64-3.7/csrc/megatron/fused_weight_gradient_dense_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -O3 -gencode arch=compute_70,code=sm_70 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -gencode arch=compute_80,code=sm_80 -gencode arch=compute_86,code=sm_86 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=fused_weight_gradient_mlp_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "  [3/3] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /content/apex/build/temp.linux-x86_64-3.7/csrc/megatron/fused_weight_gradient_dense_16bit_prec_cuda.o.d -I/content/apex/csrc -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c -c /content/apex/csrc/megatron/fused_weight_gradient_dense_16bit_prec_cuda.cu -o /content/apex/build/temp.linux-x86_64-3.7/csrc/megatron/fused_weight_gradient_dense_16bit_prec_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -O3 -gencode arch=compute_70,code=sm_70 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -gencode arch=compute_80,code=sm_80 -gencode arch=compute_86,code=sm_86 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=fused_weight_gradient_mlp_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "  x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fdebug-prefix-map=/build/python3.7-pX47U3/python3.7-3.7.12=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 /content/apex/build/temp.linux-x86_64-3.7/csrc/megatron/fused_weight_gradient_dense.o /content/apex/build/temp.linux-x86_64-3.7/csrc/megatron/fused_weight_gradient_dense_cuda.o /content/apex/build/temp.linux-x86_64-3.7/csrc/megatron/fused_weight_gradient_dense_16bit_prec_cuda.o -L/usr/local/lib/python3.7/dist-packages/torch/lib -L/usr/local/cuda/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda_cu -ltorch_cuda_cpp -o build/lib.linux-x86_64-3.7/fused_weight_gradient_mlp_cuda.cpython-37m-x86_64-linux-gnu.so\n",
            "  running install_lib\n",
            "  copying build/lib.linux-x86_64-3.7/scaled_upper_triang_masked_softmax_cuda.cpython-37m-x86_64-linux-gnu.so -> /usr/local/lib/python3.7/dist-packages\n",
            "  copying build/lib.linux-x86_64-3.7/syncbn.cpython-37m-x86_64-linux-gnu.so -> /usr/local/lib/python3.7/dist-packages\n",
            "  copying build/lib.linux-x86_64-3.7/fused_dense_cuda.cpython-37m-x86_64-linux-gnu.so -> /usr/local/lib/python3.7/dist-packages\n",
            "  copying build/lib.linux-x86_64-3.7/apex_C.cpython-37m-x86_64-linux-gnu.so -> /usr/local/lib/python3.7/dist-packages\n",
            "  copying build/lib.linux-x86_64-3.7/mlp_cuda.cpython-37m-x86_64-linux-gnu.so -> /usr/local/lib/python3.7/dist-packages\n",
            "  copying build/lib.linux-x86_64-3.7/scaled_masked_softmax_cuda.cpython-37m-x86_64-linux-gnu.so -> /usr/local/lib/python3.7/dist-packages\n",
            "  creating /usr/local/lib/python3.7/dist-packages/apex\n",
            "  copying build/lib.linux-x86_64-3.7/apex/__init__.py -> /usr/local/lib/python3.7/dist-packages/apex\n",
            "  creating /usr/local/lib/python3.7/dist-packages/apex/pyprof\n",
            "  copying build/lib.linux-x86_64-3.7/apex/pyprof/__init__.py -> /usr/local/lib/python3.7/dist-packages/apex/pyprof\n",
            "  creating /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof\n",
            "  copying build/lib.linux-x86_64-3.7/apex/pyprof/prof/pointwise.py -> /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof\n",
            "  copying build/lib.linux-x86_64-3.7/apex/pyprof/prof/linear.py -> /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof\n",
            "  copying build/lib.linux-x86_64-3.7/apex/pyprof/prof/dropout.py -> /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof\n",
            "  copying build/lib.linux-x86_64-3.7/apex/pyprof/prof/blas.py -> /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof\n",
            "  copying build/lib.linux-x86_64-3.7/apex/pyprof/prof/convert.py -> /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof\n",
            "  copying build/lib.linux-x86_64-3.7/apex/pyprof/prof/normalization.py -> /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof\n",
            "  copying build/lib.linux-x86_64-3.7/apex/pyprof/prof/__init__.py -> /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof\n",
            "  copying build/lib.linux-x86_64-3.7/apex/pyprof/prof/usage.py -> /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof\n",
            "  copying build/lib.linux-x86_64-3.7/apex/pyprof/prof/prof.py -> /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof\n",
            "  copying build/lib.linux-x86_64-3.7/apex/pyprof/prof/data.py -> /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof\n",
            "  copying build/lib.linux-x86_64-3.7/apex/pyprof/prof/recurrentCell.py -> /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof\n",
            "  copying build/lib.linux-x86_64-3.7/apex/pyprof/prof/misc.py -> /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof\n",
            "  copying build/lib.linux-x86_64-3.7/apex/pyprof/prof/__main__.py -> /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof\n",
            "  copying build/lib.linux-x86_64-3.7/apex/pyprof/prof/activation.py -> /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof\n",
            "  copying build/lib.linux-x86_64-3.7/apex/pyprof/prof/output.py -> /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof\n",
            "  copying build/lib.linux-x86_64-3.7/apex/pyprof/prof/randomSample.py -> /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof\n",
            "  copying build/lib.linux-x86_64-3.7/apex/pyprof/prof/optim.py -> /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof\n",
            "  copying build/lib.linux-x86_64-3.7/apex/pyprof/prof/embedding.py -> /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof\n",
            "  copying build/lib.linux-x86_64-3.7/apex/pyprof/prof/conv.py -> /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof\n",
            "  copying build/lib.linux-x86_64-3.7/apex/pyprof/prof/reduction.py -> /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof\n",
            "  copying build/lib.linux-x86_64-3.7/apex/pyprof/prof/softmax.py -> /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof\n",
            "  copying build/lib.linux-x86_64-3.7/apex/pyprof/prof/loss.py -> /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof\n",
            "  copying build/lib.linux-x86_64-3.7/apex/pyprof/prof/utility.py -> /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof\n",
            "  copying build/lib.linux-x86_64-3.7/apex/pyprof/prof/base.py -> /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof\n",
            "  copying build/lib.linux-x86_64-3.7/apex/pyprof/prof/index_slice_join_mutate.py -> /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof\n",
            "  copying build/lib.linux-x86_64-3.7/apex/pyprof/prof/pooling.py -> /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof\n",
            "  creating /usr/local/lib/python3.7/dist-packages/apex/pyprof/nvtx\n",
            "  copying build/lib.linux-x86_64-3.7/apex/pyprof/nvtx/__init__.py -> /usr/local/lib/python3.7/dist-packages/apex/pyprof/nvtx\n",
            "  copying build/lib.linux-x86_64-3.7/apex/pyprof/nvtx/nvmarker.py -> /usr/local/lib/python3.7/dist-packages/apex/pyprof/nvtx\n",
            "  creating /usr/local/lib/python3.7/dist-packages/apex/pyprof/parse\n",
            "  copying build/lib.linux-x86_64-3.7/apex/pyprof/parse/__init__.py -> /usr/local/lib/python3.7/dist-packages/apex/pyprof/parse\n",
            "  copying build/lib.linux-x86_64-3.7/apex/pyprof/parse/__main__.py -> /usr/local/lib/python3.7/dist-packages/apex/pyprof/parse\n",
            "  copying build/lib.linux-x86_64-3.7/apex/pyprof/parse/parse.py -> /usr/local/lib/python3.7/dist-packages/apex/pyprof/parse\n",
            "  copying build/lib.linux-x86_64-3.7/apex/pyprof/parse/kernel.py -> /usr/local/lib/python3.7/dist-packages/apex/pyprof/parse\n",
            "  copying build/lib.linux-x86_64-3.7/apex/pyprof/parse/nvvp.py -> /usr/local/lib/python3.7/dist-packages/apex/pyprof/parse\n",
            "  copying build/lib.linux-x86_64-3.7/apex/pyprof/parse/db.py -> /usr/local/lib/python3.7/dist-packages/apex/pyprof/parse\n",
            "  creating /usr/local/lib/python3.7/dist-packages/apex/optimizers\n",
            "  copying build/lib.linux-x86_64-3.7/apex/optimizers/fused_adam.py -> /usr/local/lib/python3.7/dist-packages/apex/optimizers\n",
            "  copying build/lib.linux-x86_64-3.7/apex/optimizers/fused_adagrad.py -> /usr/local/lib/python3.7/dist-packages/apex/optimizers\n",
            "  copying build/lib.linux-x86_64-3.7/apex/optimizers/__init__.py -> /usr/local/lib/python3.7/dist-packages/apex/optimizers\n",
            "  copying build/lib.linux-x86_64-3.7/apex/optimizers/fused_sgd.py -> /usr/local/lib/python3.7/dist-packages/apex/optimizers\n",
            "  copying build/lib.linux-x86_64-3.7/apex/optimizers/fused_lamb.py -> /usr/local/lib/python3.7/dist-packages/apex/optimizers\n",
            "  copying build/lib.linux-x86_64-3.7/apex/optimizers/fused_novograd.py -> /usr/local/lib/python3.7/dist-packages/apex/optimizers\n",
            "  copying build/lib.linux-x86_64-3.7/apex/optimizers/fused_mixed_precision_lamb.py -> /usr/local/lib/python3.7/dist-packages/apex/optimizers\n",
            "  creating /usr/local/lib/python3.7/dist-packages/apex/parallel\n",
            "  copying build/lib.linux-x86_64-3.7/apex/parallel/LARC.py -> /usr/local/lib/python3.7/dist-packages/apex/parallel\n",
            "  copying build/lib.linux-x86_64-3.7/apex/parallel/__init__.py -> /usr/local/lib/python3.7/dist-packages/apex/parallel\n",
            "  copying build/lib.linux-x86_64-3.7/apex/parallel/distributed.py -> /usr/local/lib/python3.7/dist-packages/apex/parallel\n",
            "  copying build/lib.linux-x86_64-3.7/apex/parallel/sync_batchnorm.py -> /usr/local/lib/python3.7/dist-packages/apex/parallel\n",
            "  copying build/lib.linux-x86_64-3.7/apex/parallel/optimized_sync_batchnorm.py -> /usr/local/lib/python3.7/dist-packages/apex/parallel\n",
            "  copying build/lib.linux-x86_64-3.7/apex/parallel/optimized_sync_batchnorm_kernel.py -> /usr/local/lib/python3.7/dist-packages/apex/parallel\n",
            "  copying build/lib.linux-x86_64-3.7/apex/parallel/multiproc.py -> /usr/local/lib/python3.7/dist-packages/apex/parallel\n",
            "  copying build/lib.linux-x86_64-3.7/apex/parallel/sync_batchnorm_kernel.py -> /usr/local/lib/python3.7/dist-packages/apex/parallel\n",
            "  creating /usr/local/lib/python3.7/dist-packages/apex/mlp\n",
            "  copying build/lib.linux-x86_64-3.7/apex/mlp/__init__.py -> /usr/local/lib/python3.7/dist-packages/apex/mlp\n",
            "  copying build/lib.linux-x86_64-3.7/apex/mlp/mlp.py -> /usr/local/lib/python3.7/dist-packages/apex/mlp\n",
            "  creating /usr/local/lib/python3.7/dist-packages/apex/transformer\n",
            "  copying build/lib.linux-x86_64-3.7/apex/transformer/enums.py -> /usr/local/lib/python3.7/dist-packages/apex/transformer\n",
            "  copying build/lib.linux-x86_64-3.7/apex/transformer/microbatches.py -> /usr/local/lib/python3.7/dist-packages/apex/transformer\n",
            "  copying build/lib.linux-x86_64-3.7/apex/transformer/__init__.py -> /usr/local/lib/python3.7/dist-packages/apex/transformer\n",
            "  creating /usr/local/lib/python3.7/dist-packages/apex/transformer/pipeline_parallel\n",
            "  copying build/lib.linux-x86_64-3.7/apex/transformer/pipeline_parallel/__init__.py -> /usr/local/lib/python3.7/dist-packages/apex/transformer/pipeline_parallel\n",
            "  copying build/lib.linux-x86_64-3.7/apex/transformer/pipeline_parallel/_timers.py -> /usr/local/lib/python3.7/dist-packages/apex/transformer/pipeline_parallel\n",
            "  copying build/lib.linux-x86_64-3.7/apex/transformer/pipeline_parallel/p2p_communication.py -> /usr/local/lib/python3.7/dist-packages/apex/transformer/pipeline_parallel\n",
            "  copying build/lib.linux-x86_64-3.7/apex/transformer/pipeline_parallel/utils.py -> /usr/local/lib/python3.7/dist-packages/apex/transformer/pipeline_parallel\n",
            "  creating /usr/local/lib/python3.7/dist-packages/apex/transformer/pipeline_parallel/schedules\n",
            "  copying build/lib.linux-x86_64-3.7/apex/transformer/pipeline_parallel/schedules/fwd_bwd_pipelining_without_interleaving.py -> /usr/local/lib/python3.7/dist-packages/apex/transformer/pipeline_parallel/schedules\n",
            "  copying build/lib.linux-x86_64-3.7/apex/transformer/pipeline_parallel/schedules/fwd_bwd_pipelining_with_interleaving.py -> /usr/local/lib/python3.7/dist-packages/apex/transformer/pipeline_parallel/schedules\n",
            "  copying build/lib.linux-x86_64-3.7/apex/transformer/pipeline_parallel/schedules/__init__.py -> /usr/local/lib/python3.7/dist-packages/apex/transformer/pipeline_parallel/schedules\n",
            "  copying build/lib.linux-x86_64-3.7/apex/transformer/pipeline_parallel/schedules/common.py -> /usr/local/lib/python3.7/dist-packages/apex/transformer/pipeline_parallel/schedules\n",
            "  copying build/lib.linux-x86_64-3.7/apex/transformer/pipeline_parallel/schedules/fwd_bwd_no_pipelining.py -> /usr/local/lib/python3.7/dist-packages/apex/transformer/pipeline_parallel/schedules\n",
            "  creating /usr/local/lib/python3.7/dist-packages/apex/transformer/tensor_parallel\n",
            "  copying build/lib.linux-x86_64-3.7/apex/transformer/tensor_parallel/random.py -> /usr/local/lib/python3.7/dist-packages/apex/transformer/tensor_parallel\n",
            "  copying build/lib.linux-x86_64-3.7/apex/transformer/tensor_parallel/layers.py -> /usr/local/lib/python3.7/dist-packages/apex/transformer/tensor_parallel\n",
            "  copying build/lib.linux-x86_64-3.7/apex/transformer/tensor_parallel/mappings.py -> /usr/local/lib/python3.7/dist-packages/apex/transformer/tensor_parallel\n",
            "  copying build/lib.linux-x86_64-3.7/apex/transformer/tensor_parallel/__init__.py -> /usr/local/lib/python3.7/dist-packages/apex/transformer/tensor_parallel\n",
            "  copying build/lib.linux-x86_64-3.7/apex/transformer/tensor_parallel/data.py -> /usr/local/lib/python3.7/dist-packages/apex/transformer/tensor_parallel\n",
            "  copying build/lib.linux-x86_64-3.7/apex/transformer/tensor_parallel/cross_entropy.py -> /usr/local/lib/python3.7/dist-packages/apex/transformer/tensor_parallel\n",
            "  copying build/lib.linux-x86_64-3.7/apex/transformer/tensor_parallel/utils.py -> /usr/local/lib/python3.7/dist-packages/apex/transformer/tensor_parallel\n",
            "  copying build/lib.linux-x86_64-3.7/apex/transformer/tensor_parallel/memory.py -> /usr/local/lib/python3.7/dist-packages/apex/transformer/tensor_parallel\n",
            "  copying build/lib.linux-x86_64-3.7/apex/transformer/log_util.py -> /usr/local/lib/python3.7/dist-packages/apex/transformer\n",
            "  copying build/lib.linux-x86_64-3.7/apex/transformer/utils.py -> /usr/local/lib/python3.7/dist-packages/apex/transformer\n",
            "  creating /usr/local/lib/python3.7/dist-packages/apex/transformer/testing\n",
            "  copying build/lib.linux-x86_64-3.7/apex/transformer/testing/commons.py -> /usr/local/lib/python3.7/dist-packages/apex/transformer/testing\n",
            "  copying build/lib.linux-x86_64-3.7/apex/transformer/testing/__init__.py -> /usr/local/lib/python3.7/dist-packages/apex/transformer/testing\n",
            "  copying build/lib.linux-x86_64-3.7/apex/transformer/testing/standalone_bert.py -> /usr/local/lib/python3.7/dist-packages/apex/transformer/testing\n",
            "  copying build/lib.linux-x86_64-3.7/apex/transformer/testing/standalone_gpt.py -> /usr/local/lib/python3.7/dist-packages/apex/transformer/testing\n",
            "  copying build/lib.linux-x86_64-3.7/apex/transformer/testing/global_vars.py -> /usr/local/lib/python3.7/dist-packages/apex/transformer/testing\n",
            "  copying build/lib.linux-x86_64-3.7/apex/transformer/testing/arguments.py -> /usr/local/lib/python3.7/dist-packages/apex/transformer/testing\n",
            "  copying build/lib.linux-x86_64-3.7/apex/transformer/parallel_state.py -> /usr/local/lib/python3.7/dist-packages/apex/transformer\n",
            "  creating /usr/local/lib/python3.7/dist-packages/apex/transformer/amp\n",
            "  copying build/lib.linux-x86_64-3.7/apex/transformer/amp/__init__.py -> /usr/local/lib/python3.7/dist-packages/apex/transformer/amp\n",
            "  copying build/lib.linux-x86_64-3.7/apex/transformer/amp/grad_scaler.py -> /usr/local/lib/python3.7/dist-packages/apex/transformer/amp\n",
            "  creating /usr/local/lib/python3.7/dist-packages/apex/transformer/_data\n",
            "  copying build/lib.linux-x86_64-3.7/apex/transformer/_data/__init__.py -> /usr/local/lib/python3.7/dist-packages/apex/transformer/_data\n",
            "  copying build/lib.linux-x86_64-3.7/apex/transformer/_data/_batchsampler.py -> /usr/local/lib/python3.7/dist-packages/apex/transformer/_data\n",
            "  creating /usr/local/lib/python3.7/dist-packages/apex/transformer/functional\n",
            "  copying build/lib.linux-x86_64-3.7/apex/transformer/functional/__init__.py -> /usr/local/lib/python3.7/dist-packages/apex/transformer/functional\n",
            "  copying build/lib.linux-x86_64-3.7/apex/transformer/functional/fused_softmax.py -> /usr/local/lib/python3.7/dist-packages/apex/transformer/functional\n",
            "  creating /usr/local/lib/python3.7/dist-packages/apex/normalization\n",
            "  copying build/lib.linux-x86_64-3.7/apex/normalization/__init__.py -> /usr/local/lib/python3.7/dist-packages/apex/normalization\n",
            "  copying build/lib.linux-x86_64-3.7/apex/normalization/fused_layer_norm.py -> /usr/local/lib/python3.7/dist-packages/apex/normalization\n",
            "  creating /usr/local/lib/python3.7/dist-packages/apex/RNN\n",
            "  copying build/lib.linux-x86_64-3.7/apex/RNN/__init__.py -> /usr/local/lib/python3.7/dist-packages/apex/RNN\n",
            "  copying build/lib.linux-x86_64-3.7/apex/RNN/cells.py -> /usr/local/lib/python3.7/dist-packages/apex/RNN\n",
            "  copying build/lib.linux-x86_64-3.7/apex/RNN/RNNBackend.py -> /usr/local/lib/python3.7/dist-packages/apex/RNN\n",
            "  copying build/lib.linux-x86_64-3.7/apex/RNN/models.py -> /usr/local/lib/python3.7/dist-packages/apex/RNN\n",
            "  creating /usr/local/lib/python3.7/dist-packages/apex/fused_dense\n",
            "  copying build/lib.linux-x86_64-3.7/apex/fused_dense/__init__.py -> /usr/local/lib/python3.7/dist-packages/apex/fused_dense\n",
            "  copying build/lib.linux-x86_64-3.7/apex/fused_dense/fused_dense.py -> /usr/local/lib/python3.7/dist-packages/apex/fused_dense\n",
            "  creating /usr/local/lib/python3.7/dist-packages/apex/amp\n",
            "  copying build/lib.linux-x86_64-3.7/apex/amp/wrap.py -> /usr/local/lib/python3.7/dist-packages/apex/amp\n",
            "  copying build/lib.linux-x86_64-3.7/apex/amp/scaler.py -> /usr/local/lib/python3.7/dist-packages/apex/amp\n",
            "  copying build/lib.linux-x86_64-3.7/apex/amp/__init__.py -> /usr/local/lib/python3.7/dist-packages/apex/amp\n",
            "  copying build/lib.linux-x86_64-3.7/apex/amp/amp.py -> /usr/local/lib/python3.7/dist-packages/apex/amp\n",
            "  copying build/lib.linux-x86_64-3.7/apex/amp/compat.py -> /usr/local/lib/python3.7/dist-packages/apex/amp\n",
            "  copying build/lib.linux-x86_64-3.7/apex/amp/frontend.py -> /usr/local/lib/python3.7/dist-packages/apex/amp\n",
            "  copying build/lib.linux-x86_64-3.7/apex/amp/utils.py -> /usr/local/lib/python3.7/dist-packages/apex/amp\n",
            "  creating /usr/local/lib/python3.7/dist-packages/apex/amp/lists\n",
            "  copying build/lib.linux-x86_64-3.7/apex/amp/lists/__init__.py -> /usr/local/lib/python3.7/dist-packages/apex/amp/lists\n",
            "  copying build/lib.linux-x86_64-3.7/apex/amp/lists/tensor_overrides.py -> /usr/local/lib/python3.7/dist-packages/apex/amp/lists\n",
            "  copying build/lib.linux-x86_64-3.7/apex/amp/lists/torch_overrides.py -> /usr/local/lib/python3.7/dist-packages/apex/amp/lists\n",
            "  copying build/lib.linux-x86_64-3.7/apex/amp/lists/functional_overrides.py -> /usr/local/lib/python3.7/dist-packages/apex/amp/lists\n",
            "  copying build/lib.linux-x86_64-3.7/apex/amp/handle.py -> /usr/local/lib/python3.7/dist-packages/apex/amp\n",
            "  copying build/lib.linux-x86_64-3.7/apex/amp/__version__.py -> /usr/local/lib/python3.7/dist-packages/apex/amp\n",
            "  copying build/lib.linux-x86_64-3.7/apex/amp/_amp_state.py -> /usr/local/lib/python3.7/dist-packages/apex/amp\n",
            "  copying build/lib.linux-x86_64-3.7/apex/amp/opt.py -> /usr/local/lib/python3.7/dist-packages/apex/amp\n",
            "  copying build/lib.linux-x86_64-3.7/apex/amp/_initialize.py -> /usr/local/lib/python3.7/dist-packages/apex/amp\n",
            "  copying build/lib.linux-x86_64-3.7/apex/amp/rnn_compat.py -> /usr/local/lib/python3.7/dist-packages/apex/amp\n",
            "  copying build/lib.linux-x86_64-3.7/apex/amp/_process_optimizer.py -> /usr/local/lib/python3.7/dist-packages/apex/amp\n",
            "  creating /usr/local/lib/python3.7/dist-packages/apex/contrib\n",
            "  creating /usr/local/lib/python3.7/dist-packages/apex/contrib/xentropy\n",
            "  copying build/lib.linux-x86_64-3.7/apex/contrib/xentropy/__init__.py -> /usr/local/lib/python3.7/dist-packages/apex/contrib/xentropy\n",
            "  copying build/lib.linux-x86_64-3.7/apex/contrib/xentropy/softmax_xentropy.py -> /usr/local/lib/python3.7/dist-packages/apex/contrib/xentropy\n",
            "  copying build/lib.linux-x86_64-3.7/apex/contrib/__init__.py -> /usr/local/lib/python3.7/dist-packages/apex/contrib\n",
            "  creating /usr/local/lib/python3.7/dist-packages/apex/contrib/optimizers\n",
            "  copying build/lib.linux-x86_64-3.7/apex/contrib/optimizers/fused_adam.py -> /usr/local/lib/python3.7/dist-packages/apex/contrib/optimizers\n",
            "  copying build/lib.linux-x86_64-3.7/apex/contrib/optimizers/__init__.py -> /usr/local/lib/python3.7/dist-packages/apex/contrib/optimizers\n",
            "  copying build/lib.linux-x86_64-3.7/apex/contrib/optimizers/fused_sgd.py -> /usr/local/lib/python3.7/dist-packages/apex/contrib/optimizers\n",
            "  copying build/lib.linux-x86_64-3.7/apex/contrib/optimizers/distributed_fused_lamb.py -> /usr/local/lib/python3.7/dist-packages/apex/contrib/optimizers\n",
            "  copying build/lib.linux-x86_64-3.7/apex/contrib/optimizers/fp16_optimizer.py -> /usr/local/lib/python3.7/dist-packages/apex/contrib/optimizers\n",
            "  copying build/lib.linux-x86_64-3.7/apex/contrib/optimizers/distributed_fused_adam_v3.py -> /usr/local/lib/python3.7/dist-packages/apex/contrib/optimizers\n",
            "  copying build/lib.linux-x86_64-3.7/apex/contrib/optimizers/distributed_fused_adam_v2.py -> /usr/local/lib/python3.7/dist-packages/apex/contrib/optimizers\n",
            "  copying build/lib.linux-x86_64-3.7/apex/contrib/optimizers/fused_lamb.py -> /usr/local/lib/python3.7/dist-packages/apex/contrib/optimizers\n",
            "  copying build/lib.linux-x86_64-3.7/apex/contrib/optimizers/distributed_fused_adam.py -> /usr/local/lib/python3.7/dist-packages/apex/contrib/optimizers\n",
            "  creating /usr/local/lib/python3.7/dist-packages/apex/contrib/transducer\n",
            "  copying build/lib.linux-x86_64-3.7/apex/contrib/transducer/__init__.py -> /usr/local/lib/python3.7/dist-packages/apex/contrib/transducer\n",
            "  copying build/lib.linux-x86_64-3.7/apex/contrib/transducer/transducer.py -> /usr/local/lib/python3.7/dist-packages/apex/contrib/transducer\n",
            "  creating /usr/local/lib/python3.7/dist-packages/apex/contrib/layer_norm\n",
            "  copying build/lib.linux-x86_64-3.7/apex/contrib/layer_norm/__init__.py -> /usr/local/lib/python3.7/dist-packages/apex/contrib/layer_norm\n",
            "  copying build/lib.linux-x86_64-3.7/apex/contrib/layer_norm/layer_norm.py -> /usr/local/lib/python3.7/dist-packages/apex/contrib/layer_norm\n",
            "  creating /usr/local/lib/python3.7/dist-packages/apex/contrib/multihead_attn\n",
            "  copying build/lib.linux-x86_64-3.7/apex/contrib/multihead_attn/mask_softmax_dropout_func.py -> /usr/local/lib/python3.7/dist-packages/apex/contrib/multihead_attn\n",
            "  copying build/lib.linux-x86_64-3.7/apex/contrib/multihead_attn/__init__.py -> /usr/local/lib/python3.7/dist-packages/apex/contrib/multihead_attn\n",
            "  copying build/lib.linux-x86_64-3.7/apex/contrib/multihead_attn/fast_encdec_multihead_attn_norm_add_func.py -> /usr/local/lib/python3.7/dist-packages/apex/contrib/multihead_attn\n",
            "  copying build/lib.linux-x86_64-3.7/apex/contrib/multihead_attn/fast_self_multihead_attn_func.py -> /usr/local/lib/python3.7/dist-packages/apex/contrib/multihead_attn\n",
            "  copying build/lib.linux-x86_64-3.7/apex/contrib/multihead_attn/self_multihead_attn_func.py -> /usr/local/lib/python3.7/dist-packages/apex/contrib/multihead_attn\n",
            "  copying build/lib.linux-x86_64-3.7/apex/contrib/multihead_attn/fast_self_multihead_attn_norm_add_func.py -> /usr/local/lib/python3.7/dist-packages/apex/contrib/multihead_attn\n",
            "  copying build/lib.linux-x86_64-3.7/apex/contrib/multihead_attn/encdec_multihead_attn_func.py -> /usr/local/lib/python3.7/dist-packages/apex/contrib/multihead_attn\n",
            "  copying build/lib.linux-x86_64-3.7/apex/contrib/multihead_attn/fast_encdec_multihead_attn_func.py -> /usr/local/lib/python3.7/dist-packages/apex/contrib/multihead_attn\n",
            "  copying build/lib.linux-x86_64-3.7/apex/contrib/multihead_attn/encdec_multihead_attn.py -> /usr/local/lib/python3.7/dist-packages/apex/contrib/multihead_attn\n",
            "  copying build/lib.linux-x86_64-3.7/apex/contrib/multihead_attn/self_multihead_attn.py -> /usr/local/lib/python3.7/dist-packages/apex/contrib/multihead_attn\n",
            "  creating /usr/local/lib/python3.7/dist-packages/apex/contrib/groupbn\n",
            "  copying build/lib.linux-x86_64-3.7/apex/contrib/groupbn/__init__.py -> /usr/local/lib/python3.7/dist-packages/apex/contrib/groupbn\n",
            "  copying build/lib.linux-x86_64-3.7/apex/contrib/groupbn/batch_norm.py -> /usr/local/lib/python3.7/dist-packages/apex/contrib/groupbn\n",
            "  creating /usr/local/lib/python3.7/dist-packages/apex/contrib/fmha\n",
            "  copying build/lib.linux-x86_64-3.7/apex/contrib/fmha/__init__.py -> /usr/local/lib/python3.7/dist-packages/apex/contrib/fmha\n",
            "  copying build/lib.linux-x86_64-3.7/apex/contrib/fmha/fmha.py -> /usr/local/lib/python3.7/dist-packages/apex/contrib/fmha\n",
            "  creating /usr/local/lib/python3.7/dist-packages/apex/contrib/sparsity\n",
            "  copying build/lib.linux-x86_64-3.7/apex/contrib/sparsity/sparse_masklib.py -> /usr/local/lib/python3.7/dist-packages/apex/contrib/sparsity\n",
            "  copying build/lib.linux-x86_64-3.7/apex/contrib/sparsity/__init__.py -> /usr/local/lib/python3.7/dist-packages/apex/contrib/sparsity\n",
            "  copying build/lib.linux-x86_64-3.7/apex/contrib/sparsity/asp.py -> /usr/local/lib/python3.7/dist-packages/apex/contrib/sparsity\n",
            "  creating /usr/local/lib/python3.7/dist-packages/apex/contrib/sparsity/permutation_search_kernels\n",
            "  copying build/lib.linux-x86_64-3.7/apex/contrib/sparsity/permutation_search_kernels/__init__.py -> /usr/local/lib/python3.7/dist-packages/apex/contrib/sparsity/permutation_search_kernels\n",
            "  copying build/lib.linux-x86_64-3.7/apex/contrib/sparsity/permutation_search_kernels/exhaustive_search.py -> /usr/local/lib/python3.7/dist-packages/apex/contrib/sparsity/permutation_search_kernels\n",
            "  copying build/lib.linux-x86_64-3.7/apex/contrib/sparsity/permutation_search_kernels/permutation_utilities.py -> /usr/local/lib/python3.7/dist-packages/apex/contrib/sparsity/permutation_search_kernels\n",
            "  copying build/lib.linux-x86_64-3.7/apex/contrib/sparsity/permutation_search_kernels/call_permutation_search_kernels.py -> /usr/local/lib/python3.7/dist-packages/apex/contrib/sparsity/permutation_search_kernels\n",
            "  copying build/lib.linux-x86_64-3.7/apex/contrib/sparsity/permutation_lib.py -> /usr/local/lib/python3.7/dist-packages/apex/contrib/sparsity\n",
            "  creating /usr/local/lib/python3.7/dist-packages/apex/contrib/bottleneck\n",
            "  copying build/lib.linux-x86_64-3.7/apex/contrib/bottleneck/__init__.py -> /usr/local/lib/python3.7/dist-packages/apex/contrib/bottleneck\n",
            "  copying build/lib.linux-x86_64-3.7/apex/contrib/bottleneck/bottleneck.py -> /usr/local/lib/python3.7/dist-packages/apex/contrib/bottleneck\n",
            "  copying build/lib.linux-x86_64-3.7/apex/contrib/bottleneck/bottleneck_module_test.py -> /usr/local/lib/python3.7/dist-packages/apex/contrib/bottleneck\n",
            "  copying build/lib.linux-x86_64-3.7/apex/contrib/bottleneck/test.py -> /usr/local/lib/python3.7/dist-packages/apex/contrib/bottleneck\n",
            "  creating /usr/local/lib/python3.7/dist-packages/apex/multi_tensor_apply\n",
            "  copying build/lib.linux-x86_64-3.7/apex/multi_tensor_apply/__init__.py -> /usr/local/lib/python3.7/dist-packages/apex/multi_tensor_apply\n",
            "  copying build/lib.linux-x86_64-3.7/apex/multi_tensor_apply/multi_tensor_apply.py -> /usr/local/lib/python3.7/dist-packages/apex/multi_tensor_apply\n",
            "  creating /usr/local/lib/python3.7/dist-packages/apex/reparameterization\n",
            "  copying build/lib.linux-x86_64-3.7/apex/reparameterization/__init__.py -> /usr/local/lib/python3.7/dist-packages/apex/reparameterization\n",
            "  copying build/lib.linux-x86_64-3.7/apex/reparameterization/weight_norm.py -> /usr/local/lib/python3.7/dist-packages/apex/reparameterization\n",
            "  copying build/lib.linux-x86_64-3.7/apex/reparameterization/reparameterization.py -> /usr/local/lib/python3.7/dist-packages/apex/reparameterization\n",
            "  creating /usr/local/lib/python3.7/dist-packages/apex/fp16_utils\n",
            "  copying build/lib.linux-x86_64-3.7/apex/fp16_utils/__init__.py -> /usr/local/lib/python3.7/dist-packages/apex/fp16_utils\n",
            "  copying build/lib.linux-x86_64-3.7/apex/fp16_utils/fp16util.py -> /usr/local/lib/python3.7/dist-packages/apex/fp16_utils\n",
            "  copying build/lib.linux-x86_64-3.7/apex/fp16_utils/fp16_optimizer.py -> /usr/local/lib/python3.7/dist-packages/apex/fp16_utils\n",
            "  copying build/lib.linux-x86_64-3.7/apex/fp16_utils/loss_scaler.py -> /usr/local/lib/python3.7/dist-packages/apex/fp16_utils\n",
            "  copying build/lib.linux-x86_64-3.7/apex/_autocast_utils.py -> /usr/local/lib/python3.7/dist-packages/apex\n",
            "  copying build/lib.linux-x86_64-3.7/amp_C.cpython-37m-x86_64-linux-gnu.so -> /usr/local/lib/python3.7/dist-packages\n",
            "  copying build/lib.linux-x86_64-3.7/fused_layer_norm_cuda.cpython-37m-x86_64-linux-gnu.so -> /usr/local/lib/python3.7/dist-packages\n",
            "  copying build/lib.linux-x86_64-3.7/fused_weight_gradient_mlp_cuda.cpython-37m-x86_64-linux-gnu.so -> /usr/local/lib/python3.7/dist-packages\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/__init__.py to __init__.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/pyprof/__init__.py to __init__.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof/pointwise.py to pointwise.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof/linear.py to linear.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof/dropout.py to dropout.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof/blas.py to blas.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof/convert.py to convert.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof/normalization.py to normalization.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof/__init__.py to __init__.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof/usage.py to usage.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof/prof.py to prof.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof/data.py to data.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof/recurrentCell.py to recurrentCell.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof/misc.py to misc.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof/__main__.py to __main__.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof/activation.py to activation.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof/output.py to output.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof/randomSample.py to randomSample.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof/optim.py to optim.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof/embedding.py to embedding.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof/conv.py to conv.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof/reduction.py to reduction.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof/softmax.py to softmax.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof/loss.py to loss.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof/utility.py to utility.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof/base.py to base.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof/index_slice_join_mutate.py to index_slice_join_mutate.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof/pooling.py to pooling.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/pyprof/nvtx/__init__.py to __init__.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/pyprof/nvtx/nvmarker.py to nvmarker.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/pyprof/parse/__init__.py to __init__.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/pyprof/parse/__main__.py to __main__.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/pyprof/parse/parse.py to parse.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/pyprof/parse/kernel.py to kernel.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/pyprof/parse/nvvp.py to nvvp.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/pyprof/parse/db.py to db.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/optimizers/fused_adam.py to fused_adam.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/optimizers/fused_adagrad.py to fused_adagrad.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/optimizers/__init__.py to __init__.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/optimizers/fused_sgd.py to fused_sgd.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/optimizers/fused_lamb.py to fused_lamb.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/optimizers/fused_novograd.py to fused_novograd.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/optimizers/fused_mixed_precision_lamb.py to fused_mixed_precision_lamb.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/parallel/LARC.py to LARC.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/parallel/__init__.py to __init__.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/parallel/distributed.py to distributed.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/parallel/sync_batchnorm.py to sync_batchnorm.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/parallel/optimized_sync_batchnorm.py to optimized_sync_batchnorm.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/parallel/optimized_sync_batchnorm_kernel.py to optimized_sync_batchnorm_kernel.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/parallel/multiproc.py to multiproc.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/parallel/sync_batchnorm_kernel.py to sync_batchnorm_kernel.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/mlp/__init__.py to __init__.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/mlp/mlp.py to mlp.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/transformer/enums.py to enums.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/transformer/microbatches.py to microbatches.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/transformer/__init__.py to __init__.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/transformer/pipeline_parallel/__init__.py to __init__.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/transformer/pipeline_parallel/_timers.py to _timers.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/transformer/pipeline_parallel/p2p_communication.py to p2p_communication.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/transformer/pipeline_parallel/utils.py to utils.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/transformer/pipeline_parallel/schedules/fwd_bwd_pipelining_without_interleaving.py to fwd_bwd_pipelining_without_interleaving.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/transformer/pipeline_parallel/schedules/fwd_bwd_pipelining_with_interleaving.py to fwd_bwd_pipelining_with_interleaving.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/transformer/pipeline_parallel/schedules/__init__.py to __init__.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/transformer/pipeline_parallel/schedules/common.py to common.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/transformer/pipeline_parallel/schedules/fwd_bwd_no_pipelining.py to fwd_bwd_no_pipelining.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/transformer/tensor_parallel/random.py to random.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/transformer/tensor_parallel/layers.py to layers.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/transformer/tensor_parallel/mappings.py to mappings.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/transformer/tensor_parallel/__init__.py to __init__.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/transformer/tensor_parallel/data.py to data.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/transformer/tensor_parallel/cross_entropy.py to cross_entropy.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/transformer/tensor_parallel/utils.py to utils.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/transformer/tensor_parallel/memory.py to memory.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/transformer/log_util.py to log_util.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/transformer/utils.py to utils.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/transformer/testing/commons.py to commons.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/transformer/testing/__init__.py to __init__.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/transformer/testing/standalone_bert.py to standalone_bert.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/transformer/testing/standalone_gpt.py to standalone_gpt.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/transformer/testing/global_vars.py to global_vars.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/transformer/testing/arguments.py to arguments.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/transformer/parallel_state.py to parallel_state.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/transformer/amp/__init__.py to __init__.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/transformer/amp/grad_scaler.py to grad_scaler.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/transformer/_data/__init__.py to __init__.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/transformer/_data/_batchsampler.py to _batchsampler.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/transformer/functional/__init__.py to __init__.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/transformer/functional/fused_softmax.py to fused_softmax.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/normalization/__init__.py to __init__.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/normalization/fused_layer_norm.py to fused_layer_norm.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/RNN/__init__.py to __init__.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/RNN/cells.py to cells.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/RNN/RNNBackend.py to RNNBackend.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/RNN/models.py to models.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/fused_dense/__init__.py to __init__.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/fused_dense/fused_dense.py to fused_dense.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/amp/wrap.py to wrap.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/amp/scaler.py to scaler.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/amp/__init__.py to __init__.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/amp/amp.py to amp.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/amp/compat.py to compat.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/amp/frontend.py to frontend.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/amp/utils.py to utils.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/amp/lists/__init__.py to __init__.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/amp/lists/tensor_overrides.py to tensor_overrides.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/amp/lists/torch_overrides.py to torch_overrides.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/amp/lists/functional_overrides.py to functional_overrides.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/amp/handle.py to handle.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/amp/__version__.py to __version__.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/amp/_amp_state.py to _amp_state.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/amp/opt.py to opt.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/amp/_initialize.py to _initialize.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/amp/rnn_compat.py to rnn_compat.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/amp/_process_optimizer.py to _process_optimizer.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/contrib/xentropy/__init__.py to __init__.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/contrib/xentropy/softmax_xentropy.py to softmax_xentropy.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/contrib/__init__.py to __init__.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/contrib/optimizers/fused_adam.py to fused_adam.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/contrib/optimizers/__init__.py to __init__.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/contrib/optimizers/fused_sgd.py to fused_sgd.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/contrib/optimizers/distributed_fused_lamb.py to distributed_fused_lamb.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/contrib/optimizers/fp16_optimizer.py to fp16_optimizer.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/contrib/optimizers/distributed_fused_adam_v3.py to distributed_fused_adam_v3.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/contrib/optimizers/distributed_fused_adam_v2.py to distributed_fused_adam_v2.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/contrib/optimizers/fused_lamb.py to fused_lamb.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/contrib/optimizers/distributed_fused_adam.py to distributed_fused_adam.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/contrib/transducer/__init__.py to __init__.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/contrib/transducer/transducer.py to transducer.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/contrib/layer_norm/__init__.py to __init__.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/contrib/layer_norm/layer_norm.py to layer_norm.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/contrib/multihead_attn/mask_softmax_dropout_func.py to mask_softmax_dropout_func.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/contrib/multihead_attn/__init__.py to __init__.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/contrib/multihead_attn/fast_encdec_multihead_attn_norm_add_func.py to fast_encdec_multihead_attn_norm_add_func.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/contrib/multihead_attn/fast_self_multihead_attn_func.py to fast_self_multihead_attn_func.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/contrib/multihead_attn/self_multihead_attn_func.py to self_multihead_attn_func.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/contrib/multihead_attn/fast_self_multihead_attn_norm_add_func.py to fast_self_multihead_attn_norm_add_func.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/contrib/multihead_attn/encdec_multihead_attn_func.py to encdec_multihead_attn_func.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/contrib/multihead_attn/fast_encdec_multihead_attn_func.py to fast_encdec_multihead_attn_func.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/contrib/multihead_attn/encdec_multihead_attn.py to encdec_multihead_attn.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/contrib/multihead_attn/self_multihead_attn.py to self_multihead_attn.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/contrib/groupbn/__init__.py to __init__.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/contrib/groupbn/batch_norm.py to batch_norm.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/contrib/fmha/__init__.py to __init__.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/contrib/fmha/fmha.py to fmha.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/contrib/sparsity/sparse_masklib.py to sparse_masklib.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/contrib/sparsity/__init__.py to __init__.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/contrib/sparsity/asp.py to asp.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/contrib/sparsity/permutation_search_kernels/__init__.py to __init__.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/contrib/sparsity/permutation_search_kernels/exhaustive_search.py to exhaustive_search.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/contrib/sparsity/permutation_search_kernels/permutation_utilities.py to permutation_utilities.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/contrib/sparsity/permutation_search_kernels/call_permutation_search_kernels.py to call_permutation_search_kernels.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/contrib/sparsity/permutation_lib.py to permutation_lib.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/contrib/bottleneck/__init__.py to __init__.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/contrib/bottleneck/bottleneck.py to bottleneck.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/contrib/bottleneck/bottleneck_module_test.py to bottleneck_module_test.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/contrib/bottleneck/test.py to test.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/multi_tensor_apply/__init__.py to __init__.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/multi_tensor_apply/multi_tensor_apply.py to multi_tensor_apply.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/reparameterization/__init__.py to __init__.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/reparameterization/weight_norm.py to weight_norm.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/reparameterization/reparameterization.py to reparameterization.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/fp16_utils/__init__.py to __init__.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/fp16_utils/fp16util.py to fp16util.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/fp16_utils/fp16_optimizer.py to fp16_optimizer.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/fp16_utils/loss_scaler.py to loss_scaler.cpython-37.pyc\n",
            "  byte-compiling /usr/local/lib/python3.7/dist-packages/apex/_autocast_utils.py to _autocast_utils.cpython-37.pyc\n",
            "  running install_egg_info\n",
            "  running egg_info\n",
            "  creating apex.egg-info\n",
            "  writing apex.egg-info/PKG-INFO\n",
            "  writing dependency_links to apex.egg-info/dependency_links.txt\n",
            "  writing top-level names to apex.egg-info/top_level.txt\n",
            "  writing manifest file 'apex.egg-info/SOURCES.txt'\n",
            "  adding license file 'LICENSE'\n",
            "  writing manifest file 'apex.egg-info/SOURCES.txt'\n",
            "  Copying apex.egg-info to /usr/local/lib/python3.7/dist-packages/apex-0.1-py3.7.egg-info\n",
            "  running install_scripts\n",
            "  writing list of installed files to '/tmp/pip-record-tg_ot5ii/install-record.txt'\n",
            "  Running setup.py install for apex ... \u001b[?25l\u001b[?25hdone\n",
            "Successfully installed apex-0.1\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oc-EidleBfeB"
      },
      "source": [
        "## Install PyCocoTools"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JwuWoBOxFV6v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e38be3be-8810-489b-e0b0-c71458c03139"
      },
      "source": [
        "!pip3 install cython; pip3 install 'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (0.29.28)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI\n",
            "  Cloning https://github.com/cocodataset/cocoapi.git to /tmp/pip-req-build-h88g3in_\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/cocodataset/cocoapi.git /tmp/pip-req-build-h88g3in_\n",
            "  Resolved https://github.com/cocodataset/cocoapi.git to commit 8c9bcc3cf640524c4c20a9c40e89cb6a2f2fa0e9\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: setuptools>=18.0 in /usr/local/lib/python3.7/dist-packages (from pycocotools==2.0) (57.4.0)\n",
            "Requirement already satisfied: cython>=0.27.3 in /usr/local/lib/python3.7/dist-packages (from pycocotools==2.0) (0.29.28)\n",
            "Requirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from pycocotools==2.0) (3.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (0.11.0)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (1.21.5)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (3.0.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (1.3.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib>=2.1.0->pycocotools==2.0) (1.15.0)\n",
            "Building wheels for collected packages: pycocotools\n",
            "  Building wheel for pycocotools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycocotools: filename=pycocotools-2.0-cp37-cp37m-linux_x86_64.whl size=264363 sha256=fac5774927f71d6515d900c1b01d71f9fe6a0a13a526b8f9395b59f42f036f12\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-9pyq294r/wheels/e2/6b/1d/344ac773c7495ea0b85eb228bc66daec7400a143a92d36b7b1\n",
            "Successfully built pycocotools\n",
            "Installing collected packages: pycocotools\n",
            "  Attempting uninstall: pycocotools\n",
            "    Found existing installation: pycocotools 2.0.4\n",
            "    Uninstalling pycocotools-2.0.4:\n",
            "      Successfully uninstalled pycocotools-2.0.4\n",
            "Successfully installed pycocotools-2.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UEdiT0rJBmRA"
      },
      "source": [
        "# Download your Data\n",
        "\n",
        "We'll download our dataset from Roboflow. Use the \"**Pascal VOC**\" export format.\n",
        "\n",
        "To get your data into Roboflow, follow the [Getting Started Guide](https://blog.roboflow.ai/getting-started-with-roboflow/).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJkU0eH-VgCn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f6b8c16-ea0c-4df8-e481-7807dcfd4dc9"
      },
      "source": [
        "#to get your roboflow code below please follow the link output by this cell\n",
        "!pip -q install roboflow\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(model_format=\"voc\", notebook=\"yolox\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.8/67.8 KB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.5/138.5 KB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m596.3/596.3 KB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m145.5/145.5 KB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.7/178.7 KB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m40.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 KB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.11.0 requires torch==1.10.0, but you have torch 1.8.0+cu111 which is incompatible.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.27.1 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mupload and label your dataset, and get an API KEY here: https://app.roboflow.com/?model=voc&ref=yolox\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gp1L8zdwGo_j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b272b1b7-7529-4c0c-d093-67d7ac5e1c43"
      },
      "source": [
        "%cd /content/\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"Quj44CovudhOOv2fXcs0\")\n",
        "project = rf.workspace().project(\"kvasir-seg-hrk5k\")\n",
        "dataset = project.version(\"1\").download(\"voc\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n",
            "Downloading Dataset Version Zip in Kvasir-SEG-1 to voc: 100% [49617130 / 49617130] bytes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting Dataset Version Zip to Kvasir-SEG-1 in voc:: 100%|██████████| 4805/4805 [00:05<00:00, 925.25it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dr4cOxxbVuHB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "365d855f-96bd-4b64-a47f-608845cabded"
      },
      "source": [
        "%cd YOLOX/\n",
        "!ln -s {dataset.location}/train/ ./datasets/VOCdevkit"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/YOLOX\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "agZSFjXLByrv"
      },
      "source": [
        "## Format Your Data Appropriately"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_xTRtDWrIw_D",
        "outputId": "261d4740-d2f4-4385-dbbd-03f58250e9b7"
      },
      "source": [
        "%mkdir \"/content/YOLOX/datasets/VOCdevkit/VOC2007\"\n",
        "!python3 voc_txt.py \"/content/YOLOX/datasets/VOCdevkit/\"\n",
        "%mkdir \"/content/YOLOX/datasets/VOCdevkit/VOC2012\"\n",
        "!cp -r \"/content/YOLOX/datasets/VOCdevkit/VOC2007/.\" \"/content/YOLOX/datasets/VOCdevkit/VOC2012\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train and val size: 1890\n",
            "train size: 1512\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BW8iyuMyB3bc"
      },
      "source": [
        "## Change the Classes\n",
        "Make sure you change the classes based on what your dataset. To ensure that the training process will function as intended, write the classes in lowercase with no whitespace."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rohuAE541Nug"
      },
      "source": [
        "from IPython.core.magic import register_line_cell_magic\n",
        "\n",
        "@register_line_cell_magic\n",
        "def writetemplate(line, cell):\n",
        "    with open(line, 'w') as f:\n",
        "        f.write(cell.format(**globals()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9h5PM8Ft1OjG"
      },
      "source": [
        "##REPLACE this cell with your classnames stripped of whitespace and lowercase\n",
        "%%writetemplate /content/YOLOX/yolox/data/datasets/voc_classes.py\n",
        "\n",
        "VOC_CLASSES = (\n",
        "  \"JSON\"\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lu6_LzErQRSU"
      },
      "source": [
        "##REPLACE this cell with your classnames stripped of whitespace and lowercase\n",
        "%%writetemplate /content/YOLOX/yolox/data/datasets/coco_classes.py\n",
        "\n",
        "COCO_CLASSES = (\n",
        "    \"JSON\"\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2uAaf5AKSE_E"
      },
      "source": [
        "Set the number of classes you have in your dataset in te `NUM_CLASSES` variable"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hxA0JmWqwU_M"
      },
      "source": [
        "NUM_CLASSES = 1\n",
        "!sed -i -e 's/self.num_classes = 20/self.num_classes = {NUM_CLASSES}/g' \"/content/YOLOX/exps/example/yolox_voc/yolox_voc_s.py\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eiYvw_GGKaro"
      },
      "source": [
        "# Download Pretrained Weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UsOCh9hRKbIw",
        "outputId": "e0bbd4e9-ee88-4001-a5e5-c50ad684ca43"
      },
      "source": [
        "%cd /content/\n",
        "!wget https://github.com/Megvii-BaseDetection/storage/releases/download/0.0.1/yolox_s.pth\n",
        "%cd /content/YOLOX/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "--2022-03-08 20:40:32--  https://github.com/Megvii-BaseDetection/storage/releases/download/0.0.1/yolox_s.pth\n",
            "Resolving github.com (github.com)... 140.82.112.3\n",
            "Connecting to github.com (github.com)|140.82.112.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/388351473/0b307dd4-bddb-4cfe-a863-1d19afb5598a?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20220308%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220308T204032Z&X-Amz-Expires=300&X-Amz-Signature=331c5df5fa642873de3795cf107e78b2525ebdb502dca5a30a5c60d5b156350b&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=388351473&response-content-disposition=attachment%3B%20filename%3Dyolox_s.pth&response-content-type=application%2Foctet-stream [following]\n",
            "--2022-03-08 20:40:32--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/388351473/0b307dd4-bddb-4cfe-a863-1d19afb5598a?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20220308%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220308T204032Z&X-Amz-Expires=300&X-Amz-Signature=331c5df5fa642873de3795cf107e78b2525ebdb502dca5a30a5c60d5b156350b&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=388351473&response-content-disposition=attachment%3B%20filename%3Dyolox_s.pth&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 72050245 (69M) [application/octet-stream]\n",
            "Saving to: ‘yolox_s.pth’\n",
            "\n",
            "yolox_s.pth         100%[===================>]  68.71M  90.7MB/s    in 0.8s    \n",
            "\n",
            "2022-03-08 20:40:33 (90.7 MB/s) - ‘yolox_s.pth’ saved [72050245/72050245]\n",
            "\n",
            "/content/YOLOX\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2TabCpJOCRti"
      },
      "source": [
        "# Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5h536amH32Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6a7242b-7e90-4a2f-eb1a-d476ea3744fd"
      },
      "source": [
        "!python tools/train.py -f exps/example/yolox_voc/yolox_voc_s.py -d 1 -b 16 --fp16 -o -c /content/yolox_s.pth"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "`fused_weight_gradient_mlp_cuda` module not found. gradient accumulation fusion with weight gradient computation disabled.\n",
            "\u001b[32m2022-03-08 20:41:02\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m125\u001b[0m - \u001b[1margs: Namespace(batch_size=16, ckpt='/content/yolox_s.pth', devices=1, dist_backend='nccl', dist_url=None, exp_file='exps/example/yolox_voc/yolox_voc_s.py', experiment_name='yolox_voc_s', fp16=True, local_rank=0, machine_rank=0, name=None, num_machines=1, occupy=True, opts=[], resume=False, start_epoch=None)\u001b[0m\n",
            "\u001b[32m2022-03-08 20:41:02\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m126\u001b[0m - \u001b[1mexp value:\n",
            "╒══════════════════╤════════════════════════════╕\n",
            "│ keys             │ values                     │\n",
            "╞══════════════════╪════════════════════════════╡\n",
            "│ seed             │ None                       │\n",
            "├──────────────────┼────────────────────────────┤\n",
            "│ output_dir       │ './YOLOX_outputs'          │\n",
            "├──────────────────┼────────────────────────────┤\n",
            "│ print_interval   │ 10                         │\n",
            "├──────────────────┼────────────────────────────┤\n",
            "│ eval_interval    │ 10                         │\n",
            "├──────────────────┼────────────────────────────┤\n",
            "│ num_classes      │ 1                          │\n",
            "├──────────────────┼────────────────────────────┤\n",
            "│ depth            │ 0.33                       │\n",
            "├──────────────────┼────────────────────────────┤\n",
            "│ width            │ 0.5                        │\n",
            "├──────────────────┼────────────────────────────┤\n",
            "│ data_num_workers │ 4                          │\n",
            "├──────────────────┼────────────────────────────┤\n",
            "│ input_size       │ (640, 640)                 │\n",
            "├──────────────────┼────────────────────────────┤\n",
            "│ random_size      │ (14, 26)                   │\n",
            "├──────────────────┼────────────────────────────┤\n",
            "│ train_ann        │ 'instances_train2017.json' │\n",
            "├──────────────────┼────────────────────────────┤\n",
            "│ val_ann          │ 'instances_val2017.json'   │\n",
            "├──────────────────┼────────────────────────────┤\n",
            "│ degrees          │ 10.0                       │\n",
            "├──────────────────┼────────────────────────────┤\n",
            "│ translate        │ 0.1                        │\n",
            "├──────────────────┼────────────────────────────┤\n",
            "│ scale            │ (0.1, 2)                   │\n",
            "├──────────────────┼────────────────────────────┤\n",
            "│ mscale           │ (0.8, 1.6)                 │\n",
            "├──────────────────┼────────────────────────────┤\n",
            "│ shear            │ 2.0                        │\n",
            "├──────────────────┼────────────────────────────┤\n",
            "│ perspective      │ 0.0                        │\n",
            "├──────────────────┼────────────────────────────┤\n",
            "│ enable_mixup     │ True                       │\n",
            "├──────────────────┼────────────────────────────┤\n",
            "│ warmup_epochs    │ 5                          │\n",
            "├──────────────────┼────────────────────────────┤\n",
            "│ max_epoch        │ 300                        │\n",
            "├──────────────────┼────────────────────────────┤\n",
            "│ warmup_lr        │ 0                          │\n",
            "├──────────────────┼────────────────────────────┤\n",
            "│ basic_lr_per_img │ 0.00015625                 │\n",
            "├──────────────────┼────────────────────────────┤\n",
            "│ scheduler        │ 'yoloxwarmcos'             │\n",
            "├──────────────────┼────────────────────────────┤\n",
            "│ no_aug_epochs    │ 15                         │\n",
            "├──────────────────┼────────────────────────────┤\n",
            "│ min_lr_ratio     │ 0.05                       │\n",
            "├──────────────────┼────────────────────────────┤\n",
            "│ ema              │ True                       │\n",
            "├──────────────────┼────────────────────────────┤\n",
            "│ weight_decay     │ 0.0005                     │\n",
            "├──────────────────┼────────────────────────────┤\n",
            "│ momentum         │ 0.9                        │\n",
            "├──────────────────┼────────────────────────────┤\n",
            "│ exp_name         │ 'yolox_voc_s'              │\n",
            "├──────────────────┼────────────────────────────┤\n",
            "│ test_size        │ (640, 640)                 │\n",
            "├──────────────────┼────────────────────────────┤\n",
            "│ test_conf        │ 0.01                       │\n",
            "├──────────────────┼────────────────────────────┤\n",
            "│ nmsthre          │ 0.65                       │\n",
            "╘══════════════════╧════════════════════════════╛\u001b[0m\n",
            "\u001b[32m2022-03-08 20:41:02\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m132\u001b[0m - \u001b[1mModel Summary: Params: 8.94M, Gflops: 26.64\u001b[0m\n",
            "\u001b[32m2022-03-08 20:41:07\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mapex.amp.frontend\u001b[0m:\u001b[36m328\u001b[0m - \u001b[1mSelected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.\u001b[0m\n",
            "\u001b[32m2022-03-08 20:41:07\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mapex.amp.frontend\u001b[0m:\u001b[36m329\u001b[0m - \u001b[1mDefaults for this optimization level are:\u001b[0m\n",
            "\u001b[32m2022-03-08 20:41:07\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mapex.amp.frontend\u001b[0m:\u001b[36m331\u001b[0m - \u001b[1menabled                : True\u001b[0m\n",
            "\u001b[32m2022-03-08 20:41:07\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mapex.amp.frontend\u001b[0m:\u001b[36m331\u001b[0m - \u001b[1mopt_level              : O1\u001b[0m\n",
            "\u001b[32m2022-03-08 20:41:07\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mapex.amp.frontend\u001b[0m:\u001b[36m331\u001b[0m - \u001b[1mcast_model_type        : None\u001b[0m\n",
            "\u001b[32m2022-03-08 20:41:07\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mapex.amp.frontend\u001b[0m:\u001b[36m331\u001b[0m - \u001b[1mpatch_torch_functions  : True\u001b[0m\n",
            "\u001b[32m2022-03-08 20:41:07\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mapex.amp.frontend\u001b[0m:\u001b[36m331\u001b[0m - \u001b[1mkeep_batchnorm_fp32    : None\u001b[0m\n",
            "\u001b[32m2022-03-08 20:41:07\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mapex.amp.frontend\u001b[0m:\u001b[36m331\u001b[0m - \u001b[1mmaster_weights         : None\u001b[0m\n",
            "\u001b[32m2022-03-08 20:41:07\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mapex.amp.frontend\u001b[0m:\u001b[36m331\u001b[0m - \u001b[1mloss_scale             : dynamic\u001b[0m\n",
            "\u001b[32m2022-03-08 20:41:07\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mapex.amp.frontend\u001b[0m:\u001b[36m336\u001b[0m - \u001b[1mProcessing user overrides (additional kwargs that are not None)...\u001b[0m\n",
            "\u001b[32m2022-03-08 20:41:07\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mapex.amp.frontend\u001b[0m:\u001b[36m354\u001b[0m - \u001b[1mAfter processing overrides, optimization options are:\u001b[0m\n",
            "\u001b[32m2022-03-08 20:41:07\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mapex.amp.frontend\u001b[0m:\u001b[36m356\u001b[0m - \u001b[1menabled                : True\u001b[0m\n",
            "\u001b[32m2022-03-08 20:41:07\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mapex.amp.frontend\u001b[0m:\u001b[36m356\u001b[0m - \u001b[1mopt_level              : O1\u001b[0m\n",
            "\u001b[32m2022-03-08 20:41:07\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mapex.amp.frontend\u001b[0m:\u001b[36m356\u001b[0m - \u001b[1mcast_model_type        : None\u001b[0m\n",
            "\u001b[32m2022-03-08 20:41:07\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mapex.amp.frontend\u001b[0m:\u001b[36m356\u001b[0m - \u001b[1mpatch_torch_functions  : True\u001b[0m\n",
            "\u001b[32m2022-03-08 20:41:07\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mapex.amp.frontend\u001b[0m:\u001b[36m356\u001b[0m - \u001b[1mkeep_batchnorm_fp32    : None\u001b[0m\n",
            "\u001b[32m2022-03-08 20:41:07\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mapex.amp.frontend\u001b[0m:\u001b[36m356\u001b[0m - \u001b[1mmaster_weights         : None\u001b[0m\n",
            "\u001b[32m2022-03-08 20:41:07\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mapex.amp.frontend\u001b[0m:\u001b[36m356\u001b[0m - \u001b[1mloss_scale             : dynamic\u001b[0m\n",
            "\u001b[32m2022-03-08 20:41:07\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m297\u001b[0m - \u001b[1mloading checkpoint for fine tuning\u001b[0m\n",
            "\u001b[32m2022-03-08 20:41:07\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36myolox.utils.checkpoint\u001b[0m:\u001b[36m27\u001b[0m - \u001b[33m\u001b[1mShape of head.cls_preds.0.weight in checkpoint is torch.Size([80, 128, 1, 1]), while shape of head.cls_preds.0.weight in model is torch.Size([1, 128, 1, 1]).\u001b[0m\n",
            "\u001b[32m2022-03-08 20:41:07\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36myolox.utils.checkpoint\u001b[0m:\u001b[36m27\u001b[0m - \u001b[33m\u001b[1mShape of head.cls_preds.0.bias in checkpoint is torch.Size([80]), while shape of head.cls_preds.0.bias in model is torch.Size([1]).\u001b[0m\n",
            "\u001b[32m2022-03-08 20:41:07\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36myolox.utils.checkpoint\u001b[0m:\u001b[36m27\u001b[0m - \u001b[33m\u001b[1mShape of head.cls_preds.1.weight in checkpoint is torch.Size([80, 128, 1, 1]), while shape of head.cls_preds.1.weight in model is torch.Size([1, 128, 1, 1]).\u001b[0m\n",
            "\u001b[32m2022-03-08 20:41:07\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36myolox.utils.checkpoint\u001b[0m:\u001b[36m27\u001b[0m - \u001b[33m\u001b[1mShape of head.cls_preds.1.bias in checkpoint is torch.Size([80]), while shape of head.cls_preds.1.bias in model is torch.Size([1]).\u001b[0m\n",
            "\u001b[32m2022-03-08 20:41:07\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36myolox.utils.checkpoint\u001b[0m:\u001b[36m27\u001b[0m - \u001b[33m\u001b[1mShape of head.cls_preds.2.weight in checkpoint is torch.Size([80, 128, 1, 1]), while shape of head.cls_preds.2.weight in model is torch.Size([1, 128, 1, 1]).\u001b[0m\n",
            "\u001b[32m2022-03-08 20:41:07\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36myolox.utils.checkpoint\u001b[0m:\u001b[36m27\u001b[0m - \u001b[33m\u001b[1mShape of head.cls_preds.2.bias in checkpoint is torch.Size([80]), while shape of head.cls_preds.2.bias in model is torch.Size([1]).\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\u001b[32m2022-03-08 20:41:07\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m152\u001b[0m - \u001b[1minit prefetcher, this might take one minute or less...\u001b[0m\n",
            "\u001b[32m2022-03-08 20:41:08\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36myolox.core.launch\u001b[0m:\u001b[36m90\u001b[0m - \u001b[31m\u001b[1mAn error has been caught in function 'launch', process 'MainProcess' (1151), thread 'MainThread' (139799330588544):\u001b[0m\n",
            "\u001b[33m\u001b[1mTraceback (most recent call last):\u001b[0m\n",
            "\n",
            "  File \"\u001b[32mtools/\u001b[0m\u001b[32m\u001b[1mtrain.py\u001b[0m\", line \u001b[33m125\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
            "    \u001b[1margs\u001b[0m\u001b[35m\u001b[1m=\u001b[0m\u001b[1m(\u001b[0m\u001b[1mexp\u001b[0m\u001b[1m,\u001b[0m \u001b[1margs\u001b[0m\u001b[1m)\u001b[0m\u001b[1m,\u001b[0m\n",
            "    \u001b[36m      │    └ \u001b[0m\u001b[36m\u001b[1mNamespace(batch_size=16, ckpt='/content/yolox_s.pth', devices=1, dist_backend='nccl', dist_url=None, exp_file='exps/example/y...\u001b[0m\n",
            "    \u001b[36m      └ \u001b[0m\u001b[36m\u001b[1m╒══════════════════╤═════════════════════════════════════════════════════════════════════════════════════════════════════════...\u001b[0m\n",
            "\n",
            "> File \"\u001b[32m/content/YOLOX/yolox/core/\u001b[0m\u001b[32m\u001b[1mlaunch.py\u001b[0m\", line \u001b[33m90\u001b[0m, in \u001b[35mlaunch\u001b[0m\n",
            "    \u001b[1mmain_func\u001b[0m\u001b[1m(\u001b[0m\u001b[35m\u001b[1m*\u001b[0m\u001b[1margs\u001b[0m\u001b[1m)\u001b[0m\n",
            "    \u001b[36m│          └ \u001b[0m\u001b[36m\u001b[1m(╒══════════════════╤════════════════════════════════════════════════════════════════════════════════════════════════════════...\u001b[0m\n",
            "    \u001b[36m└ \u001b[0m\u001b[36m\u001b[1m<function main at 0x7f258f447170>\u001b[0m\n",
            "\n",
            "  File \"\u001b[32mtools/\u001b[0m\u001b[32m\u001b[1mtrain.py\u001b[0m\", line \u001b[33m104\u001b[0m, in \u001b[35mmain\u001b[0m\n",
            "    \u001b[1mtrainer\u001b[0m\u001b[35m\u001b[1m.\u001b[0m\u001b[1mtrain\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
            "    \u001b[36m│       └ \u001b[0m\u001b[36m\u001b[1m<function Trainer.train at 0x7f248e60ac20>\u001b[0m\n",
            "    \u001b[36m└ \u001b[0m\u001b[36m\u001b[1m<yolox.core.trainer.Trainer object at 0x7f24888a5d10>\u001b[0m\n",
            "\n",
            "  File \"\u001b[32m/content/YOLOX/yolox/core/\u001b[0m\u001b[32m\u001b[1mtrainer.py\u001b[0m\", line \u001b[33m69\u001b[0m, in \u001b[35mtrain\u001b[0m\n",
            "    \u001b[1mself\u001b[0m\u001b[35m\u001b[1m.\u001b[0m\u001b[1mbefore_train\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
            "    \u001b[36m│    └ \u001b[0m\u001b[36m\u001b[1m<function Trainer.before_train at 0x7f2488d75710>\u001b[0m\n",
            "    \u001b[36m└ \u001b[0m\u001b[36m\u001b[1m<yolox.core.trainer.Trainer object at 0x7f24888a5d10>\u001b[0m\n",
            "\n",
            "  File \"\u001b[32m/content/YOLOX/yolox/core/\u001b[0m\u001b[32m\u001b[1mtrainer.py\u001b[0m\", line \u001b[33m153\u001b[0m, in \u001b[35mbefore_train\u001b[0m\n",
            "    \u001b[1mself\u001b[0m\u001b[35m\u001b[1m.\u001b[0m\u001b[1mprefetcher\u001b[0m \u001b[35m\u001b[1m=\u001b[0m \u001b[1mDataPrefetcher\u001b[0m\u001b[1m(\u001b[0m\u001b[1mself\u001b[0m\u001b[35m\u001b[1m.\u001b[0m\u001b[1mtrain_loader\u001b[0m\u001b[1m)\u001b[0m\n",
            "    \u001b[36m│                 │              │    └ \u001b[0m\u001b[36m\u001b[1m<yolox.data.dataloading.DataLoader object at 0x7f2485eb9510>\u001b[0m\n",
            "    \u001b[36m│                 │              └ \u001b[0m\u001b[36m\u001b[1m<yolox.core.trainer.Trainer object at 0x7f24888a5d10>\u001b[0m\n",
            "    \u001b[36m│                 └ \u001b[0m\u001b[36m\u001b[1m<class 'yolox.data.data_prefetcher.DataPrefetcher'>\u001b[0m\n",
            "    \u001b[36m└ \u001b[0m\u001b[36m\u001b[1m<yolox.core.trainer.Trainer object at 0x7f24888a5d10>\u001b[0m\n",
            "\n",
            "  File \"\u001b[32m/content/YOLOX/yolox/data/\u001b[0m\u001b[32m\u001b[1mdata_prefetcher.py\u001b[0m\", line \u001b[33m26\u001b[0m, in \u001b[35m__init__\u001b[0m\n",
            "    \u001b[1mself\u001b[0m\u001b[35m\u001b[1m.\u001b[0m\u001b[1mpreload\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
            "    \u001b[36m│    └ \u001b[0m\u001b[36m\u001b[1m<function DataPrefetcher.preload at 0x7f248cf39440>\u001b[0m\n",
            "    \u001b[36m└ \u001b[0m\u001b[36m\u001b[1m<yolox.data.data_prefetcher.DataPrefetcher object at 0x7f2485eb9690>\u001b[0m\n",
            "\n",
            "  File \"\u001b[32m/content/YOLOX/yolox/data/\u001b[0m\u001b[32m\u001b[1mdata_prefetcher.py\u001b[0m\", line \u001b[33m30\u001b[0m, in \u001b[35mpreload\u001b[0m\n",
            "    \u001b[1mself\u001b[0m\u001b[35m\u001b[1m.\u001b[0m\u001b[1mnext_input\u001b[0m\u001b[1m,\u001b[0m \u001b[1mself\u001b[0m\u001b[35m\u001b[1m.\u001b[0m\u001b[1mnext_target\u001b[0m\u001b[1m,\u001b[0m \u001b[1m_\u001b[0m\u001b[1m,\u001b[0m \u001b[1m_\u001b[0m \u001b[35m\u001b[1m=\u001b[0m \u001b[1mnext\u001b[0m\u001b[1m(\u001b[0m\u001b[1mself\u001b[0m\u001b[35m\u001b[1m.\u001b[0m\u001b[1mloader\u001b[0m\u001b[1m)\u001b[0m\n",
            "    \u001b[36m│                │                             │    └ \u001b[0m\u001b[36m\u001b[1m<torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f2485eb9b10>\u001b[0m\n",
            "    \u001b[36m│                │                             └ \u001b[0m\u001b[36m\u001b[1m<yolox.data.data_prefetcher.DataPrefetcher object at 0x7f2485eb9690>\u001b[0m\n",
            "    \u001b[36m│                └ \u001b[0m\u001b[36m\u001b[1m<yolox.data.data_prefetcher.DataPrefetcher object at 0x7f2485eb9690>\u001b[0m\n",
            "    \u001b[36m└ \u001b[0m\u001b[36m\u001b[1m<yolox.data.data_prefetcher.DataPrefetcher object at 0x7f2485eb9690>\u001b[0m\n",
            "\n",
            "  File \"\u001b[32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/\u001b[0m\u001b[32m\u001b[1mdataloader.py\u001b[0m\", line \u001b[33m517\u001b[0m, in \u001b[35m__next__\u001b[0m\n",
            "    \u001b[1mdata\u001b[0m \u001b[35m\u001b[1m=\u001b[0m \u001b[1mself\u001b[0m\u001b[35m\u001b[1m.\u001b[0m\u001b[1m_next_data\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
            "    \u001b[36m       │    └ \u001b[0m\u001b[36m\u001b[1m<function _MultiProcessingDataLoaderIter._next_data at 0x7f249a47c3b0>\u001b[0m\n",
            "    \u001b[36m       └ \u001b[0m\u001b[36m\u001b[1m<torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f2485eb9b10>\u001b[0m\n",
            "\n",
            "  File \"\u001b[32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/\u001b[0m\u001b[32m\u001b[1mdataloader.py\u001b[0m\", line \u001b[33m1199\u001b[0m, in \u001b[35m_next_data\u001b[0m\n",
            "    \u001b[35m\u001b[1mreturn\u001b[0m \u001b[1mself\u001b[0m\u001b[35m\u001b[1m.\u001b[0m\u001b[1m_process_data\u001b[0m\u001b[1m(\u001b[0m\u001b[1mdata\u001b[0m\u001b[1m)\u001b[0m\n",
            "    \u001b[36m       │    │             └ \u001b[0m\u001b[36m\u001b[1m<torch._utils.ExceptionWrapper object at 0x7f2485f23990>\u001b[0m\n",
            "    \u001b[36m       │    └ \u001b[0m\u001b[36m\u001b[1m<function _MultiProcessingDataLoaderIter._process_data at 0x7f249a47c4d0>\u001b[0m\n",
            "    \u001b[36m       └ \u001b[0m\u001b[36m\u001b[1m<torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f2485eb9b10>\u001b[0m\n",
            "\n",
            "  File \"\u001b[32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/\u001b[0m\u001b[32m\u001b[1mdataloader.py\u001b[0m\", line \u001b[33m1225\u001b[0m, in \u001b[35m_process_data\u001b[0m\n",
            "    \u001b[1mdata\u001b[0m\u001b[35m\u001b[1m.\u001b[0m\u001b[1mreraise\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
            "    \u001b[36m│    └ \u001b[0m\u001b[36m\u001b[1m<function ExceptionWrapper.reraise at 0x7f258cdfd3b0>\u001b[0m\n",
            "    \u001b[36m└ \u001b[0m\u001b[36m\u001b[1m<torch._utils.ExceptionWrapper object at 0x7f2485f23990>\u001b[0m\n",
            "\n",
            "  File \"\u001b[32m/usr/local/lib/python3.7/dist-packages/torch/\u001b[0m\u001b[32m\u001b[1m_utils.py\u001b[0m\", line \u001b[33m429\u001b[0m, in \u001b[35mreraise\u001b[0m\n",
            "    \u001b[35m\u001b[1mraise\u001b[0m \u001b[1mself\u001b[0m\u001b[35m\u001b[1m.\u001b[0m\u001b[1mexc_type\u001b[0m\u001b[1m(\u001b[0m\u001b[1mmsg\u001b[0m\u001b[1m)\u001b[0m\n",
            "    \u001b[36m      │    │        └ \u001b[0m\u001b[36m\u001b[1mCaught KeyError in DataLoader worker process 0.\u001b[0m\n",
            "    \u001b[36m      │    │          \u001b[0m\u001b[36m\u001b[1mOriginal Traceback (most recent call last):\u001b[0m\n",
            "    \u001b[36m      │    │          \u001b[0m\u001b[36m\u001b[1m  File \"/usr/local/lib/python3.7/...\u001b[0m\n",
            "    \u001b[36m      │    └ \u001b[0m\u001b[36m\u001b[1m<class 'KeyError'>\u001b[0m\n",
            "    \u001b[36m      └ \u001b[0m\u001b[36m\u001b[1m<torch._utils.ExceptionWrapper object at 0x7f2485f23990>\u001b[0m\n",
            "\n",
            "\u001b[31m\u001b[1mKeyError\u001b[0m:\u001b[1m Caught KeyError in DataLoader worker process 0.\n",
            "Original Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/worker.py\", line 202, in _worker_loop\n",
            "    data = fetcher.fetch(index)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\", line 44, in fetch\n",
            "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\", line 44, in <listcomp>\n",
            "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
            "  File \"/content/YOLOX/yolox/data/datasets/datasets_wrapper.py\", line 121, in wrapper\n",
            "    ret_val = getitem_fn(self, index)\n",
            "  File \"/content/YOLOX/yolox/data/datasets/mosaicdetection.py\", line 91, in __getitem__\n",
            "    img, _labels, _, _ = self._dataset.pull_item(index)\n",
            "  File \"/content/YOLOX/yolox/data/datasets/voc.py\", line 145, in pull_item\n",
            "    target = self.load_anno(index)\n",
            "  File \"/content/YOLOX/yolox/data/datasets/voc.py\", line 126, in load_anno\n",
            "    target = self.target_transform(target)\n",
            "  File \"/content/YOLOX/yolox/data/datasets/voc.py\", line 64, in __call__\n",
            "    label_idx = self.class_to_ind[name]\n",
            "KeyError: 'json'\n",
            "\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8UjsuFDICVov"
      },
      "source": [
        "# Evaluate the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sE5oWuEOICAF",
        "outputId": "8c96188b-93cb-4eea-ba59-9abb1640ecc3"
      },
      "source": [
        "MODEL_PATH = \"/content/YOLOX/YOLOX_outputs/yolox_voc_s/latest_ckpt.pth.tar\"\n",
        "!python3 tools/eval.py -n  yolox-s -c {MODEL_PATH} -b 64 -d 1 --conf 0.001 -f exps/example/yolox_voc/yolox_voc_s.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m2022-02-21 14:52:17\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m129\u001b[0m - \u001b[1mArgs: Namespace(batch_size=64, ckpt='/content/YOLOX/YOLOX_outputs/yolox_voc_s/latest_ckpt.pth.tar', conf=0.001, devices=1, dist_backend='nccl', dist_url=None, exp_file='exps/example/yolox_voc/yolox_voc_s.py', experiment_name='yolox_voc_s', fp16=False, fuse=False, local_rank=0, machine_rank=0, name='yolox-s', nms=None, num_machines=1, opts=[], seed=None, speed=False, test=False, trt=False, tsize=None)\u001b[0m\n",
            "\u001b[32m2022-02-21 14:52:18\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m139\u001b[0m - \u001b[1mModel Summary: Params: 8.94M, Gflops: 26.64\u001b[0m\n",
            "\u001b[32m2022-02-21 14:52:18\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m140\u001b[0m - \u001b[1mModel Structure:\n",
            "YOLOX(\n",
            "  (backbone): YOLOPAFPN(\n",
            "    (backbone): CSPDarknet(\n",
            "      (stem): Focus(\n",
            "        (conv): BaseConv(\n",
            "          (conv): Conv2d(12, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "      (dark2): Sequential(\n",
            "        (0): BaseConv(\n",
            "          (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (1): CSPLayer(\n",
            "          (conv1): BaseConv(\n",
            "            (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (conv2): BaseConv(\n",
            "            (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (conv3): BaseConv(\n",
            "            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (m): Sequential(\n",
            "            (0): Bottleneck(\n",
            "              (conv1): BaseConv(\n",
            "                (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "                (act): SiLU(inplace=True)\n",
            "              )\n",
            "              (conv2): BaseConv(\n",
            "                (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "                (act): SiLU(inplace=True)\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (dark3): Sequential(\n",
            "        (0): BaseConv(\n",
            "          (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (1): CSPLayer(\n",
            "          (conv1): BaseConv(\n",
            "            (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (conv2): BaseConv(\n",
            "            (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (conv3): BaseConv(\n",
            "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (m): Sequential(\n",
            "            (0): Bottleneck(\n",
            "              (conv1): BaseConv(\n",
            "                (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "                (act): SiLU(inplace=True)\n",
            "              )\n",
            "              (conv2): BaseConv(\n",
            "                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "                (act): SiLU(inplace=True)\n",
            "              )\n",
            "            )\n",
            "            (1): Bottleneck(\n",
            "              (conv1): BaseConv(\n",
            "                (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "                (act): SiLU(inplace=True)\n",
            "              )\n",
            "              (conv2): BaseConv(\n",
            "                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "                (act): SiLU(inplace=True)\n",
            "              )\n",
            "            )\n",
            "            (2): Bottleneck(\n",
            "              (conv1): BaseConv(\n",
            "                (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "                (act): SiLU(inplace=True)\n",
            "              )\n",
            "              (conv2): BaseConv(\n",
            "                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "                (act): SiLU(inplace=True)\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (dark4): Sequential(\n",
            "        (0): BaseConv(\n",
            "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (1): CSPLayer(\n",
            "          (conv1): BaseConv(\n",
            "            (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (conv2): BaseConv(\n",
            "            (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (conv3): BaseConv(\n",
            "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (m): Sequential(\n",
            "            (0): Bottleneck(\n",
            "              (conv1): BaseConv(\n",
            "                (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "                (act): SiLU(inplace=True)\n",
            "              )\n",
            "              (conv2): BaseConv(\n",
            "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "                (act): SiLU(inplace=True)\n",
            "              )\n",
            "            )\n",
            "            (1): Bottleneck(\n",
            "              (conv1): BaseConv(\n",
            "                (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "                (act): SiLU(inplace=True)\n",
            "              )\n",
            "              (conv2): BaseConv(\n",
            "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "                (act): SiLU(inplace=True)\n",
            "              )\n",
            "            )\n",
            "            (2): Bottleneck(\n",
            "              (conv1): BaseConv(\n",
            "                (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "                (act): SiLU(inplace=True)\n",
            "              )\n",
            "              (conv2): BaseConv(\n",
            "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "                (act): SiLU(inplace=True)\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (dark5): Sequential(\n",
            "        (0): BaseConv(\n",
            "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (1): SPPBottleneck(\n",
            "          (conv1): BaseConv(\n",
            "            (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (m): ModuleList(\n",
            "            (0): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n",
            "            (1): MaxPool2d(kernel_size=9, stride=1, padding=4, dilation=1, ceil_mode=False)\n",
            "            (2): MaxPool2d(kernel_size=13, stride=1, padding=6, dilation=1, ceil_mode=False)\n",
            "          )\n",
            "          (conv2): BaseConv(\n",
            "            (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "        (2): CSPLayer(\n",
            "          (conv1): BaseConv(\n",
            "            (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (conv2): BaseConv(\n",
            "            (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (conv3): BaseConv(\n",
            "            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (m): Sequential(\n",
            "            (0): Bottleneck(\n",
            "              (conv1): BaseConv(\n",
            "                (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "                (act): SiLU(inplace=True)\n",
            "              )\n",
            "              (conv2): BaseConv(\n",
            "                (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "                (act): SiLU(inplace=True)\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (upsample): Upsample(scale_factor=2.0, mode=nearest)\n",
            "    (lateral_conv0): BaseConv(\n",
            "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      (act): SiLU(inplace=True)\n",
            "    )\n",
            "    (C3_p4): CSPLayer(\n",
            "      (conv1): BaseConv(\n",
            "        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (conv2): BaseConv(\n",
            "        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (conv3): BaseConv(\n",
            "        (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (m): Sequential(\n",
            "        (0): Bottleneck(\n",
            "          (conv1): BaseConv(\n",
            "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (conv2): BaseConv(\n",
            "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (reduce_conv1): BaseConv(\n",
            "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      (act): SiLU(inplace=True)\n",
            "    )\n",
            "    (C3_p3): CSPLayer(\n",
            "      (conv1): BaseConv(\n",
            "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (conv2): BaseConv(\n",
            "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (conv3): BaseConv(\n",
            "        (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (m): Sequential(\n",
            "        (0): Bottleneck(\n",
            "          (conv1): BaseConv(\n",
            "            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (conv2): BaseConv(\n",
            "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (bu_conv2): BaseConv(\n",
            "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      (act): SiLU(inplace=True)\n",
            "    )\n",
            "    (C3_n3): CSPLayer(\n",
            "      (conv1): BaseConv(\n",
            "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (conv2): BaseConv(\n",
            "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (conv3): BaseConv(\n",
            "        (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (m): Sequential(\n",
            "        (0): Bottleneck(\n",
            "          (conv1): BaseConv(\n",
            "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (conv2): BaseConv(\n",
            "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (bu_conv1): BaseConv(\n",
            "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      (act): SiLU(inplace=True)\n",
            "    )\n",
            "    (C3_n4): CSPLayer(\n",
            "      (conv1): BaseConv(\n",
            "        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (conv2): BaseConv(\n",
            "        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (conv3): BaseConv(\n",
            "        (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (m): Sequential(\n",
            "        (0): Bottleneck(\n",
            "          (conv1): BaseConv(\n",
            "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (conv2): BaseConv(\n",
            "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (head): YOLOXHead(\n",
            "    (cls_convs): ModuleList(\n",
            "      (0): Sequential(\n",
            "        (0): BaseConv(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (1): BaseConv(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Sequential(\n",
            "        (0): BaseConv(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (1): BaseConv(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "      (2): Sequential(\n",
            "        (0): BaseConv(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (1): BaseConv(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (reg_convs): ModuleList(\n",
            "      (0): Sequential(\n",
            "        (0): BaseConv(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (1): BaseConv(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Sequential(\n",
            "        (0): BaseConv(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (1): BaseConv(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "      (2): Sequential(\n",
            "        (0): BaseConv(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (1): BaseConv(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (cls_preds): ModuleList(\n",
            "      (0): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (1): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (2): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "    (reg_preds): ModuleList(\n",
            "      (0): Conv2d(128, 4, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (1): Conv2d(128, 4, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (2): Conv2d(128, 4, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "    (obj_preds): ModuleList(\n",
            "      (0): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (1): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (2): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "    (stems): ModuleList(\n",
            "      (0): BaseConv(\n",
            "        (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (1): BaseConv(\n",
            "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (2): BaseConv(\n",
            "        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (l1_loss): L1Loss()\n",
            "    (bcewithlog_loss): BCEWithLogitsLoss()\n",
            "    (iou_loss): IOUloss()\n",
            "  )\n",
            ")\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\u001b[32m2022-02-21 14:52:20\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mloading checkpoint\u001b[0m\n",
            "\u001b[32m2022-02-21 14:52:20\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36myolox.core.launch\u001b[0m:\u001b[36m90\u001b[0m - \u001b[31m\u001b[1mAn error has been caught in function 'launch', process 'MainProcess' (1178), thread 'MainThread' (139915029833600):\u001b[0m\n",
            "\u001b[33m\u001b[1mTraceback (most recent call last):\u001b[0m\n",
            "\n",
            "  File \"\u001b[32mtools/\u001b[0m\u001b[32m\u001b[1meval.py\u001b[0m\", line \u001b[33m206\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
            "    \u001b[1margs\u001b[0m\u001b[35m\u001b[1m=\u001b[0m\u001b[1m(\u001b[0m\u001b[1mexp\u001b[0m\u001b[1m,\u001b[0m \u001b[1margs\u001b[0m\u001b[1m,\u001b[0m \u001b[1mnum_gpu\u001b[0m\u001b[1m)\u001b[0m\u001b[1m,\u001b[0m\n",
            "    \u001b[36m      │    │     └ \u001b[0m\u001b[36m\u001b[1m1\u001b[0m\n",
            "    \u001b[36m      │    └ \u001b[0m\u001b[36m\u001b[1mNamespace(batch_size=64, ckpt='/content/YOLOX/YOLOX_outputs/yolox_voc_s/latest_ckpt.pth.tar', conf=0.001, devices=1, dist_bac...\u001b[0m\n",
            "    \u001b[36m      └ \u001b[0m\u001b[36m\u001b[1m╒══════════════════╤═════════════════════════════════════════════════════════════════════════════════════════════════════════...\u001b[0m\n",
            "\n",
            "> File \"\u001b[32m/content/YOLOX/yolox/core/\u001b[0m\u001b[32m\u001b[1mlaunch.py\u001b[0m\", line \u001b[33m90\u001b[0m, in \u001b[35mlaunch\u001b[0m\n",
            "    \u001b[1mmain_func\u001b[0m\u001b[1m(\u001b[0m\u001b[35m\u001b[1m*\u001b[0m\u001b[1margs\u001b[0m\u001b[1m)\u001b[0m\n",
            "    \u001b[36m│          └ \u001b[0m\u001b[36m\u001b[1m(╒══════════════════╤════════════════════════════════════════════════════════════════════════════════════════════════════════...\u001b[0m\n",
            "    \u001b[36m└ \u001b[0m\u001b[36m\u001b[1m<function main at 0x7f407d80fdd0>\u001b[0m\n",
            "\n",
            "  File \"\u001b[32mtools/\u001b[0m\u001b[32m\u001b[1meval.py\u001b[0m\", line \u001b[33m155\u001b[0m, in \u001b[35mmain\u001b[0m\n",
            "    \u001b[1mckpt\u001b[0m \u001b[35m\u001b[1m=\u001b[0m \u001b[1mtorch\u001b[0m\u001b[35m\u001b[1m.\u001b[0m\u001b[1mload\u001b[0m\u001b[1m(\u001b[0m\u001b[1mckpt_file\u001b[0m\u001b[1m,\u001b[0m \u001b[1mmap_location\u001b[0m\u001b[35m\u001b[1m=\u001b[0m\u001b[1mloc\u001b[0m\u001b[1m)\u001b[0m\n",
            "    \u001b[36m       │     │    │                       └ \u001b[0m\u001b[36m\u001b[1m'cuda:0'\u001b[0m\n",
            "    \u001b[36m       │     │    └ \u001b[0m\u001b[36m\u001b[1m'/content/YOLOX/YOLOX_outputs/yolox_voc_s/latest_ckpt.pth.tar'\u001b[0m\n",
            "    \u001b[36m       │     └ \u001b[0m\u001b[36m\u001b[1m<function load at 0x7f3f8b1f5a70>\u001b[0m\n",
            "    \u001b[36m       └ \u001b[0m\u001b[36m\u001b[1m<module 'torch' from '/usr/local/lib/python3.7/dist-packages/torch/__init__.py'>\u001b[0m\n",
            "\n",
            "  File \"\u001b[32m/usr/local/lib/python3.7/dist-packages/torch/\u001b[0m\u001b[32m\u001b[1mserialization.py\u001b[0m\", line \u001b[33m579\u001b[0m, in \u001b[35mload\u001b[0m\n",
            "    \u001b[35m\u001b[1mwith\u001b[0m \u001b[1m_open_file_like\u001b[0m\u001b[1m(\u001b[0m\u001b[1mf\u001b[0m\u001b[1m,\u001b[0m \u001b[36m'rb'\u001b[0m\u001b[1m)\u001b[0m \u001b[35m\u001b[1mas\u001b[0m \u001b[1mopened_file\u001b[0m\u001b[1m:\u001b[0m\n",
            "    \u001b[36m     │               └ \u001b[0m\u001b[36m\u001b[1m'/content/YOLOX/YOLOX_outputs/yolox_voc_s/latest_ckpt.pth.tar'\u001b[0m\n",
            "    \u001b[36m     └ \u001b[0m\u001b[36m\u001b[1m<function _open_file_like at 0x7f3f8b1f2e60>\u001b[0m\n",
            "\n",
            "  File \"\u001b[32m/usr/local/lib/python3.7/dist-packages/torch/\u001b[0m\u001b[32m\u001b[1mserialization.py\u001b[0m\", line \u001b[33m230\u001b[0m, in \u001b[35m_open_file_like\u001b[0m\n",
            "    \u001b[35m\u001b[1mreturn\u001b[0m \u001b[1m_open_file\u001b[0m\u001b[1m(\u001b[0m\u001b[1mname_or_buffer\u001b[0m\u001b[1m,\u001b[0m \u001b[1mmode\u001b[0m\u001b[1m)\u001b[0m\n",
            "    \u001b[36m       │          │               └ \u001b[0m\u001b[36m\u001b[1m'rb'\u001b[0m\n",
            "    \u001b[36m       │          └ \u001b[0m\u001b[36m\u001b[1m'/content/YOLOX/YOLOX_outputs/yolox_voc_s/latest_ckpt.pth.tar'\u001b[0m\n",
            "    \u001b[36m       └ \u001b[0m\u001b[36m\u001b[1m<class 'torch.serialization._open_file'>\u001b[0m\n",
            "\n",
            "  File \"\u001b[32m/usr/local/lib/python3.7/dist-packages/torch/\u001b[0m\u001b[32m\u001b[1mserialization.py\u001b[0m\", line \u001b[33m211\u001b[0m, in \u001b[35m__init__\u001b[0m\n",
            "    \u001b[1msuper\u001b[0m\u001b[1m(\u001b[0m\u001b[1m_open_file\u001b[0m\u001b[1m,\u001b[0m \u001b[1mself\u001b[0m\u001b[1m)\u001b[0m\u001b[35m\u001b[1m.\u001b[0m\u001b[1m__init__\u001b[0m\u001b[1m(\u001b[0m\u001b[1mopen\u001b[0m\u001b[1m(\u001b[0m\u001b[1mname\u001b[0m\u001b[1m,\u001b[0m \u001b[1mmode\u001b[0m\u001b[1m)\u001b[0m\u001b[1m)\u001b[0m\n",
            "    \u001b[36m      │           │                   │     └ \u001b[0m\u001b[36m\u001b[1m'rb'\u001b[0m\n",
            "    \u001b[36m      │           │                   └ \u001b[0m\u001b[36m\u001b[1m'/content/YOLOX/YOLOX_outputs/yolox_voc_s/latest_ckpt.pth.tar'\u001b[0m\n",
            "    \u001b[36m      │           └ \u001b[0m\u001b[36m\u001b[1m<torch.serialization._open_file object at 0x7f3f78c286d0>\u001b[0m\n",
            "    \u001b[36m      └ \u001b[0m\u001b[36m\u001b[1m<class 'torch.serialization._open_file'>\u001b[0m\n",
            "\n",
            "\u001b[31m\u001b[1mFileNotFoundError\u001b[0m:\u001b[1m [Errno 2] No such file or directory: '/content/YOLOX/YOLOX_outputs/yolox_voc_s/latest_ckpt.pth.tar'\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CnFRJEa7CaPe"
      },
      "source": [
        "# Test the Model\n",
        "Make sure you replace the `TEST_IMAGE_PATH` variable with a test image from your dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uIXoCCwkMjpK",
        "outputId": "cc896737-672a-4d25-ff9b-a79c972985cc"
      },
      "source": [
        "TEST_IMAGE_PATH = \"/content/valid/BloodImage_00057_jpg.rf.1ee93e9ec4d76cfaddaa7df70456c376.jpg\"\n",
        "!python tools/demo.py image -f /content/YOLOX/exps/example/yolox_voc/yolox_voc_s.py -c {MODEL_PATH} --path {TEST_IMAGE_PATH} --conf 0.25 --nms 0.45 --tsize 640 --save_result --device gpu"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m2022-02-21 14:52:23.208\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m240\u001b[0m - \u001b[1mArgs: Namespace(camid=0, ckpt='/content/YOLOX/YOLOX_outputs/yolox_voc_s/latest_ckpt.pth.tar', conf=0.25, demo='image', device='gpu', exp_file='/content/YOLOX/exps/example/yolox_voc/yolox_voc_s.py', experiment_name='yolox_voc_s', fp16=False, fuse=False, name=None, nms=0.45, path='/content/valid/BloodImage_00057_jpg.rf.1ee93e9ec4d76cfaddaa7df70456c376.jpg', save_result=True, trt=False, tsize=640)\u001b[0m\n",
            "\u001b[32m2022-02-21 14:52:23.461\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m250\u001b[0m - \u001b[1mModel Summary: Params: 8.94M, Gflops: 26.64\u001b[0m\n",
            "\u001b[32m2022-02-21 14:52:25.862\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m261\u001b[0m - \u001b[1mloading checkpoint\u001b[0m\n",
            "Traceback (most recent call last):\n",
            "  File \"tools/demo.py\", line 296, in <module>\n",
            "    main(exp, args)\n",
            "  File \"tools/demo.py\", line 262, in main\n",
            "    ckpt = torch.load(ckpt_file, map_location=\"cpu\")\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/serialization.py\", line 579, in load\n",
            "    with _open_file_like(f, 'rb') as opened_file:\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/serialization.py\", line 230, in _open_file_like\n",
            "    return _open_file(name_or_buffer, mode)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/serialization.py\", line 211, in __init__\n",
            "    super(_open_file, self).__init__(open(name, mode))\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/YOLOX/YOLOX_outputs/yolox_voc_s/latest_ckpt.pth.tar'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N7nX2nwWCper"
      },
      "source": [
        "# Visualize the Predictions\n",
        "Make sure you replace the `OUTPUT_IMAGE_PATH` with the respective path of the image output. This path can be found somewhere in the `YOLOX_outputs` folder\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3_kOK2cZtJK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "outputId": "25b113b5-818e-4cee-fd6b-84d6b54d1619"
      },
      "source": [
        "from PIL import Image\n",
        "OUTPUT_IMAGE_PATH = \"/content/YOLOX/YOLOX_outputs/yolox_voc_s/vis_res/2021_08_01_19_51_59/BloodImage_00057_jpg.rf.1ee93e9ec4d76cfaddaa7df70456c376.jpg\" \n",
        "Image.open(OUTPUT_IMAGE_PATH)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-fdb8f523e960>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mOUTPUT_IMAGE_PATH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/YOLOX/YOLOX_outputs/yolox_voc_s/vis_res/2021_08_01_19_51_59/BloodImage_00057_jpg.rf.1ee93e9ec4d76cfaddaa7df70456c376.jpg\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mOUTPUT_IMAGE_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2842\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2843\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2844\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2845\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/YOLOX/YOLOX_outputs/yolox_voc_s/vis_res/2021_08_01_19_51_59/BloodImage_00057_jpg.rf.1ee93e9ec4d76cfaddaa7df70456c376.jpg'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XFbMKDkxPWoD"
      },
      "source": [
        "# Export Trained Weights for Future Inference\n",
        "\n",
        "Now that you have trained your custom detector, you can export the trained weights you have made here for inference on your device elsewhere"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SlZf3KlMPYPS"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LDrqgjePPaXK"
      },
      "source": [
        "%cp {MODEL_PATH} /content/gdrive/My\\ Drive"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}